{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6729aad1-261a-48fa-ae59-986428165ebd",
   "metadata": {},
   "source": [
    "# Training a neural network in PyTorch\n",
    "\n",
    "This notebook demonstrates training a classifier in PyTorch. In order to train a model, there are three main steps:\n",
    "\n",
    "1. Initialize the data and model\n",
    "1. Run the training loop\n",
    "1. Ensure training success with some small evaluation\n",
    "\n",
    "Training a model can be as simple as calling a model.fit() function on some modified data, however there are a number of desired qualities when it comes to model training that will be presented in this notebook: Reproducibility of the model, tracking of model training, and helping model generalization through data randomization\n",
    "\n",
    "### Resources\n",
    "A short compiled list of resources that might help with understanding / helped with development:\n",
    "1. LSTM: https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html\n",
    "1. Embedding: https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html\n",
    "1. Skip Connection: [Torch Implentation of skip-connection](https://github.com/pytorch/vision/blob/a9a8220e0bcb4ce66a733f8c03a1c2f6c68d22cb/torchvision/models/resnet.py#L56-L72)\n",
    "    2. [ResNet](https://arxiv.org/pdf/1512.03385.pdf)\n",
    "1. Pytorch Tutorials: https://pytorch.org/tutorials/\n",
    "    2. Dataloader: https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
    "1. MlFlow: https://mlflow.org/\n",
    "1. Pytorch Lightning: https://www.pytorchlightning.ai/\n",
    "\n",
    "### Environment\n",
    "\n",
    "This notebook is intended to be run in the py-lightning-cbh conda environment defined in requirements_torch.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea2ebc23-4958-4cc3-8f6b-c30686f571eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pl ver: 1.7.7\n",
      "mlflow ver: 1.30.0\n",
      "torch ver: 1.12.1\n",
      "Python ver: sys.version_info(major=3, minor=10, micro=6, releaselevel='final', serial=0)\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "\n",
    "import datetime\n",
    "\n",
    "# file handling\n",
    "import os\n",
    "import pathlib\n",
    "import sys\n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "import zarr\n",
    "\n",
    "import dask\n",
    "import dask.array\n",
    "\n",
    "# training helpers\n",
    "import mlflow.pytorch\n",
    "\n",
    "# math operators\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "# ml\n",
    "import torch\n",
    "from dask.diagnostics import CacheProfiler, Profiler, ResourceProfiler, visualize\n",
    "from mlflow.tracking import MlflowClient\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "from pytorch_lightning.callbacks import (\n",
    "    RichProgressBar,\n",
    ")  # this progress bar works through jupyterHub on spice\n",
    "from pytorch_lightning.loggers import MLFlowLogger\n",
    "\n",
    "# defined in directory (model related definitions)\n",
    "import cbh_data_definitions\n",
    "\n",
    "# cbh_data_definitions.register_cache()\n",
    "import cbh_torch_lstm\n",
    "import cbh_torch_MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33dbdf0f-d6e3-4b83-861d-085acff685a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify package versions\n",
    "print(\"pl ver:\", pl.__version__)\n",
    "print(\"mlflow ver:\", mlflow.__version__)\n",
    "print(\"torch ver:\", torch.__version__)\n",
    "print(\"Python ver:\", sys.version_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "508614de-9142-42df-811b-bba77c76bea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload packages to allow for ease of notebook updates\n",
    "RELOAD_PACKAGES = False\n",
    "if RELOAD_PACKAGES:\n",
    "    import importlib\n",
    "\n",
    "    importlib.reload(cbh_torch_lstm)\n",
    "    importlib.reload(cbh_torch_MLP)\n",
    "    importlib.reload(cbh_data_definitions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd93df58-ab96-441a-a65a-e65004e9c3ad",
   "metadata": {},
   "source": [
    "## MLFlow\n",
    "\n",
    "MLFlow is a technology that can be used for tracking machine learning experiments. The ideal use case involves a team of machine learning practitioners who save their machine learning runs to the same location (backend-store) which provides a history of machine learning experiments (the desired feature in the case of this notebook). Model metrics, parameters, and the model itself can be logged to mlflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2d53e4d-26b1-4d18-a0b7-3f7232f73063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# intialize some settings: mlflow, data directory, resources\n",
    "root_data_directory = pathlib.Path(os.environ[\"SCRATCH\"]) / \"cbh_data\"\n",
    "\n",
    "dev_data_path = root_data_directory / \"analysis_ready\" / \"dev_randomized.zarr\"\n",
    "training_data_path = root_data_directory / \"analysis_ready\" / \"train_randomized.zarr\"\n",
    "\n",
    "mlflow_command_line_run = \"\"\"\n",
    "    mlflow server --port 5001 --backend-store-uri sqlite:///mlflowSQLserver.db  --default-artifact-root ./mlflow_artifacts/\n",
    "\"\"\"\n",
    "alt_mlflow_command_line_run = \"\"\"\n",
    "mlflow server --port 5001 --backend-store-uri sqlite:////data/users/hsouth/mlflow/mlflowServer.db  --default-artifact-root /data/users/hsouth/mlflow/mlflow_artifacts --host 0.0.0.0\n",
    "\"\"\"  # This command is used, as /data/ will not run out of storage quota like /home/ will with many runs\n",
    "mlflow_server_address = \"vld425\"\n",
    "mlflow_server_port = 5001\n",
    "mlflow_server_uri = f\"http://{mlflow_server_address}:{mlflow_server_port:d}\"\n",
    "mlflow_artifact_root = pathlib.Path(\"/data/users/hsouth/mlflow/mlflow_artifacts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0e2648-e3cf-49e8-a5e2-68bef410c58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# further initialization, hyperparameters on evironment\n",
    "hparams_for_mlflow = {}\n",
    "\n",
    "CPU_COUNT = 6\n",
    "RAM_GB = 64\n",
    "hparams_for_mlflow[\"CPU Count\"] = CPU_COUNT\n",
    "hparams_for_mlflow[\"Compute Memory\"] = RAM_GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c96b79fe-a8c4-4026-a77f-39d048642745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded zarr, file information:\n",
      " Name              : /\n",
      "Type              : zarr.hierarchy.Group\n",
      "Read-only         : False\n",
      "Synchronizer type : zarr.sync.ThreadSynchronizer\n",
      "Store type        : zarr.storage.DirectoryStore\n",
      "No. members       : 2\n",
      "No. arrays        : 2\n",
      "No. groups        : 0\n",
      "Arrays            : cloud_base_label_y.zarr, humidity_temp_pressure_x.zarr\n",
      " \n",
      "\n",
      "Loaded zarr, file information:\n",
      " Name              : /\n",
      "Type              : zarr.hierarchy.Group\n",
      "Read-only         : False\n",
      "Synchronizer type : zarr.sync.ThreadSynchronizer\n",
      "Store type        : zarr.storage.DirectoryStore\n",
      "No. members       : 2\n",
      "No. arrays        : 2\n",
      "No. groups        : 0\n",
      "Arrays            : cloud_base_label_y.zarr, humidity_temp_pressure_x.zarr\n",
      " \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table>\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 87.48 GiB </td>\n",
       "                        <td> 1.82 GiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (111820800, 70, 3) </td>\n",
       "                        <td> (2329600, 70, 3) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Count </th>\n",
       "                        <td> 2 Graph Layers </td>\n",
       "                        <td> 48 Chunks </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                    <th> Type </th>\n",
       "                    <td> float32 </td>\n",
       "                    <td> numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"156\" height=\"146\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"80\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"10\" y1=\"25\" x2=\"80\" y2=\"96\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"10\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"12\" y1=\"2\" x2=\"12\" y2=\"28\" />\n",
       "  <line x1=\"17\" y1=\"7\" x2=\"17\" y2=\"32\" />\n",
       "  <line x1=\"20\" y1=\"10\" x2=\"20\" y2=\"35\" />\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"24\" y2=\"40\" />\n",
       "  <line x1=\"27\" y1=\"17\" x2=\"27\" y2=\"43\" />\n",
       "  <line x1=\"32\" y1=\"22\" x2=\"32\" y2=\"47\" />\n",
       "  <line x1=\"35\" y1=\"25\" x2=\"35\" y2=\"50\" />\n",
       "  <line x1=\"39\" y1=\"29\" x2=\"39\" y2=\"54\" />\n",
       "  <line x1=\"42\" y1=\"32\" x2=\"42\" y2=\"57\" />\n",
       "  <line x1=\"46\" y1=\"36\" x2=\"46\" y2=\"62\" />\n",
       "  <line x1=\"49\" y1=\"39\" x2=\"49\" y2=\"65\" />\n",
       "  <line x1=\"54\" y1=\"44\" x2=\"54\" y2=\"69\" />\n",
       "  <line x1=\"57\" y1=\"47\" x2=\"57\" y2=\"72\" />\n",
       "  <line x1=\"61\" y1=\"51\" x2=\"61\" y2=\"76\" />\n",
       "  <line x1=\"64\" y1=\"54\" x2=\"64\" y2=\"79\" />\n",
       "  <line x1=\"68\" y1=\"58\" x2=\"68\" y2=\"84\" />\n",
       "  <line x1=\"71\" y1=\"61\" x2=\"71\" y2=\"87\" />\n",
       "  <line x1=\"76\" y1=\"66\" x2=\"76\" y2=\"91\" />\n",
       "  <line x1=\"80\" y1=\"70\" x2=\"80\" y2=\"96\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 80.58823529411765,70.58823529411765 80.58823529411765,96.00085180870013 10.0,25.412616514582485\" style=\"fill:#8B4903A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"35\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"12\" y1=\"2\" x2=\"38\" y2=\"2\" />\n",
       "  <line x1=\"17\" y1=\"7\" x2=\"42\" y2=\"7\" />\n",
       "  <line x1=\"20\" y1=\"10\" x2=\"45\" y2=\"10\" />\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"50\" y2=\"14\" />\n",
       "  <line x1=\"27\" y1=\"17\" x2=\"53\" y2=\"17\" />\n",
       "  <line x1=\"32\" y1=\"22\" x2=\"57\" y2=\"22\" />\n",
       "  <line x1=\"35\" y1=\"25\" x2=\"60\" y2=\"25\" />\n",
       "  <line x1=\"39\" y1=\"29\" x2=\"64\" y2=\"29\" />\n",
       "  <line x1=\"42\" y1=\"32\" x2=\"67\" y2=\"32\" />\n",
       "  <line x1=\"46\" y1=\"36\" x2=\"72\" y2=\"36\" />\n",
       "  <line x1=\"49\" y1=\"39\" x2=\"75\" y2=\"39\" />\n",
       "  <line x1=\"54\" y1=\"44\" x2=\"79\" y2=\"44\" />\n",
       "  <line x1=\"57\" y1=\"47\" x2=\"82\" y2=\"47\" />\n",
       "  <line x1=\"61\" y1=\"51\" x2=\"86\" y2=\"51\" />\n",
       "  <line x1=\"64\" y1=\"54\" x2=\"89\" y2=\"54\" />\n",
       "  <line x1=\"68\" y1=\"58\" x2=\"94\" y2=\"58\" />\n",
       "  <line x1=\"71\" y1=\"61\" x2=\"97\" y2=\"61\" />\n",
       "  <line x1=\"76\" y1=\"66\" x2=\"101\" y2=\"66\" />\n",
       "  <line x1=\"80\" y1=\"70\" x2=\"106\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"80\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"35\" y1=\"0\" x2=\"106\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 35.41261651458248,0.0 106.00085180870013,70.58823529411765 80.58823529411765,70.58823529411765\" style=\"fill:#8B4903A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"80\" y1=\"70\" x2=\"106\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"80\" y1=\"96\" x2=\"106\" y2=\"96\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"80\" y1=\"70\" x2=\"80\" y2=\"96\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"106\" y1=\"70\" x2=\"106\" y2=\"96\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"80.58823529411765,70.58823529411765 106.00085180870013,70.58823529411765 106.00085180870013,96.00085180870013 80.58823529411765,96.00085180870013\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"93.294544\" y=\"116.000852\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >3</text>\n",
       "  <text x=\"126.000852\" y=\"83.294544\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(0,126.000852,83.294544)\">70</text>\n",
       "  <text x=\"35.294118\" y=\"80.706734\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(45,35.294118,80.706734)\">111820800</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<from-zarr, shape=(111820800, 70, 3), dtype=float32, chunksize=(2329600, 70, 3), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize data\n",
    "(\n",
    "    train_input,\n",
    "    train_labels,\n",
    "    _,\n",
    ") = cbh_data_definitions.load_data_from_zarr(training_data_path)\n",
    "\n",
    "(dev_input, dev_labels, _) = cbh_data_definitions.load_data_from_zarr(dev_data_path)\n",
    "\n",
    "# the cloud volume is not needed for the task, so isn't saved on the load\n",
    "# show a chunk\n",
    "train_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c8b8915-497a-4d90-8ec2-971caa896dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings for data limiting (used for development e.g. faster training runs)\n",
    "LIMIT_DATA = False\n",
    "LIMIT_DATA_INT = -1\n",
    "if LIMIT_DATA:\n",
    "    LIMIT_DATA_INT = 10024\n",
    "    train_input = train_input[:LIMIT_DATA_INT]\n",
    "    train_labels = train_labels[:LIMIT_DATA_INT]\n",
    "    # train_cloud_volume = train_cloud_volume[:LIMIT_DATA_INT]\n",
    "    dev_input = dev_input[:LIMIT_DATA_INT]\n",
    "    dev_labels = dev_labels[:LIMIT_DATA_INT]\n",
    "    # dev_cloud_volume = dev_cloud_volume[:LIMIT_DATA_INT]\n",
    "hparams_for_mlflow[\"Limited sample number\"] = LIMIT_DATA_INT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffba27b-d62f-4bcd-8132-e668c3479e3b",
   "metadata": {},
   "source": [
    "In order to make machine learning reproducible, hyperparameters will be logged using MLflow so that models can be redefined exactly as they were, and a seed for our random functions e.g. random shuffling of data: The random seed ensures that the same \"random\" shuffle of the data is performed each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b83e7351-b657-4e9b-8997-2d4022f8b5e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "# reproducibility with seed everything\n",
    "seed_everything_int = 42\n",
    "seed_everything(seed_everything_int)\n",
    "hparams_for_mlflow[\"Random seed\"] = seed_everything_int"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0ab5c4-12e5-48cb-a947-f4f70a0e520e",
   "metadata": {},
   "source": [
    "## Perform the network initialization and training\n",
    "\n",
    "for each different model architecture, various different hyperparameters must be defined. For example in the case of an LSTM, bi-directionality is a simple to implement extension to the model type as this is a parameter of the layer definition in pytorch so can be included in the LSTM hyperparameter definition, there is no concept of input sequence direction in a simple MLP, so this hyperparameter doesn't apply\n",
    "\n",
    "training related hyperparameters are also defined. It is important to track exactly how much training is performed (epoch and step), the batch size, the learning rate and the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66118c9f-b5e5-447f-a4af-0e2fc7445238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.89052188e+04, 2.43972824e+02, 1.78724772e-03])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_l_p_f_m = np.load(\"./per_level_per_feat_mean.npz\")\n",
    "p_l_p_f_s = np.load(\"./per_level_per_feat_std.npz\")\n",
    "p_f_m = np.load(\"./per_feat_mean.npz\")\n",
    "p_f_s = np.load(\"./per_feat_std.npz\")\n",
    "p_l_p_f_s += 5.0e-12  # prevent divide by 0\n",
    "p_f_m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a05e84-7052-4d68-a28c-e437c106dc68",
   "metadata": {},
   "source": [
    "### Pytorch\n",
    "\n",
    "https://pytorch.org/:\n",
    "for this notebook, pytorch lightning will be used as the machine learning framework. Pytorch aims to behave in a similar way to Python (to be \"Pythonic\"), and has a focus on dynamic modelling which makes custom model behaviour easier to implement than other popular frameworks.\n",
    "\n",
    "models are implemented in python files outside of the jupyter notebook, this is because the model is reused in all following notebooks so is given its own class for import\n",
    "\n",
    "### Pytorch lightning\n",
    "\n",
    "https://www.pytorchlightning.ai/:\n",
    "Pytorch lightning (PL) boasts many impressive features, it aims to remove elements that always exist in a pytorch ML pipeline (e.g. model.zero_grad and loss.backward typically always precede optimizer.step), and automate other choices such as hardware specification. PL has the mantra \"more time on research, less on engineering\", but the desirable feature of this technology in our case is the greater enforment of coding patterns:\n",
    "\n",
    "- For example, in the pytorch documentation, it is common for example usage of a neural network layer to be presented in code, outside of a model e.g. model = torch.nn.Linear(x,y)-- if your desired model is only one layer or fits into a single nn.Sequential, there isn't any need to write the more common pattern of implementing a class for the model which inherits from torch.nn.Module. However this lack of standard exists beyond model definition: should model training be in its own function? Does my optimizer belong as an attribute of the model class? pytorch lightning makes these decisions less of a choice which is better for code accessibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ce919a8-22f0-46c1-a895-6b7c07ccdba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data chunk size: 2329600\n",
      "Factors of chunk:  [1, 2, 4, 5, 7, 8, 10, 13, 14, 16, 20, 25, 26, 28, 32, 35, 40, 50, 52, 56, 64, 65, 70, 80, 91, 100, 104, 112, 128, 130, 140, 160, 175, 182, 200, 208, 224, 256, 260, 280, 320, 325, 350, 364, 400, 416, 448, 455, 512, 520, 560, 640, 650, 700, 728, 800, 832, 896, 910, 1024, 1040, 1120, 1280, 1300, 1400, 1456, 1600, 1664, 1792, 1820, 2080, 2240, 2275, 2560, 2600, 2800, 2912, 3200, 3328, 3584, 3640, 4160, 4480, 4550, 5120, 5200, 5600, 5824, 6400, 6656, 7168, 7280, 8320, 8960, 9100, 10400, 11200, 11648, 12800, 13312, 14560, 16640, 17920, 18200, 20800, 22400, 23296, 25600, 29120, 33280, 35840, 36400, 41600, 44800, 46592, 58240, 66560, 72800, 83200, 89600, 93184, 116480, 145600, 166400, 179200, 232960, 291200, 332800, 465920, 582400, 1164800, 2329600]\n"
     ]
    }
   ],
   "source": [
    "# define model and hyperparameters\n",
    "mlp_layernum = 3\n",
    "model_hyperparameter_dictionary = {\n",
    "    \"LSTM\": {\n",
    "        \"input_size\": train_input.shape[2],  # input size is the cell input (feat dim)\n",
    "        \"lstm_layers\": 2,\n",
    "        \"lstm_hidden_size\": 100,\n",
    "        \"output_size\": 100,  # for each height layer, predict one value for cloud base prob\n",
    "        \"height_dimension\": train_input.shape[1],\n",
    "        \"embed_size\": 20,\n",
    "        \"BILSTM\": True,\n",
    "        \"batch_first\": True,\n",
    "        \"skip_connection\": True,\n",
    "        \"backward_lstm_differing_transitions\": False,\n",
    "        \"lr\": 0.001460,\n",
    "        \"norm_mat_mean\": torch.from_numpy(p_l_p_f_m.astype(np.float32)),\n",
    "        \"norm_mat_std\": torch.from_numpy(p_l_p_f_s.astype(np.float32)),\n",
    "        \"norm_method\": \"p_l_p_f\",\n",
    "        \"linear_instead_of_conv_cap\": True,\n",
    "    },\n",
    "    \"MLP\": {\n",
    "        \"input_size\": train_input.shape[2] * train_input.shape[1],\n",
    "        \"ff_nodes\": mlp_layernum * [256],\n",
    "        \"output_size\": train_input.shape[1],\n",
    "        \"lr\": 1.0e-3,\n",
    "        \"activation\": \"relu\",\n",
    "        \"layer_num\": mlp_layernum,\n",
    "        \"norm_mat_mean\": torch.from_numpy(p_l_p_f_m.astype(np.float32)),\n",
    "        \"norm_mat_std\": torch.from_numpy(p_l_p_f_s.astype(np.float32)),\n",
    "        \"norm_method\": \"p_l_p_f\",\n",
    "    },\n",
    "}\n",
    "\n",
    "model_definition_dictionary = {\n",
    "    \"LSTM\": cbh_torch_lstm.CloudBaseLSTM(**model_hyperparameter_dictionary[\"LSTM\"]),\n",
    "    \"MLP\": cbh_torch_MLP.CloudBaseMLP(**model_hyperparameter_dictionary[\"MLP\"]),\n",
    "}\n",
    "model_picked = \"LSTM\"\n",
    "model = model_definition_dictionary[model_picked]  # pick a model\n",
    "hparams_for_mlflow[\"Model defined hparams\"] = model_hyperparameter_dictionary[\n",
    "    model_picked\n",
    "]\n",
    "\n",
    "\n",
    "# define training related hyperparameters\n",
    "\n",
    "epochs = 1\n",
    "hparams_for_mlflow[\"Max epochs\"] = epochs\n",
    "collate_fn = cbh_data_definitions.dataloader_collate_with_dask\n",
    "print(\"Data chunk size:\", train_input.chunksize[0])\n",
    "print(\n",
    "    \"Factors of chunk: \",\n",
    "    [\n",
    "        n\n",
    "        for n in range(1, train_input.chunksize[0] + 1)\n",
    "        if train_input.chunksize[0] % n == 0\n",
    "    ],\n",
    ")\n",
    "batch_size = 100\n",
    "hparams_for_mlflow[\"Batch size\"] = batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09b8445-1600-4674-9f08-3ab87c08bcfd",
   "metadata": {},
   "source": [
    "### Dataloader\n",
    "The PyTorch dataloader is also initialized. The PyTorch dataloader acts as an interface to implement methods for getting the data into an ML model. It facilitates automatic batching and shuffling of the data having only defined how the data is retrieved at an index, and is well documented in use for ML training, validation, and testing. In this case there are multiple strategies for batch selection implemented and the batch collection method has been overwritten for every strategy. The custom functionality is then abstracted behind the DataLoader for a simpler/ more manageable ML pipeline. https://pytorch.org/docs/stable/data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adc82bd5-20a8-4072-a266-4c162e41ed41",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader = None, None\n",
    "\n",
    "single_proc_workers = True  # False causes crashes in some cases or in the case of 1 chunk at a time, makes data access slower\n",
    "if single_proc_workers:\n",
    "    WORKERS_CPU_COUNT = 0\n",
    "else:\n",
    "    WORKERS_CPU_COUNT = CPU_COUNT\n",
    "\n",
    "data_loader_hparam_dict = {\n",
    "    \"batch_size\": batch_size,\n",
    "    \"num_workers\": WORKERS_CPU_COUNT,\n",
    "    # 'pin_memory':False,\n",
    "    \"collate_fn\": None,  # using 1chunk method\n",
    "    \"thread_count_for_dask\": CPU_COUNT,\n",
    "    \"method\": \"1chunk\",\n",
    "}\n",
    "shuffle_training_data = (False,)\n",
    "\n",
    "datamodule = cbh_data_definitions.CBH_DataModule(\n",
    "    train_input,\n",
    "    train_labels,\n",
    "    dev_input,\n",
    "    dev_labels,\n",
    "    **data_loader_hparam_dict,\n",
    "    randomize_chunkwise=True,\n",
    ")\n",
    "data_loader_hparam_dict[\"shuffle_training_data\"] = shuffle_training_data\n",
    "hparams_for_mlflow[\"data loader hparams\"] = data_loader_hparam_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53ceb9d-9a31-4b3c-9dbe-ffb7cbda4d15",
   "metadata": {},
   "source": [
    "Next we initialize an MLflow experiement, MLflow serves to share model training information in collaboration, allow for monitoring of current training processes, and tracking of hyperparameters + models + metrics for reproducing saving and loading training experiements. The MLflow server is launched from the command line, and connected to through the below cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39551462-62c9-4181-a41b-640463f4196c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating experiment\n"
     ]
    }
   ],
   "source": [
    "experiment_name = \"cbh-label-model-runs\"\n",
    "# experiment_name = 'test-setup-for-model-runs'\n",
    "\n",
    "# torch.set_num_threads(CPU_COUNT)\n",
    "\n",
    "mlflow.set_tracking_uri(mlflow_server_uri)\n",
    "# make vars global\n",
    "mlf_exp = None\n",
    "mlf_exp_id = None\n",
    "try:\n",
    "    print(\"Creating experiment\")\n",
    "    mlf_exp_id = mlflow.create_experiment(experiment_name)\n",
    "    mlf_exp = mlflow.get_experiment(mlf_exp_id)\n",
    "except mlflow.exceptions.RestException:\n",
    "    mlf_exp = mlflow.get_experiment_by_name(experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9fbe59-be67-4309-8369-33245ae25fef",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Autologging\n",
    "Autologging is a common feature of ML pipelines which will report desired metrics and values to your ML tracking tools. It is useful as logging is best practice, so helps prevent extra boilerplate.\n",
    "\n",
    "Autologging of the experiement did not work in this implementation, the best guess as to why is due to dask's lock on the data which prevents saving model weights, or displaying model attributes in some cases which autologging uses. To circumvent this, a custom checkpointing function is implemented into the PyTorch-Lighning's implementation for logging to MLflow. It is possible to give the run information to the mlflow logger as a class attribute, as currently artifacts are logged locally which is not desirable for both the sharing of logged models or your disk space allowance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82240810-0347-41a2-a8be-c43140184584",
   "metadata": {},
   "source": [
    "Below the MLFlowLogger, which is a [pytorch-lightning logger](https://pytorch-lightning.readthedocs.io/en/stable/extensions/generated/pytorch_lightning.loggers.MLFlowLogger.html) has had the after_save_checkpoint method overwritten in order to attempt to combat the autologging failure, as our main issue is lack of saving the model weights after evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21185156-4866-4d28-8c57-f036993f8170",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLFlowLogger(pl.loggers.MLFlowLogger):  # overwrite mlflogger\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def after_save_checkpoint(\n",
    "        self, model_checkpoint: pl.callbacks.ModelCheckpoint\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Called after model checkpoint callback saves a new checkpoint.\n",
    "        \"\"\"\n",
    "        best_chkpt = torch.load(model_checkpoint.best_model_path)\n",
    "        # print(best_chkpt)\n",
    "        # print(best_chkpt['callbacks'])\n",
    "        checkpoint_for_mlflow = {\n",
    "            \"val loss\": float(\n",
    "                best_chkpt[\"callbacks\"][\n",
    "                    list(\n",
    "                        key\n",
    "                        for key in list(best_chkpt[\"callbacks\"].keys())\n",
    "                        if \"ModelCheckpoint\" in key\n",
    "                    )[0]\n",
    "                ][\"current_score\"]\n",
    "            ),\n",
    "            # \"train loss at step-1\": list(train_loss_metric.value for train_loss_metric in self._mlflow_client.get_metric_history(run.info.run_id, \"Train loss\") if (int(train_loss_metric.step) == int(best_chkpt['global_step']-1)))[0],\n",
    "            \"global_step\": best_chkpt[\"global_step\"],\n",
    "            \"model_state_dict\": best_chkpt[\"state_dict\"],\n",
    "            \"checkpoint\": best_chkpt,\n",
    "        }\n",
    "        with TemporaryDirectory() as tmpdirname:\n",
    "            f_name = os.path.join(\n",
    "                tmpdirname,\n",
    "                f\"{datetime.datetime.now()}best_model_checkpoint-step_{best_chkpt['global_step']}.pt\",\n",
    "            )\n",
    "            torch.save(checkpoint_for_mlflow, f_name)\n",
    "            mlflow.log_artifact(f_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bc69ee-249e-4e53-8187-58269595c44d",
   "metadata": {},
   "source": [
    "Here the training is run, but not before some more model settings:timeout for training, naming of the MLflow experiement, defining when to validate, how to report progress in the notebook, and defining when to save a model. After training is run, another copy of the model is saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "959986bc-8f6a-46c5-a538-21ee2c81de7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c78d61e-c966-4ae2-a99e-278ab50c2b26",
   "metadata": {},
   "source": [
    "More hyperparameters are defined in this section, and the training loop is run. pytorch lightning has a \"trainer\" object which handles the training specific hyperparameter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbed128a-5335-4d4f-a4d1-0285b5a1b3cc",
   "metadata": {},
   "source": [
    "Below is the main element of this notebook, the training loop. Pytorch lightning tries to abstract a lot of the common training loop boilerplate, such as the loop itself and eval with a trainer object. This is also where the mlflow \"run\" is initialized so that we can start tracking the output of training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ac41e5-2a57-4750-af90-df368fc114f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_time = \"00:03:00:00\"  # dd:hh:mm:ss\n",
    "\n",
    "hparams_for_mlflow[\"Training timeout\"] = max_time\n",
    "\n",
    "timestamp_template = \"{dt.year:04d}{dt.month:02d}{dt.day:02d}T{dt.hour:02d}{dt.minute:02d}{dt.second:02d}\"\n",
    "run_name_template = \"cbh_challenge_{network_name}_\" + timestamp_template\n",
    "current_run_name = run_name_template.format(\n",
    "    network_name=model.__class__.__name__, dt=datetime.datetime.now()\n",
    ")\n",
    "\n",
    "predef_train_hparams = {\n",
    "    \"max_epochs\": epochs,\n",
    "    \"deterministic\": True,\n",
    "    \"val_check_interval\": 0.01,  # val every percentage of the data\n",
    "    \"devices\": \"auto\",\n",
    "    \"accelerator\": \"auto\",\n",
    "    \"max_time\": max_time,\n",
    "    \"replace_sampler_ddp\": False,\n",
    "    \"enable_checkpointing\": True,\n",
    "    \"strategy\": None,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c2dade6-a531-43b9-a88c-dcfb92937ab0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Epoch 0/0 </span> <span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">18875/1133008</span> <span style=\"color: #8a8a8a; text-decoration-color: #8a8a8a\">2:45:17 • 6 days, 14:08:51</span> <span style=\"color: #b2b2b2; text-decoration-color: #b2b2b2\">1.96it/s</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">loss: 1.02 v_num: f9d6 </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[37mEpoch 0/0 \u001b[0m \u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[37m18875/1133008\u001b[0m \u001b[38;5;245m2:45:17 • 6 days, 14:08:51\u001b[0m \u001b[38;5;249m1.96it/s\u001b[0m \u001b[37mloss: 1.02 v_num: f9d6 \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/12/02 16:56:37 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during pytorch autologging: cannot pickle '_thread.RLock' object\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ended run 6063389151104ea7afdd046d15ccf9d6\n"
     ]
    }
   ],
   "source": [
    "# with Profiler() as prof, ResourceProfiler(dt=0.25) as rprof, CacheProfiler() as cprof:\n",
    "with mlflow.start_run(\n",
    "    experiment_id=mlf_exp.experiment_id, run_name=current_run_name\n",
    ") as run:\n",
    "\n",
    "    mlflow.pytorch.autolog()\n",
    "    mlf_logger = MLFlowLogger(\n",
    "        experiment_name=experiment_name,\n",
    "        tracking_uri=mlflow_server_uri,\n",
    "        run_id=run.info.run_id,\n",
    "    )\n",
    "\n",
    "    # define trainer\n",
    "    time_for_checkpoint = datetime.timedelta(minutes=15)\n",
    "    checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "        train_time_interval=time_for_checkpoint,\n",
    "        dirpath=run.info.artifact_uri,\n",
    "        monitor=\"Val loss\",\n",
    "        save_on_train_epoch_end=False,\n",
    "        mode=\"min\",\n",
    "    )\n",
    "    callbacks = [checkpoint_callback, RichProgressBar()]\n",
    "    \n",
    "    trainer_hparams = {\n",
    "        \"callbacks\": callbacks,\n",
    "        \"logger\": mlf_logger,\n",
    "    }\n",
    "    trainer_hparams = {**trainer_hparams,**predef_train_hparams}\n",
    "    hparams_for_mlflow[\"Trainer hparams\"] = trainer_hparams\n",
    "    mlf_logger.log_hyperparams(hparams_for_mlflow)\n",
    "    trainer = pl.Trainer(**trainer_hparams)\n",
    "\n",
    "    trainer.fit(model=model, datamodule=datamodule)\n",
    "    path_to_save = \"{dt.year:04d}{dt.month:02d}{dt.day:02d}-{dt.hour:02d}{dt.minute:02d}{dt.second:02d}\".format(\n",
    "        dt=datetime.datetime.now()\n",
    "    )\n",
    "    trainer.save_checkpoint(\n",
    "        filepath=run.info.artifact_uri + f\"/post_epoch_modelchkpt_{path_to_save}\"\n",
    "    )\n",
    "    with TemporaryDirectory() as tmpdirname:\n",
    "        f_name = os.path.join(\n",
    "            tmpdirname, f\"{run.info.run_id}-post_epoch_checkpoint_logged.pt\"\n",
    "        )\n",
    "        trainer.save_checkpoint(filepath=f_name)\n",
    "        mlflow.log_artifact(f_name)\n",
    "print(\"Ended run\", run.info.run_id)\n",
    "# print(visualize([prof, rprof, cprof], filename='profile_loop.html', save=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba52d2c-1212-4894-ad05-3a9f7761ccf2",
   "metadata": {},
   "source": [
    "## Display and evaluate results\n",
    "\n",
    "After training, explore some of the results from our model. tracking of experiment progress can be done during training, but it is a good idea to get an idea of final performance, or quickly investigate aspects of the model which cannot be monitored during training such as class imbalance of predictions. More ensurement of properties of the training can also be performed in this section, such as recalling MLflow variables in order to double check correct logging functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "888b7d7e-5158-42a9-b3f2-046dca3a218c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_id: 6063389151104ea7afdd046d15ccf9d6\n",
      "artifacts: []\n",
      "params: {}\n",
      "metrics: {}\n",
      "tags: {}\n"
     ]
    }
   ],
   "source": [
    "def print_auto_logged_info(r):\n",
    "\n",
    "    tags = {k: v for k, v in r.data.tags.items() if not k.startswith(\"mlflow.\")}\n",
    "    artifacts = [f.path for f in MlflowClient().list_artifacts(r.info.run_id, \"model\")]\n",
    "    print(\"run_id: {}\".format(r.info.run_id))\n",
    "    print(\"artifacts: {}\".format(artifacts))\n",
    "    print(\"params: {}\".format(r.data.params))\n",
    "    print(\"metrics: {}\".format(r.data.metrics))\n",
    "    print(\"tags: {}\".format(tags))\n",
    "\n",
    "\n",
    "print_auto_logged_info(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ce386db-e33d-42aa-90ff-8a4a4dd3be76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 70]) prediction output\n",
      "(100,) prediction label shape\n",
      "(100,) targ shape\n",
      "Correct samples: 59\n",
      "Total samples tested: 100\n",
      "Accuracy: 59.0 %\n",
      "Model predictions binned: (Class labels), (Counts): (array([ 0,  2,  3,  5,  6,  7,  9, 10, 11, 12, 13, 14, 16, 18, 22, 24, 32,\n",
      "       33, 34, 35, 36, 38, 40, 41, 42, 43, 44, 69]), array([28,  3,  6,  1,  6,  2,  1,  1,  3,  2,  3,  3,  2,  1,  1,  1,  1,\n",
      "        1,  2,  1,  1,  1,  1,  1,  3,  1,  1, 22]))\n",
      "Model targets binned: (Class labels), (Counts): (array([ 0,  2,  3,  4,  5,  6,  7,  9, 10, 11, 12, 13, 14, 15, 16, 18, 20,\n",
      "       24, 32, 33, 34, 35, 36, 38, 40, 42, 43, 44, 46, 69]), array([18,  3,  4,  3,  2,  3,  3,  1,  1,  3,  3,  4,  2,  3,  1,  1,  1,\n",
      "        3,  2,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, 29]))\n"
     ]
    }
   ],
   "source": [
    "# test model functionality through outputs on a batch of independent data\n",
    "example_batch = next(iter(datamodule.train_dataloader()))\n",
    "inputs = example_batch[0]\n",
    "try:\n",
    "    preds, _ = model(inputs, heights)\n",
    "except:\n",
    "    if model_picked == \"LSTM\":\n",
    "        inputs = example_batch[0]\n",
    "    else:\n",
    "        print(example_batch[0].shape, \"inp pre-flat\")\n",
    "        inputs = torch.flatten(example_batch[0], start_dim=1)\n",
    "    preds = model(inputs)\n",
    "print(preds.shape, \"prediction output\")\n",
    "pred_label = np.argmax(preds.detach().numpy(), axis=1)\n",
    "print(pred_label.shape, \"prediction label shape\")\n",
    "targs = example_batch[1]\n",
    "targs = np.array(targs)\n",
    "print(targs.shape, \"targ shape\")\n",
    "correct = targs == pred_label\n",
    "print(\"Correct samples:\", np.count_nonzero(correct))\n",
    "print(\"Total samples tested:\", len(correct))\n",
    "print(\"Accuracy:\", (np.count_nonzero(correct) / len(correct) * 100), \"%\")\n",
    "print(\n",
    "    \"Model predictions binned: (Class labels), (Counts):\",\n",
    "    np.unique(pred_label, return_counts=True),\n",
    ")\n",
    "print(\n",
    "    \"Model targets binned: (Class labels), (Counts):\",\n",
    "    np.unique(targs, return_counts=True),\n",
    ")\n",
    "eg_batch_metrics = {\n",
    "    \"Correct samples\": np.count_nonzero(correct),\n",
    "    \"Total samples tested\": len(correct),\n",
    "    \"Accuracy\": (np.count_nonzero(correct) / len(correct) * 100),\n",
    "    \"Model predictions binned: (Class labels), (Counts)\": str(\n",
    "        np.unique(pred_label, return_counts=True)\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab5a6d3a-5b0b-4fe5-b6d3-664fa93f6498",
   "metadata": {},
   "outputs": [],
   "source": [
    "eg_batch_metrics = {\n",
    "    \"Single batch example validation metrics/Correct samples\": np.count_nonzero(\n",
    "        correct\n",
    "    ),\n",
    "    \"Single batch example validation metrics/Total samples tested\": len(correct),\n",
    "    \"Single batch example validation metrics/Accuracy\": np.count_nonzero(correct)\n",
    "    / len(correct)\n",
    "    * 100,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b42f978-4908-4d20-95e4-b2d7adf48bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlf_logger.log_metrics(eg_batch_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c108cb0a-4886-40ac-8ab8-af913c5d3b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_id: 6063389151104ea7afdd046d15ccf9d6\n",
      "artifacts: []\n",
      "params: {'CPU Count': '6', 'Compute Memory': '64', 'Limited sample number': '-1', 'Random seed': '42', 'Model defined hparams/input_size': '3', 'Model defined hparams/lstm_layers': '2', 'Model defined hparams/lstm_hidden_size': '100', 'Model defined hparams/output_size': '100', 'Model defined hparams/height_dimension': '70', 'Model defined hparams/embed_size': '20', 'Model defined hparams/BILSTM': 'True', 'Model defined hparams/batch_first': 'True', 'Model defined hparams/skip_connection': 'True', 'Model defined hparams/backward_lstm_differing_transitions': 'False', 'Model defined hparams/lr': '0.00146', 'Model defined hparams/norm_method': 'p_l_p_f', 'Model defined hparams/linear_instead_of_conv_cap': 'True', 'Max epochs': '1', 'Batch size': '100', 'data loader hparams/batch_size': '100', 'data loader hparams/num_workers': '0', 'data loader hparams/collate_fn': 'None', 'data loader hparams/thread_count_for_dask': '6', 'data loader hparams/method': '1chunk', 'data loader hparams/shuffle_training_data': '(False,)', 'Training timeout': '00:03:00:00', 'Trainer hparams/max_epochs': '1', 'Trainer hparams/deterministic': 'True', 'Trainer hparams/val_check_interval': '0.01', 'Trainer hparams/devices': 'auto', 'Trainer hparams/accelerator': 'auto', 'Trainer hparams/max_time': '00:03:00:00', 'Trainer hparams/replace_sampler_ddp': 'False', 'Trainer hparams/enable_checkpointing': 'True', 'Trainer hparams/strategy': 'None', 'Trainer hparams/callbacks': '[<pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint object at 0x2ba410aa31f0>, <pytorch_lightning.callbacks.progress.rich_progress.RichProgressBar object at 0x2ba410aa32e0>]', 'Trainer hparams/logger': '<__main__.MLFlowLogger object at 0x2ba410279ab0>', 'input_size': '3', 'lstm_layers': '2', 'lstm_hidden_size': '100', 'output_size': '100', 'height_dimension': '70', 'embed_size': '20', 'BILSTM': 'True', 'backward_lstm_differing_transitions': 'False', 'batch_first': 'True', 'lr': '0.00146', 'skip_connection': 'True', 'norm_method': 'p_l_p_f', 'linear_instead_of_conv_cap': 'True', 'conv_cap_window': '5', 'epochs': '1', 'optimizer_name': 'Adam', 'betas': '(0.9, 0.999)', 'eps': '1e-08', 'weight_decay': '0', 'amsgrad': 'False', 'maximize': 'False', 'foreach': 'None', 'capturable': 'False'}\n",
      "metrics: {'Val loss': 1.1445627212524414, 'val_loss_mean': 1.1743098497390747, 'Train loss': 0.8445764183998108, 'epoch': 0.0, 'Single batch example validation metrics/Correct samples': 59.0, 'Single batch example validation metrics/Total samples tested': 100.0, 'Single batch example validation metrics/Accuracy': 59.0}\n",
      "tags: {'Mode': 'training'}\n"
     ]
    }
   ],
   "source": [
    "# display mlflow output\n",
    "print_auto_logged_info(mlflow.get_run(run_id=run.info.run_id))\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85794064-f496-47a1-b2f6-efcd28dafb46",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "In this phase of the model pipeline it is important to make many iterations to ensure that the model is well understood. It is helpful to print the dimensions of layers at each step of the foward pass, to verify the model behaves as expected, and monitor loss for reasonable learning\n",
    "\n",
    "- Are there any dead weights? https://towardsdatascience.com/neural-network-the-dead-neuron-eaa92e575748\n",
    "- Does the learning rate cause the gradient to explode https://neptune.ai/blog/vanishing-and-exploding-gradients-debugging-monitoring-fixing\n",
    "\n",
    "These resources may help in debugging\n",
    "\n",
    "- https://wandb.ai/ayush-thakur/debug-neural-nets/reports/Visualizing-and-Debugging-Neural-Networks-with-PyTorch-and-Weights-Biases--Vmlldzo2OTUzNA\n",
    "- http://karpathy.github.io/2019/04/25/recipe/\n",
    "\n",
    "Make sure to go to the evaluation notebook after running a single model, and ensure that nothing goes wrong after training, for example in my case, the normalization method wasn't sufficient, so a view of the outputs on the validation data showed that predictions only worked in certain areas of the model output, after this is known and the normalization is changed, the problem is reduced.\n",
    "\n",
    "Try out different options until reasonable loss is achieved before moving to hyperparameter tuning in order to get a better sense of the ranges that will be used when defining the hyperparameter space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59c42a7-5d05-4686-aaff-7bdee4dcc7a0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Notebook to Script\n",
    "\n",
    "Models may be developed on this notebook, though longer training time is desirable when it comes to producing a final result, post hyper parameter tuning. In order to do this, the notebook can be converted to a script with\n",
    "`jupyter nbconvert --to script 03_pytorch_train.ipynb`\n",
    "once converted, update the values of some of the variables to match the longer training time, e.g. max time should be increased to sometime soon before the time on SPICE (leaving some room for the model to end its current training step, save out, and give some initial evaluation). and CPUs might be increased for a non-test run of the model.\n",
    "\n",
    "afterward you can submit the py file to sbatch with a shell script (.sh)\n",
    "\n",
    "```\n",
    "#!/bin/bash -l\n",
    "conda activate py-lightning\n",
    "python 03_pytorch_train.py\n",
    "\n",
    "```\n",
    "\n",
    "e.g. `sbatch --qos=long --time=4319 --mem=64G --tasks 8 run_train_single_model.sh ` will give the model 3 days to train\n",
    "you can view the progress of the training in MLflow\n",
    "\n",
    "An important thing to watch out for is that MLflow fails to handle work for large training sessions. In the case of this notebook, a training run which had reported the training loss over 300K times while still in a run and reporting more training loss values typically failed to handle the work of requesting the 300K loss values, this has a probability of crashing all the MLflow workers which will stop training with an exception when the loss values fail to be reported to a server without workers to accept the reported values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76742192-5f7d-469b-8345-e3f13d591f12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda-py-lightning-cbh Python (Conda)",
   "language": "python",
   "name": "conda-env-.conda-py-lightning-cbh-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
