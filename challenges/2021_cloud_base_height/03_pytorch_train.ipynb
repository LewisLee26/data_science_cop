{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6729aad1-261a-48fa-ae59-986428165ebd",
   "metadata": {},
   "source": [
    "# Training a neural network in PyTorch\n",
    "\n",
    "This notebook demonstrates training a classifier in PyTorch. In order to train a model, there are three main steps:\n",
    "1. Initialize the data and model\n",
    "1. Run the training loop\n",
    "1. Ensure training success with some small evaluation\n",
    "\n",
    "Training a model can be as simple as calling a model.fit() function on some modified data, however there are a number of desired qualities when it comes to model training that will be presented in this notebook: Reproducibility of the model, tracking of model training, and helping model generalization through data randomization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea2ebc23-4958-4cc3-8f6b-c30686f571eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pl ver: 1.7.7\n",
      "mlflow ver: 1.30.0\n",
      "torch ver: 1.12.1\n",
      "Python ver: sys.version_info(major=3, minor=10, micro=6, releaselevel='final', serial=0)\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "\n",
    "# file handling\n",
    "import os\n",
    "import pathlib\n",
    "import sys\n",
    "\n",
    "from pytorch_lightning.loggers import MLFlowLogger\n",
    "\n",
    "import dask\n",
    "import dask.array\n",
    "\n",
    "# math operators\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "# ml\n",
    "import torch\n",
    "import zarr\n",
    "\n",
    "import datetime\n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "# training helpers\n",
    "import mlflow.pytorch\n",
    "from dask.diagnostics import CacheProfiler, Profiler, ResourceProfiler, visualize\n",
    "from mlflow.tracking import MlflowClient\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "from pytorch_lightning.callbacks import (\n",
    "    RichProgressBar,\n",
    ")  # this progress bar works through jupyterHub on spice\n",
    "\n",
    "# defined in directory (model related definitions)\n",
    "import cbh_data_definitions\n",
    "# cbh_data_definitions.register_cache()\n",
    "import cbh_torch_lstm\n",
    "import cbh_torch_MLP\n",
    "\n",
    "print(\"pl ver:\", pl.__version__)\n",
    "print(\"mlflow ver:\", mlflow.__version__)\n",
    "print(\"torch ver:\", torch.__version__)\n",
    "print(\"Python ver:\", sys.version_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "508614de-9142-42df-811b-bba77c76bea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload packages to allow for ease of notebook updates\n",
    "RELOAD_PACKAGES = True\n",
    "if RELOAD_PACKAGES:\n",
    "    import importlib\n",
    "    importlib.reload(cbh_torch_lstm)\n",
    "    importlib.reload(cbh_torch_MLP)\n",
    "    importlib.reload(cbh_data_definitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2d53e4d-26b1-4d18-a0b7-3f7232f73063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# intialize some settings: mlflow, data directory, resources\n",
    "root_data_directory = pathlib.Path(os.environ[\"SCRATCH\"]) / \"cbh_data\"\n",
    "\n",
    "dev_data_path = root_data_directory / \"analysis_ready\" / \"dev_randomized.zarr\"\n",
    "training_data_path = root_data_directory / \"analysis_ready\" / \"train_randomized.zarr\"\n",
    "\n",
    "mlflow_command_line_run = \"\"\"\n",
    "    mlflow server --port 5001 --backend-store-uri sqlite:///mlflowSQLserver.db  --default-artifact-root ./mlflow_artifacts/\n",
    "\"\"\"\n",
    "alt_mlflow_command_line_run = \"\"\"\n",
    "mlflow server --port 5001 --backend-store-uri sqlite:////data/users/hsouth/mlflow/mlflowServer.db  --default-artifact-root /data/users/hsouth/mlflow/mlflow_artifacts --host 0.0.0.0\n",
    "\"\"\" # This command is used, as /data/ will not run out of storage quota like /home/ will with many runs\n",
    "mlflow_server_address = 'vld425'\n",
    "mlflow_server_port = 5001\n",
    "mlflow_server_uri = f'http://{mlflow_server_address}:{mlflow_server_port:d}'\n",
    "mlflow_artifact_root = pathlib.Path('/data/users/hsouth/mlflow/mlflow_artifacts')\n",
    "\n",
    "hparams_for_mlflow = {}\n",
    "\n",
    "CPU_COUNT = 6\n",
    "RAM_GB = 64\n",
    "hparams_for_mlflow['CPU Count'] = CPU_COUNT\n",
    "hparams_for_mlflow['Compute Memory'] = RAM_GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c96b79fe-a8c4-4026-a77f-39d048642745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded zarr, file information:\n",
      " Name              : /\n",
      "Type              : zarr.hierarchy.Group\n",
      "Read-only         : False\n",
      "Synchronizer type : zarr.sync.ThreadSynchronizer\n",
      "Store type        : zarr.storage.DirectoryStore\n",
      "No. members       : 2\n",
      "No. arrays        : 2\n",
      "No. groups        : 0\n",
      "Arrays            : cloud_base_label_y.zarr, humidity_temp_pressure_x.zarr\n",
      " \n",
      "\n",
      "Loaded zarr, file information:\n",
      " Name              : /\n",
      "Type              : zarr.hierarchy.Group\n",
      "Read-only         : False\n",
      "Synchronizer type : zarr.sync.ThreadSynchronizer\n",
      "Store type        : zarr.storage.DirectoryStore\n",
      "No. members       : 2\n",
      "No. arrays        : 2\n",
      "No. groups        : 0\n",
      "Arrays            : cloud_base_label_y.zarr, humidity_temp_pressure_x.zarr\n",
      " \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table>\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 87.48 GiB </td>\n",
       "                        <td> 1.82 GiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (111820800, 70, 3) </td>\n",
       "                        <td> (2329600, 70, 3) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Count </th>\n",
       "                        <td> 2 Graph Layers </td>\n",
       "                        <td> 48 Chunks </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                    <th> Type </th>\n",
       "                    <td> float32 </td>\n",
       "                    <td> numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"156\" height=\"146\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"80\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"10\" y1=\"25\" x2=\"80\" y2=\"96\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"10\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"12\" y1=\"2\" x2=\"12\" y2=\"28\" />\n",
       "  <line x1=\"17\" y1=\"7\" x2=\"17\" y2=\"32\" />\n",
       "  <line x1=\"20\" y1=\"10\" x2=\"20\" y2=\"35\" />\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"24\" y2=\"40\" />\n",
       "  <line x1=\"27\" y1=\"17\" x2=\"27\" y2=\"43\" />\n",
       "  <line x1=\"32\" y1=\"22\" x2=\"32\" y2=\"47\" />\n",
       "  <line x1=\"35\" y1=\"25\" x2=\"35\" y2=\"50\" />\n",
       "  <line x1=\"39\" y1=\"29\" x2=\"39\" y2=\"54\" />\n",
       "  <line x1=\"42\" y1=\"32\" x2=\"42\" y2=\"57\" />\n",
       "  <line x1=\"46\" y1=\"36\" x2=\"46\" y2=\"62\" />\n",
       "  <line x1=\"49\" y1=\"39\" x2=\"49\" y2=\"65\" />\n",
       "  <line x1=\"54\" y1=\"44\" x2=\"54\" y2=\"69\" />\n",
       "  <line x1=\"57\" y1=\"47\" x2=\"57\" y2=\"72\" />\n",
       "  <line x1=\"61\" y1=\"51\" x2=\"61\" y2=\"76\" />\n",
       "  <line x1=\"64\" y1=\"54\" x2=\"64\" y2=\"79\" />\n",
       "  <line x1=\"68\" y1=\"58\" x2=\"68\" y2=\"84\" />\n",
       "  <line x1=\"71\" y1=\"61\" x2=\"71\" y2=\"87\" />\n",
       "  <line x1=\"76\" y1=\"66\" x2=\"76\" y2=\"91\" />\n",
       "  <line x1=\"80\" y1=\"70\" x2=\"80\" y2=\"96\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 80.58823529411765,70.58823529411765 80.58823529411765,96.00085180870013 10.0,25.412616514582485\" style=\"fill:#8B4903A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"35\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"12\" y1=\"2\" x2=\"38\" y2=\"2\" />\n",
       "  <line x1=\"17\" y1=\"7\" x2=\"42\" y2=\"7\" />\n",
       "  <line x1=\"20\" y1=\"10\" x2=\"45\" y2=\"10\" />\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"50\" y2=\"14\" />\n",
       "  <line x1=\"27\" y1=\"17\" x2=\"53\" y2=\"17\" />\n",
       "  <line x1=\"32\" y1=\"22\" x2=\"57\" y2=\"22\" />\n",
       "  <line x1=\"35\" y1=\"25\" x2=\"60\" y2=\"25\" />\n",
       "  <line x1=\"39\" y1=\"29\" x2=\"64\" y2=\"29\" />\n",
       "  <line x1=\"42\" y1=\"32\" x2=\"67\" y2=\"32\" />\n",
       "  <line x1=\"46\" y1=\"36\" x2=\"72\" y2=\"36\" />\n",
       "  <line x1=\"49\" y1=\"39\" x2=\"75\" y2=\"39\" />\n",
       "  <line x1=\"54\" y1=\"44\" x2=\"79\" y2=\"44\" />\n",
       "  <line x1=\"57\" y1=\"47\" x2=\"82\" y2=\"47\" />\n",
       "  <line x1=\"61\" y1=\"51\" x2=\"86\" y2=\"51\" />\n",
       "  <line x1=\"64\" y1=\"54\" x2=\"89\" y2=\"54\" />\n",
       "  <line x1=\"68\" y1=\"58\" x2=\"94\" y2=\"58\" />\n",
       "  <line x1=\"71\" y1=\"61\" x2=\"97\" y2=\"61\" />\n",
       "  <line x1=\"76\" y1=\"66\" x2=\"101\" y2=\"66\" />\n",
       "  <line x1=\"80\" y1=\"70\" x2=\"106\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"80\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"35\" y1=\"0\" x2=\"106\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 35.41261651458248,0.0 106.00085180870013,70.58823529411765 80.58823529411765,70.58823529411765\" style=\"fill:#8B4903A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"80\" y1=\"70\" x2=\"106\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"80\" y1=\"96\" x2=\"106\" y2=\"96\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"80\" y1=\"70\" x2=\"80\" y2=\"96\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"106\" y1=\"70\" x2=\"106\" y2=\"96\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"80.58823529411765,70.58823529411765 106.00085180870013,70.58823529411765 106.00085180870013,96.00085180870013 80.58823529411765,96.00085180870013\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"93.294544\" y=\"116.000852\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >3</text>\n",
       "  <text x=\"126.000852\" y=\"83.294544\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(0,126.000852,83.294544)\">70</text>\n",
       "  <text x=\"35.294118\" y=\"80.706734\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(45,35.294118,80.706734)\">111820800</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<from-zarr, shape=(111820800, 70, 3), dtype=float32, chunksize=(2329600, 70, 3), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initialize data\n",
    "(\n",
    "    train_input,\n",
    "    train_labels,\n",
    "    _,\n",
    ") = cbh_data_definitions.load_data_from_zarr(training_data_path)\n",
    "\n",
    "(\n",
    "    dev_input, \n",
    "    dev_labels, \n",
    "    _\n",
    ") = cbh_data_definitions.load_data_from_zarr(dev_data_path)\n",
    "\n",
    "# the cloud volume is not needed for the task, so isn't saved on the load\n",
    "# show a chunk\n",
    "train_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c8b8915-497a-4d90-8ec2-971caa896dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings for data limiting (used for development e.g. faster training runs)\n",
    "LIMIT_DATA = False\n",
    "LIMIT_DATA_INT = -1\n",
    "if LIMIT_DATA:\n",
    "    LIMIT_DATA_INT = 10024\n",
    "    train_input = train_input[:LIMIT_DATA_INT]\n",
    "    train_labels = train_labels[:LIMIT_DATA_INT]\n",
    "    # train_cloud_volume = train_cloud_volume[:LIMIT_DATA_INT]\n",
    "    dev_input = dev_input[:LIMIT_DATA_INT]\n",
    "    dev_labels = dev_labels[:LIMIT_DATA_INT]\n",
    "    # dev_cloud_volume = dev_cloud_volume[:LIMIT_DATA_INT]\n",
    "hparams_for_mlflow['Limited sample number'] =  LIMIT_DATA_INT  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffba27b-d62f-4bcd-8132-e668c3479e3b",
   "metadata": {},
   "source": [
    "In order to make machine learning reproducible, hyperparameters will be logged using MLflow so that models can be redefined exactly as they were, and a seed for our random functions e.g. random shuffling of data: The random seed ensures that the same \"random\" shuffle of the data is performed each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b83e7351-b657-4e9b-8997-2d4022f8b5e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "# reproducibility with seed everything\n",
    "seed_everything_int = 42\n",
    "seed_everything(seed_everything_int)\n",
    "hparams_for_mlflow['Random seed'] = seed_everything_int"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0ab5c4-12e5-48cb-a947-f4f70a0e520e",
   "metadata": {},
   "source": [
    "## Perform the network initialization and training\n",
    "\n",
    "for each different model architecture, various different hyperparameters must be defined. For example in the case of an LSTM, bi-directionality is a simple to implement extension to the model type as this is a parameter of the layer definition in pytorch so can be included in the LSTM hyperparameter definition, there is no concept of input sequence direction in a simple MLP, so this hyperparameter doesn't apply \n",
    "\n",
    "training related hyperparameters are also defined. It is important to track exactly how much training is performed (epoch and step), the batch size, the learning rate and the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66118c9f-b5e5-447f-a4af-0e2fc7445238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.89052188e+04, 2.43972824e+02, 1.78724772e-03])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_l_p_f_m = np.load(\"./per_level_per_feat_mean.npz\")\n",
    "p_l_p_f_s = np.load(\"./per_level_per_feat_std.npz\")\n",
    "p_f_m = np.load(\"./per_feat_mean.npz\")\n",
    "p_f_s = np.load(\"./per_feat_std.npz\")\n",
    "p_l_p_f_s += 5.0e-12 # prevent divide by 0\n",
    "p_f_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ce919a8-22f0-46c1-a895-6b7c07ccdba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data chunk size: 2329600\n",
      "Factors of chunk:  [1, 2, 4, 5, 7, 8, 10, 13, 14, 16, 20, 25, 26, 28, 32, 35, 40, 50, 52, 56, 64, 65, 70, 80, 91, 100, 104, 112, 128, 130, 140, 160, 175, 182, 200, 208, 224, 256, 260, 280, 320, 325, 350, 364, 400, 416, 448, 455, 512, 520, 560, 640, 650, 700, 728, 800, 832, 896, 910, 1024, 1040, 1120, 1280, 1300, 1400, 1456, 1600, 1664, 1792, 1820, 2080, 2240, 2275, 2560, 2600, 2800, 2912, 3200, 3328, 3584, 3640, 4160, 4480, 4550, 5120, 5200, 5600, 5824, 6400, 6656, 7168, 7280, 8320, 8960, 9100, 10400, 11200, 11648, 12800, 13312, 14560, 16640, 17920, 18200, 20800, 22400, 23296, 25600, 29120, 33280, 35840, 36400, 41600, 44800, 46592, 58240, 66560, 72800, 83200, 89600, 93184, 116480, 145600, 166400, 179200, 232960, 291200, 332800, 465920, 582400, 1164800, 2329600]\n"
     ]
    }
   ],
   "source": [
    "# define model and hyperparameters\n",
    "mlp_layernum = 3             \n",
    "model_hyperparameter_dictionary = {\n",
    "    \"LSTM\": {\n",
    "        \"input_size\": train_input.shape[2],  # input size is the cell input (feat dim)\n",
    "        \"lstm_layers\": 2,\n",
    "        \"lstm_hidden_size\": 100,\n",
    "        \"output_size\": 100,  # for each height layer, predict one value for cloud base prob\n",
    "        \"height_dimension\": train_input.shape[1],\n",
    "        \"embed_size\": 20,\n",
    "        \"BILSTM\": True,\n",
    "        \"batch_first\": True,\n",
    "        \"skip_connection\":True,\n",
    "        \"backward_lstm_differing_transitions\":False,\n",
    "        \"lr\": 0.001460,\n",
    "        \"norm_mat_mean\":torch.from_numpy(p_l_p_f_m.astype(np.float32)), \n",
    "        \"norm_mat_std\":torch.from_numpy(p_l_p_f_s.astype(np.float32)),\n",
    "        \"norm_method\":\"p_l_p_f\",\n",
    "        \"linear_instead_of_conv_cap\":True,\n",
    "    },\n",
    "    \"MLP\": {\n",
    "        \"input_size\": train_input.shape[2] * train_input.shape[1],\n",
    "        \"ff_nodes\": mlp_layernum * [256],\n",
    "        \"output_size\": train_input.shape[1],\n",
    "        \"lr\": 1.0e-3,\n",
    "        \"activation\": \"relu\",\n",
    "        \"layer_num\": mlp_layernum,\n",
    "        \"norm_mat_mean\":torch.from_numpy(p_l_p_f_m.astype(np.float32)), \n",
    "        \"norm_mat_std\":torch.from_numpy(p_l_p_f_s.astype(np.float32)),\n",
    "        \"norm_method\":\"p_l_p_f\",\n",
    "    },\n",
    "}\n",
    "\n",
    "model_definition_dictionary = {\n",
    "    \"LSTM\": cbh_torch_lstm.CloudBaseLSTM(**model_hyperparameter_dictionary[\"LSTM\"]),\n",
    "    \"MLP\": cbh_torch_MLP.CloudBaseMLP(**model_hyperparameter_dictionary[\"MLP\"]),\n",
    "}\n",
    "model_picked = \"LSTM\"\n",
    "model = model_definition_dictionary[model_picked]  # pick a model\n",
    "hparams_for_mlflow[\"Model defined hparams\"] = model_hyperparameter_dictionary[model_picked]\n",
    "\n",
    "\n",
    "# define training related hyperparameters\n",
    "\n",
    "epochs = 1\n",
    "hparams_for_mlflow[\"Max epochs\"] = epochs\n",
    "collate_fn = cbh_data_definitions.dataloader_collate_with_dask\n",
    "print(\"Data chunk size:\", train_input.chunksize[0])\n",
    "print(\"Factors of chunk: \", [n for n in range(1, train_input.chunksize[0] + 1) if train_input.chunksize[0] % n == 0])\n",
    "batch_size = 100\n",
    "hparams_for_mlflow[\"Batch size\"] = batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09b8445-1600-4674-9f08-3ab87c08bcfd",
   "metadata": {},
   "source": [
    "The pytorch dataloader is also initialized, usually the dataloader does not change the outcome of ML training, however in our case there are multiple strategies for batch selection implemented, so tracking these settings are important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adc82bd5-20a8-4072-a266-4c162e41ed41",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader = None, None\n",
    "\n",
    "single_proc_workers = True # False causes crashes in some cases or in the case of 1 chunk at a time, makes data access slower\n",
    "if single_proc_workers:\n",
    "    WORKERS_CPU_COUNT=0\n",
    "else:\n",
    "    WORKERS_CPU_COUNT = CPU_COUNT\n",
    "\n",
    "data_loader_hparam_dict = {\n",
    "    'batch_size':batch_size,\n",
    "    'num_workers':WORKERS_CPU_COUNT,\n",
    "    # 'pin_memory':False,\n",
    "    'collate_fn':None, # using 1chunk method\n",
    "    'thread_count_for_dask':CPU_COUNT,\n",
    "    'method':'1chunk',\n",
    "}\n",
    "shuffle_training_data=False,\n",
    "\n",
    "datamodule = cbh_data_definitions.CBH_DataModule(\n",
    "        train_input, train_labels,\n",
    "        dev_input, dev_labels,\n",
    "        **data_loader_hparam_dict,\n",
    "        randomize_chunkwise = True,\n",
    "        \n",
    "    )\n",
    "data_loader_hparam_dict['shuffle_training_data']=shuffle_training_data\n",
    "hparams_for_mlflow['data loader hparams'] = data_loader_hparam_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53ceb9d-9a31-4b3c-9dbe-ffb7cbda4d15",
   "metadata": {},
   "source": [
    "Next we initialize an MLflow experiement, MLflow serves to share model training information in collaboration, allow for monitoring of current training processes, and tracking of hyperparameters + models + metrics for reproducing saving and loading training experiements. The MLflow server is launched from the command line, and connected to through the below cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39551462-62c9-4181-a41b-640463f4196c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating experiment\n"
     ]
    }
   ],
   "source": [
    "experiment_name = 'cbh-label-model-runs'\n",
    "# experiment_name = 'test-setup-for-model-runs'\n",
    "\n",
    "# torch.set_num_threads(CPU_COUNT)\n",
    "\n",
    "mlflow.set_tracking_uri(mlflow_server_uri)\n",
    "# make vars global\n",
    "mlf_exp = None\n",
    "mlf_exp_id = None\n",
    "try: \n",
    "    print('Creating experiment')\n",
    "    mlf_exp_id = mlflow.create_experiment(experiment_name)\n",
    "    mlf_exp = mlflow.get_experiment(mlf_exp_id)\n",
    "except mlflow.exceptions.RestException:\n",
    "    mlf_exp = mlflow.get_experiment_by_name(experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9fbe59-be67-4309-8369-33245ae25fef",
   "metadata": {},
   "source": [
    "Autologging of the experiement did not work in this implementation, the best guess as to why is due to dasks lock on the data which prevents saving model weights, or displaying model attributes in some cases which autologging uses. To circumvent this, a custom checkpointing function is implemented into the PyTorch-Lighning's implementation for logging to MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21185156-4866-4d28-8c57-f036993f8170",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLFlowLogger(pl.loggers.MLFlowLogger): #overwrite mlflogger\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def after_save_checkpoint(self, model_checkpoint: pl.callbacks.ModelCheckpoint) -> None:\n",
    "        \"\"\"\n",
    "        Called after model checkpoint callback saves a new checkpoint.\n",
    "        \"\"\"\n",
    "        best_chkpt = torch.load(model_checkpoint.best_model_path)\n",
    "        # print(best_chkpt)\n",
    "        # print(best_chkpt['callbacks'])\n",
    "        checkpoint_for_mlflow = {\n",
    "            \"val loss\": float(best_chkpt['callbacks'][list(key for key in list(best_chkpt['callbacks'].keys()) if \"ModelCheckpoint\" in key)[0]]['current_score']),\n",
    "            # \"train loss at step-1\": list(train_loss_metric.value for train_loss_metric in self._mlflow_client.get_metric_history(run.info.run_id, \"Train loss\") if (int(train_loss_metric.step) == int(best_chkpt['global_step']-1)))[0],\n",
    "            \"global_step\": best_chkpt['global_step'],\n",
    "            \"model_state_dict\": best_chkpt['state_dict'],\n",
    "            \"checkpoint\": best_chkpt,\n",
    "\n",
    "        }\n",
    "        with TemporaryDirectory() as tmpdirname:\n",
    "            f_name = os.path.join(tmpdirname, f\"{datetime.datetime.now()}best_model_checkpoint-step_{best_chkpt['global_step']}.pt\")\n",
    "            torch.save(checkpoint_for_mlflow, f_name)\n",
    "            mlflow.log_artifact(f_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bc69ee-249e-4e53-8187-58269595c44d",
   "metadata": {},
   "source": [
    "Here the training is run, but not before some more model settings:timeout for training, naming of the MLflow experiement, defining when to validate, how to report progress in the notebook, and defining when to save a model. After training is run, another copy of the model is saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "959986bc-8f6a-46c5-a538-21ee2c81de7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c2dade6-a531-43b9-a88c-dcfb92937ab0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Epoch 0/0 </span> <span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">18875/1133008</span> <span style=\"color: #8a8a8a; text-decoration-color: #8a8a8a\">2:45:17 • 6 days, 14:08:51</span> <span style=\"color: #b2b2b2; text-decoration-color: #b2b2b2\">1.96it/s</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">loss: 1.02 v_num: f9d6 </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[37mEpoch 0/0 \u001b[0m \u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[37m18875/1133008\u001b[0m \u001b[38;5;245m2:45:17 • 6 days, 14:08:51\u001b[0m \u001b[38;5;249m1.96it/s\u001b[0m \u001b[37mloss: 1.02 v_num: f9d6 \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/12/02 16:56:37 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during pytorch autologging: cannot pickle '_thread.RLock' object\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ended run 6063389151104ea7afdd046d15ccf9d6\n"
     ]
    }
   ],
   "source": [
    "max_time = \"00:03:00:00\"  # dd:hh:mm:ss\n",
    "\n",
    "hparams_for_mlflow[\"Training timeout\"] = max_time\n",
    "\n",
    "timestamp_template = '{dt.year:04d}{dt.month:02d}{dt.day:02d}T{dt.hour:02d}{dt.minute:02d}{dt.second:02d}'\n",
    "run_name_template = 'cbh_challenge_{network_name}_' + timestamp_template\n",
    "current_run_name = run_name_template.format(network_name=model.__class__.__name__,\n",
    "                                                dt=datetime.datetime.now()\n",
    "                                               )\n",
    "\n",
    "# with Profiler() as prof, ResourceProfiler(dt=0.25) as rprof, CacheProfiler() as cprof:\n",
    "with mlflow.start_run(experiment_id=mlf_exp.experiment_id, run_name=current_run_name) as run:\n",
    "\n",
    "    mlflow.pytorch.autolog()\n",
    "    mlf_logger = MLFlowLogger(experiment_name=experiment_name, tracking_uri=mlflow_server_uri, run_id=run.info.run_id)\n",
    "\n",
    "\n",
    "    # define trainer\n",
    "    time_for_checkpoint = datetime.timedelta(minutes=15)\n",
    "    checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "        train_time_interval=time_for_checkpoint,\n",
    "        dirpath=run.info.artifact_uri,\n",
    "        monitor=\"Val loss\",\n",
    "        save_on_train_epoch_end=False,\n",
    "        mode=\"min\"\n",
    "    )\n",
    "    callbacks = [checkpoint_callback, RichProgressBar()]\n",
    "    trainer_hparams = {\n",
    "        'max_epochs':epochs,\n",
    "        'deterministic':True,\n",
    "        'val_check_interval':0.01, # val every percentage of the data\n",
    "        'devices':\"auto\",\n",
    "        'accelerator':\"auto\",\n",
    "        'max_time':max_time,\n",
    "        'replace_sampler_ddp':False,\n",
    "        'enable_checkpointing':True,\n",
    "        'strategy':None,\n",
    "        'callbacks':callbacks,\n",
    "        'logger':mlf_logger,\n",
    "    }\n",
    "    hparams_for_mlflow[\"Trainer hparams\"] = trainer_hparams\n",
    "    mlf_logger.log_hyperparams(hparams_for_mlflow)\n",
    "    trainer = pl.Trainer(\n",
    "        **trainer_hparams\n",
    "    )\n",
    "    \n",
    "    \n",
    "    trainer.fit(model=model, datamodule=datamodule)\n",
    "    path_to_save = '{dt.year:04d}{dt.month:02d}{dt.day:02d}-{dt.hour:02d}{dt.minute:02d}{dt.second:02d}'.format(dt=datetime.datetime.now())\n",
    "    trainer.save_checkpoint(filepath=run.info.artifact_uri + f'/post_epoch_modelchkpt_{path_to_save}')\n",
    "    with TemporaryDirectory() as tmpdirname:\n",
    "            f_name = os.path.join(tmpdirname, f\"{run.info.run_id}-post_epoch_checkpoint_logged.pt\")\n",
    "            trainer.save_checkpoint(filepath=f_name)\n",
    "            mlflow.log_artifact(f_name)\n",
    "print(\"Ended run\", run.info.run_id)\n",
    "    # print(visualize([prof, rprof, cprof], filename='profile_loop.html', save=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba52d2c-1212-4894-ad05-3a9f7761ccf2",
   "metadata": {},
   "source": [
    "## Display and evaluate results\n",
    "\n",
    "After training, explore some of the results from our model. tracking of experiment progress can be done during training, but it is a good idea to get an idea of final performance, or quickly investigate aspects of the model which cannot be monitored during training such as class imbalance of predictions. More ensurement of properties of the training can also be performed in this section, such as recalling MLflow variables in order to double check correct logging functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "888b7d7e-5158-42a9-b3f2-046dca3a218c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_id: 6063389151104ea7afdd046d15ccf9d6\n",
      "artifacts: []\n",
      "params: {}\n",
      "metrics: {}\n",
      "tags: {}\n"
     ]
    }
   ],
   "source": [
    "def print_auto_logged_info(r):\n",
    "\n",
    "    tags = {k: v for k, v in r.data.tags.items() if not k.startswith(\"mlflow.\")}\n",
    "    artifacts = [f.path for f in MlflowClient().list_artifacts(r.info.run_id, \"model\")]\n",
    "    print(\"run_id: {}\".format(r.info.run_id))\n",
    "    print(\"artifacts: {}\".format(artifacts))\n",
    "    print(\"params: {}\".format(r.data.params))\n",
    "    print(\"metrics: {}\".format(r.data.metrics))\n",
    "    print(\"tags: {}\".format(tags))\n",
    "print_auto_logged_info(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ce386db-e33d-42aa-90ff-8a4a4dd3be76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 70]) prediction output\n",
      "(100,) prediction label shape\n",
      "(100,) targ shape\n",
      "Correct samples: 59\n",
      "Total samples tested: 100\n",
      "Accuracy: 59.0 %\n",
      "Model predictions binned: (Class labels), (Counts): (array([ 0,  2,  3,  5,  6,  7,  9, 10, 11, 12, 13, 14, 16, 18, 22, 24, 32,\n",
      "       33, 34, 35, 36, 38, 40, 41, 42, 43, 44, 69]), array([28,  3,  6,  1,  6,  2,  1,  1,  3,  2,  3,  3,  2,  1,  1,  1,  1,\n",
      "        1,  2,  1,  1,  1,  1,  1,  3,  1,  1, 22]))\n",
      "Model targets binned: (Class labels), (Counts): (array([ 0,  2,  3,  4,  5,  6,  7,  9, 10, 11, 12, 13, 14, 15, 16, 18, 20,\n",
      "       24, 32, 33, 34, 35, 36, 38, 40, 42, 43, 44, 46, 69]), array([18,  3,  4,  3,  2,  3,  3,  1,  1,  3,  3,  4,  2,  3,  1,  1,  1,\n",
      "        3,  2,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, 29]))\n"
     ]
    }
   ],
   "source": [
    "# test model functionality through outputs on a batch of independent data\n",
    "example_batch = next(iter(datamodule.train_dataloader()))\n",
    "inputs = example_batch[0]\n",
    "try:\n",
    "    preds, _ = model(inputs, heights)\n",
    "except:\n",
    "    if model_picked == \"LSTM\":\n",
    "        inputs = example_batch[0]\n",
    "    else:     \n",
    "        print(example_batch[0].shape, \"inp pre-flat\")\n",
    "        inputs = torch.flatten(example_batch[0], start_dim=1)\n",
    "    preds = model(inputs)\n",
    "print(preds.shape, \"prediction output\")\n",
    "pred_label = np.argmax(preds.detach().numpy(), axis=1)\n",
    "print(pred_label.shape, \"prediction label shape\")\n",
    "targs = example_batch[1]\n",
    "targs = np.array(targs)\n",
    "print(targs.shape, \"targ shape\")\n",
    "correct = targs == pred_label\n",
    "print(\"Correct samples:\", np.count_nonzero(correct))\n",
    "print(\"Total samples tested:\", len(correct))\n",
    "print(\"Accuracy:\", (np.count_nonzero(correct) / len(correct) * 100), \"%\")\n",
    "print(\n",
    "    \"Model predictions binned: (Class labels), (Counts):\",\n",
    "    np.unique(pred_label, return_counts=True),\n",
    ")\n",
    "print(\n",
    "    \"Model targets binned: (Class labels), (Counts):\",\n",
    "    np.unique(targs, return_counts=True),\n",
    ")\n",
    "eg_batch_metrics = {\n",
    "    \"Correct samples\" : np.count_nonzero(correct),\n",
    "    \"Total samples tested\" : len(correct),\n",
    "    \"Accuracy\" : (np.count_nonzero(correct) / len(correct) * 100),\n",
    "\n",
    "    \"Model predictions binned: (Class labels), (Counts)\"\n",
    "     : str(np.unique(pred_label, return_counts=True)),\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab5a6d3a-5b0b-4fe5-b6d3-664fa93f6498",
   "metadata": {},
   "outputs": [],
   "source": [
    "eg_batch_metrics = {\n",
    "    \"Single batch example validation metrics/Correct samples\" : np.count_nonzero(correct),\n",
    "    \"Single batch example validation metrics/Total samples tested\" : len(correct),\n",
    "    \"Single batch example validation metrics/Accuracy\" : np.count_nonzero(correct) / len(correct) * 100,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b42f978-4908-4d20-95e4-b2d7adf48bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlf_logger.log_metrics(eg_batch_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c108cb0a-4886-40ac-8ab8-af913c5d3b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_id: 6063389151104ea7afdd046d15ccf9d6\n",
      "artifacts: []\n",
      "params: {'CPU Count': '6', 'Compute Memory': '64', 'Limited sample number': '-1', 'Random seed': '42', 'Model defined hparams/input_size': '3', 'Model defined hparams/lstm_layers': '2', 'Model defined hparams/lstm_hidden_size': '100', 'Model defined hparams/output_size': '100', 'Model defined hparams/height_dimension': '70', 'Model defined hparams/embed_size': '20', 'Model defined hparams/BILSTM': 'True', 'Model defined hparams/batch_first': 'True', 'Model defined hparams/skip_connection': 'True', 'Model defined hparams/backward_lstm_differing_transitions': 'False', 'Model defined hparams/lr': '0.00146', 'Model defined hparams/norm_method': 'p_l_p_f', 'Model defined hparams/linear_instead_of_conv_cap': 'True', 'Max epochs': '1', 'Batch size': '100', 'data loader hparams/batch_size': '100', 'data loader hparams/num_workers': '0', 'data loader hparams/collate_fn': 'None', 'data loader hparams/thread_count_for_dask': '6', 'data loader hparams/method': '1chunk', 'data loader hparams/shuffle_training_data': '(False,)', 'Training timeout': '00:03:00:00', 'Trainer hparams/max_epochs': '1', 'Trainer hparams/deterministic': 'True', 'Trainer hparams/val_check_interval': '0.01', 'Trainer hparams/devices': 'auto', 'Trainer hparams/accelerator': 'auto', 'Trainer hparams/max_time': '00:03:00:00', 'Trainer hparams/replace_sampler_ddp': 'False', 'Trainer hparams/enable_checkpointing': 'True', 'Trainer hparams/strategy': 'None', 'Trainer hparams/callbacks': '[<pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint object at 0x2ba410aa31f0>, <pytorch_lightning.callbacks.progress.rich_progress.RichProgressBar object at 0x2ba410aa32e0>]', 'Trainer hparams/logger': '<__main__.MLFlowLogger object at 0x2ba410279ab0>', 'input_size': '3', 'lstm_layers': '2', 'lstm_hidden_size': '100', 'output_size': '100', 'height_dimension': '70', 'embed_size': '20', 'BILSTM': 'True', 'backward_lstm_differing_transitions': 'False', 'batch_first': 'True', 'lr': '0.00146', 'skip_connection': 'True', 'norm_method': 'p_l_p_f', 'linear_instead_of_conv_cap': 'True', 'conv_cap_window': '5', 'epochs': '1', 'optimizer_name': 'Adam', 'betas': '(0.9, 0.999)', 'eps': '1e-08', 'weight_decay': '0', 'amsgrad': 'False', 'maximize': 'False', 'foreach': 'None', 'capturable': 'False'}\n",
      "metrics: {'Val loss': 1.1445627212524414, 'val_loss_mean': 1.1743098497390747, 'Train loss': 0.8445764183998108, 'epoch': 0.0, 'Single batch example validation metrics/Correct samples': 59.0, 'Single batch example validation metrics/Total samples tested': 100.0, 'Single batch example validation metrics/Accuracy': 59.0}\n",
      "tags: {'Mode': 'training'}\n"
     ]
    }
   ],
   "source": [
    "# display mlflow output\n",
    "print_auto_logged_info(mlflow.get_run(run_id=run.info.run_id))\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59c42a7-5d05-4686-aaff-7bdee4dcc7a0",
   "metadata": {},
   "source": [
    "Models may be developed on this notebook, though longer training time is desirable when it comes to producing a final result, post hyper parameter tuning. In order to do this, the notebook can be converted to a script with\n",
    "`jupyter nbconvert --to script 03_pytorch_train.ipynb`\n",
    "once converted, update the values of some of the variables to match the longer training time, e.g. max time should be increased to sometime soon before the time on SPICE (leaving some room for the model to end its current training step, save out, and give some initial evaluation). and CPUs might be increased for a non-test run of the model.\n",
    "\n",
    "afterward you can submit the py file to sbatch with a shell script (.sh)\n",
    "```\n",
    "#!/bin/bash -l\n",
    "conda activate py-lightning\n",
    "python 03_pytorch_train.py\n",
    "\n",
    "```\n",
    "\n",
    "e.g. `sbatch --qos=long --time=4319 --mem=64G --tasks 8 run_train_single_model.sh ` will give the model 3 days to train\n",
    "you can view the progress of the training in MLflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff0e5a0-c62f-4dfb-a12c-9883b4af04d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda-py-lightning Python (Conda)",
   "language": "python",
   "name": "conda-env-.conda-py-lightning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
