{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6729aad1-261a-48fa-ae59-986428165ebd",
   "metadata": {},
   "source": [
    "# Training a neural network in PyTorch\n",
    "\n",
    "This notebook demonstrates training a classifier in PyTorch. In order to train a model, there are three main steps:\n",
    "1. Initialize the data and model\n",
    "1. Run the training loop\n",
    "1. Ensure training success with some small evaluation\n",
    "\n",
    "Training a model can be as simple as calling a model.fit() function on some modified data, however there are a number of desired qualities when it comes to model training that will be presented in this notebook: Reproducibility of the model, tracking of model training, and helping model generalization through data randomization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea2ebc23-4958-4cc3-8f6b-c30686f571eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pl ver: 1.7.7\n",
      "mlflow ver: 1.30.0\n",
      "torch ver: 1.12.1\n",
      "Python ver: sys.version_info(major=3, minor=10, micro=6, releaselevel='final', serial=0)\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "\n",
    "# file handling\n",
    "import os\n",
    "import pathlib\n",
    "import sys\n",
    "\n",
    "from pytorch_lightning.loggers import MLFlowLogger\n",
    "\n",
    "import dask\n",
    "import dask.array\n",
    "\n",
    "# math operators\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "# ml\n",
    "import torch\n",
    "import zarr\n",
    "\n",
    "import datetime\n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "# training helpers\n",
    "import mlflow.pytorch\n",
    "from dask.diagnostics import CacheProfiler, Profiler, ResourceProfiler, visualize\n",
    "from mlflow.tracking import MlflowClient\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "from pytorch_lightning.callbacks import (\n",
    "    RichProgressBar,\n",
    ")  # this progress bar works through jupyterHub on spice\n",
    "\n",
    "# defined in directory (model related definitions)\n",
    "import cbh_data_definitions\n",
    "# cbh_data_definitions.register_cache()\n",
    "import cbh_torch_lstm\n",
    "import cbh_torch_MLP\n",
    "\n",
    "print(\"pl ver:\", pl.__version__)\n",
    "print(\"mlflow ver:\", mlflow.__version__)\n",
    "print(\"torch ver:\", torch.__version__)\n",
    "print(\"Python ver:\", sys.version_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "508614de-9142-42df-811b-bba77c76bea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload packages to allow for ease of notebook updates\n",
    "RELOAD_PACKAGES = True\n",
    "if RELOAD_PACKAGES:\n",
    "    import importlib\n",
    "    importlib.reload(cbh_torch_lstm)\n",
    "    importlib.reload(cbh_torch_MLP)\n",
    "    importlib.reload(cbh_data_definitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2d53e4d-26b1-4d18-a0b7-3f7232f73063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# intialize some settings: mlflow, data directory, resources\n",
    "root_data_directory = pathlib.Path(os.environ[\"SCRATCH\"]) / \"cbh_data\"\n",
    "\n",
    "dev_data_path = root_data_directory / \"analysis_ready\" / \"dev_randomized.zarr\"\n",
    "training_data_path = root_data_directory / \"analysis_ready\" / \"train_randomized.zarr\"\n",
    "\n",
    "mlflow_command_line_run = \"\"\"\n",
    "    mlflow server --port 5001 --backend-store-uri sqlite:///mlflowSQLserver.db  --default-artifact-root ./mlflow_artifacts/\n",
    "\"\"\"\n",
    "alt_mlflow_command_line_run = \"\"\"\n",
    "mlflow server --port 5001 --backend-store-uri sqlite:////data/users/hsouth/mlflow/mlflowServer.db  --default-artifact-root /data/users/hsouth/mlflow/mlflow_artifacts --host 0.0.0.0\n",
    "\"\"\" # This command is used, as /data/ will not run out of storage quota like /home/ will with many runs\n",
    "mlflow_server_address = 'vld425'\n",
    "mlflow_server_port = 5001\n",
    "mlflow_server_uri = f'http://{mlflow_server_address}:{mlflow_server_port:d}'\n",
    "mlflow_artifact_root = pathlib.Path('/data/users/hsouth/mlflow/mlflow_artifacts')\n",
    "\n",
    "hparams_for_mlflow = {}\n",
    "\n",
    "CPU_COUNT = 12\n",
    "RAM_GB = 64\n",
    "hparams_for_mlflow['CPU Count'] = CPU_COUNT\n",
    "hparams_for_mlflow['Compute Memory'] = RAM_GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c96b79fe-a8c4-4026-a77f-39d048642745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded zarr, file information:\n",
      " Name              : /\n",
      "Type              : zarr.hierarchy.Group\n",
      "Read-only         : False\n",
      "Synchronizer type : zarr.sync.ThreadSynchronizer\n",
      "Store type        : zarr.storage.DirectoryStore\n",
      "No. members       : 2\n",
      "No. arrays        : 2\n",
      "No. groups        : 0\n",
      "Arrays            : cloud_base_label_y.zarr, humidity_temp_pressure_x.zarr\n",
      " \n",
      "\n",
      "Loaded zarr, file information:\n",
      " Name              : /\n",
      "Type              : zarr.hierarchy.Group\n",
      "Read-only         : False\n",
      "Synchronizer type : zarr.sync.ThreadSynchronizer\n",
      "Store type        : zarr.storage.DirectoryStore\n",
      "No. members       : 2\n",
      "No. arrays        : 2\n",
      "No. groups        : 0\n",
      "Arrays            : cloud_base_label_y.zarr, humidity_temp_pressure_x.zarr\n",
      " \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table>\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 87.48 GiB </td>\n",
       "                        <td> 1.82 GiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (111820800, 70, 3) </td>\n",
       "                        <td> (2329600, 70, 3) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Count </th>\n",
       "                        <td> 2 Graph Layers </td>\n",
       "                        <td> 48 Chunks </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                    <th> Type </th>\n",
       "                    <td> float32 </td>\n",
       "                    <td> numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"156\" height=\"146\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"80\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"10\" y1=\"25\" x2=\"80\" y2=\"96\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"10\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"12\" y1=\"2\" x2=\"12\" y2=\"28\" />\n",
       "  <line x1=\"17\" y1=\"7\" x2=\"17\" y2=\"32\" />\n",
       "  <line x1=\"20\" y1=\"10\" x2=\"20\" y2=\"35\" />\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"24\" y2=\"40\" />\n",
       "  <line x1=\"27\" y1=\"17\" x2=\"27\" y2=\"43\" />\n",
       "  <line x1=\"32\" y1=\"22\" x2=\"32\" y2=\"47\" />\n",
       "  <line x1=\"35\" y1=\"25\" x2=\"35\" y2=\"50\" />\n",
       "  <line x1=\"39\" y1=\"29\" x2=\"39\" y2=\"54\" />\n",
       "  <line x1=\"42\" y1=\"32\" x2=\"42\" y2=\"57\" />\n",
       "  <line x1=\"46\" y1=\"36\" x2=\"46\" y2=\"62\" />\n",
       "  <line x1=\"49\" y1=\"39\" x2=\"49\" y2=\"65\" />\n",
       "  <line x1=\"54\" y1=\"44\" x2=\"54\" y2=\"69\" />\n",
       "  <line x1=\"57\" y1=\"47\" x2=\"57\" y2=\"72\" />\n",
       "  <line x1=\"61\" y1=\"51\" x2=\"61\" y2=\"76\" />\n",
       "  <line x1=\"64\" y1=\"54\" x2=\"64\" y2=\"79\" />\n",
       "  <line x1=\"68\" y1=\"58\" x2=\"68\" y2=\"84\" />\n",
       "  <line x1=\"71\" y1=\"61\" x2=\"71\" y2=\"87\" />\n",
       "  <line x1=\"76\" y1=\"66\" x2=\"76\" y2=\"91\" />\n",
       "  <line x1=\"80\" y1=\"70\" x2=\"80\" y2=\"96\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 80.58823529411765,70.58823529411765 80.58823529411765,96.00085180870013 10.0,25.412616514582485\" style=\"fill:#8B4903A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"35\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"12\" y1=\"2\" x2=\"38\" y2=\"2\" />\n",
       "  <line x1=\"17\" y1=\"7\" x2=\"42\" y2=\"7\" />\n",
       "  <line x1=\"20\" y1=\"10\" x2=\"45\" y2=\"10\" />\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"50\" y2=\"14\" />\n",
       "  <line x1=\"27\" y1=\"17\" x2=\"53\" y2=\"17\" />\n",
       "  <line x1=\"32\" y1=\"22\" x2=\"57\" y2=\"22\" />\n",
       "  <line x1=\"35\" y1=\"25\" x2=\"60\" y2=\"25\" />\n",
       "  <line x1=\"39\" y1=\"29\" x2=\"64\" y2=\"29\" />\n",
       "  <line x1=\"42\" y1=\"32\" x2=\"67\" y2=\"32\" />\n",
       "  <line x1=\"46\" y1=\"36\" x2=\"72\" y2=\"36\" />\n",
       "  <line x1=\"49\" y1=\"39\" x2=\"75\" y2=\"39\" />\n",
       "  <line x1=\"54\" y1=\"44\" x2=\"79\" y2=\"44\" />\n",
       "  <line x1=\"57\" y1=\"47\" x2=\"82\" y2=\"47\" />\n",
       "  <line x1=\"61\" y1=\"51\" x2=\"86\" y2=\"51\" />\n",
       "  <line x1=\"64\" y1=\"54\" x2=\"89\" y2=\"54\" />\n",
       "  <line x1=\"68\" y1=\"58\" x2=\"94\" y2=\"58\" />\n",
       "  <line x1=\"71\" y1=\"61\" x2=\"97\" y2=\"61\" />\n",
       "  <line x1=\"76\" y1=\"66\" x2=\"101\" y2=\"66\" />\n",
       "  <line x1=\"80\" y1=\"70\" x2=\"106\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"80\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"35\" y1=\"0\" x2=\"106\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 35.41261651458248,0.0 106.00085180870013,70.58823529411765 80.58823529411765,70.58823529411765\" style=\"fill:#8B4903A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"80\" y1=\"70\" x2=\"106\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"80\" y1=\"96\" x2=\"106\" y2=\"96\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"80\" y1=\"70\" x2=\"80\" y2=\"96\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"106\" y1=\"70\" x2=\"106\" y2=\"96\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"80.58823529411765,70.58823529411765 106.00085180870013,70.58823529411765 106.00085180870013,96.00085180870013 80.58823529411765,96.00085180870013\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"93.294544\" y=\"116.000852\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >3</text>\n",
       "  <text x=\"126.000852\" y=\"83.294544\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(0,126.000852,83.294544)\">70</text>\n",
       "  <text x=\"35.294118\" y=\"80.706734\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(45,35.294118,80.706734)\">111820800</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<from-zarr, shape=(111820800, 70, 3), dtype=float32, chunksize=(2329600, 70, 3), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initialize data\n",
    "(\n",
    "    train_input,\n",
    "    train_labels,\n",
    "    _,\n",
    ") = cbh_data_definitions.load_data_from_zarr(training_data_path)\n",
    "\n",
    "(\n",
    "    dev_input, \n",
    "    dev_labels, \n",
    "    _\n",
    ") = cbh_data_definitions.load_data_from_zarr(dev_data_path)\n",
    "\n",
    "# the cloud volume is not needed for the task, so isn't saved on the load\n",
    "# show a chunk\n",
    "train_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c8b8915-497a-4d90-8ec2-971caa896dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings for data limiting (used for development e.g. faster training runs)\n",
    "LIMIT_DATA = False\n",
    "LIMIT_DATA_INT = -1\n",
    "if LIMIT_DATA:\n",
    "    LIMIT_DATA_INT = 10024\n",
    "    train_input = train_input[:LIMIT_DATA_INT]\n",
    "    train_labels = train_labels[:LIMIT_DATA_INT]\n",
    "    # train_cloud_volume = train_cloud_volume[:LIMIT_DATA_INT]\n",
    "    dev_input = dev_input[:LIMIT_DATA_INT]\n",
    "    dev_labels = dev_labels[:LIMIT_DATA_INT]\n",
    "    # dev_cloud_volume = dev_cloud_volume[:LIMIT_DATA_INT]\n",
    "hparams_for_mlflow['Limited sample number'] =  LIMIT_DATA_INT  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffba27b-d62f-4bcd-8132-e668c3479e3b",
   "metadata": {},
   "source": [
    "In order to make machine learning reproducible, hyperparameters will be logged using MLflow so that models can be redefined exactly as they were, and a seed for our random functions e.g. random shuffling of data: The random seed ensures that the same \"random\" shuffle of the data is performed each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b83e7351-b657-4e9b-8997-2d4022f8b5e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "# reproducibility with seed everything\n",
    "seed_everything_int = 42\n",
    "seed_everything(seed_everything_int)\n",
    "hparams_for_mlflow['Random seed'] = seed_everything_int"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0ab5c4-12e5-48cb-a947-f4f70a0e520e",
   "metadata": {},
   "source": [
    "## Perform the network initialization and training\n",
    "\n",
    "for each different model architecture, various different hyperparameters must be defined. For example in the case of an LSTM, bi-directionality is a simple to implement extension to the model type as this is a parameter of the layer definition in pytorch so can be included in the LSTM hyperparameter definition, there is no concept of input sequence direction in a simple MLP, so this hyperparameter doesn't apply \n",
    "\n",
    "training related hyperparameters are also defined. It is important to track exactly how much training is performed (epoch and step), the batch size, the learning rate and the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66118c9f-b5e5-447f-a4af-0e2fc7445238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.89052188e+04, 2.43972824e+02, 1.78724772e-03])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_l_p_f_m = np.load(\"./per_level_per_feat_mean.npz\")\n",
    "p_l_p_f_s = np.load(\"./per_level_per_feat_std.npz\")\n",
    "p_f_m = np.load(\"./per_feat_mean.npz\")\n",
    "p_f_s = np.load(\"./per_feat_std.npz\")\n",
    "p_l_p_f_s += 5.0e-12 # prevent divide by 0\n",
    "p_f_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ce919a8-22f0-46c1-a895-6b7c07ccdba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data chunk size: 2329600\n",
      "Factors of chunk:  [1, 2, 4, 5, 7, 8, 10, 13, 14, 16, 20, 25, 26, 28, 32, 35, 40, 50, 52, 56, 64, 65, 70, 80, 91, 100, 104, 112, 128, 130, 140, 160, 175, 182, 200, 208, 224, 256, 260, 280, 320, 325, 350, 364, 400, 416, 448, 455, 512, 520, 560, 640, 650, 700, 728, 800, 832, 896, 910, 1024, 1040, 1120, 1280, 1300, 1400, 1456, 1600, 1664, 1792, 1820, 2080, 2240, 2275, 2560, 2600, 2800, 2912, 3200, 3328, 3584, 3640, 4160, 4480, 4550, 5120, 5200, 5600, 5824, 6400, 6656, 7168, 7280, 8320, 8960, 9100, 10400, 11200, 11648, 12800, 13312, 14560, 16640, 17920, 18200, 20800, 22400, 23296, 25600, 29120, 33280, 35840, 36400, 41600, 44800, 46592, 58240, 66560, 72800, 83200, 89600, 93184, 116480, 145600, 166400, 179200, 232960, 291200, 332800, 465920, 582400, 1164800, 2329600]\n"
     ]
    }
   ],
   "source": [
    "# define model and hyperparameters\n",
    "mlp_layernum = 3             \n",
    "model_hyperparameter_dictionary = {\n",
    "    \"LSTM\": {\n",
    "        \"input_size\": train_input.shape[2],  # input size is the cell input (feat dim)\n",
    "        \"lstm_layers\": 1,\n",
    "        \"lstm_hidden_size\": 8,\n",
    "        \"output_size\": 1,  # for each height layer, predict one value for cloud base prob\n",
    "        \"height_dimension\": train_input.shape[1],\n",
    "        \"embed_size\": 1,\n",
    "        \"BILSTM\": True,\n",
    "        \"batch_first\": True,\n",
    "        \"skip_connection\":True,\n",
    "        \"backward_lstm_differing_transitions\":True,\n",
    "        \"lr\": 0.003,\n",
    "        \"norm_mat_mean\":torch.from_numpy(p_l_p_f_m.astype(np.float32)), \n",
    "        \"norm_mat_std\":torch.from_numpy(p_l_p_f_s.astype(np.float32)),\n",
    "        \"norm_method\":\"p_l_p_f\",\n",
    "    },\n",
    "    \"MLP\": {\n",
    "        \"input_size\": train_input.shape[2] * train_input.shape[1],\n",
    "        \"ff_nodes\": mlp_layernum * [256],\n",
    "        \"output_size\": train_input.shape[1],\n",
    "        \"lr\": 1.0e-3,\n",
    "        \"activation\": \"relu\",\n",
    "        \"layer_num\": mlp_layernum\n",
    "    },\n",
    "}\n",
    "\n",
    "model_definition_dictionary = {\n",
    "    \"LSTM\": cbh_torch_lstm.CloudBaseLSTM(**model_hyperparameter_dictionary[\"LSTM\"]),\n",
    "    \"MLP\": cbh_torch_MLP.CloudBaseMLP(**model_hyperparameter_dictionary[\"MLP\"]),\n",
    "}\n",
    "model_picked = \"LSTM\"\n",
    "model = model_definition_dictionary[model_picked]  # pick a model\n",
    "hparams_for_mlflow[\"Model defined hparams\"] = model_hyperparameter_dictionary[model_picked]\n",
    "\n",
    "\n",
    "# define training related hyperparameters\n",
    "\n",
    "epochs = 1\n",
    "hparams_for_mlflow[\"Max epochs\"] = epochs\n",
    "collate_fn = cbh_data_definitions.dataloader_collate_with_dask\n",
    "print(\"Data chunk size:\", train_input.chunksize[0])\n",
    "print(\"Factors of chunk: \", [n for n in range(1, train_input.chunksize[0] + 1) if train_input.chunksize[0] % n == 0])\n",
    "batch_size = 2080\n",
    "hparams_for_mlflow[\"Batch size\"] = batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09b8445-1600-4674-9f08-3ab87c08bcfd",
   "metadata": {},
   "source": [
    "The pytorch dataloader is also initialized, usually the dataloader does not change the outcome of ML training, however in our case there are multiple strategies for batch selection implemented, so tracking these settings are important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adc82bd5-20a8-4072-a266-4c162e41ed41",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader = None, None\n",
    "\n",
    "single_proc_workers = True # False causes crashes in some cases or in the case of 1 chunk at a time, makes data access slower\n",
    "if single_proc_workers:\n",
    "    WORKERS_CPU_COUNT=0\n",
    "else:\n",
    "    WORKERS_CPU_COUNT = CPU_COUNT\n",
    "\n",
    "data_loader_hparam_dict = {\n",
    "    'batch_size':batch_size,\n",
    "    'num_workers':WORKERS_CPU_COUNT,\n",
    "    # 'pin_memory':False,\n",
    "    'collate_fn':None, # using 1chunk method\n",
    "    'thread_count_for_dask':CPU_COUNT,\n",
    "    'method':'1chunk',\n",
    "}\n",
    "shuffle_training_data=False,\n",
    "\n",
    "datamodule = cbh_data_definitions.CBH_DataModule(\n",
    "        train_input, train_labels,\n",
    "        dev_input, dev_labels,\n",
    "        **data_loader_hparam_dict,\n",
    "        randomize_chunkwise = True,\n",
    "        \n",
    "    )\n",
    "data_loader_hparam_dict['shuffle_training_data']=shuffle_training_data\n",
    "hparams_for_mlflow['data loader hparams'] = data_loader_hparam_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53ceb9d-9a31-4b3c-9dbe-ffb7cbda4d15",
   "metadata": {},
   "source": [
    "Next we initialize an MLflow experiement, MLflow serves to share model training information in collaboration, allow for monitoring of current training processes, and tracking of hyperparameters + models + metrics for reproducing saving and loading training experiements. The MLflow server is launched from the command line, and connected to through the below cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39551462-62c9-4181-a41b-640463f4196c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating experiment\n"
     ]
    }
   ],
   "source": [
    "experiment_name = 'cbh-label-model-runs'\n",
    "experiment_name = 'test-setup-for-model-runs'\n",
    "\n",
    "# torch.set_num_threads(CPU_COUNT)\n",
    "\n",
    "mlflow.set_tracking_uri(mlflow_server_uri)\n",
    "# make vars global\n",
    "mlf_exp = None\n",
    "mlf_exp_id = None\n",
    "try: \n",
    "    print('Creating experiment')\n",
    "    mlf_exp_id = mlflow.create_experiment(experiment_name)\n",
    "    mlf_exp = mlflow.get_experiment(mlf_exp_id)\n",
    "except mlflow.exceptions.RestException:\n",
    "    mlf_exp = mlflow.get_experiment_by_name(experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9fbe59-be67-4309-8369-33245ae25fef",
   "metadata": {},
   "source": [
    "Autologging of the experiement did not work in this implementation, the best guess as to why is due to dasks lock on the data which prevents saving model weights, or displaying model attributes in some cases which autologging uses. To circumvent this, a custom checkpointing function is implemented into the PyTorch-Lighning's implementation for logging to MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21185156-4866-4d28-8c57-f036993f8170",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLFlowLogger(pl.loggers.MLFlowLogger): #overwrite mlflogger\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def after_save_checkpoint(self, model_checkpoint: pl.callbacks.ModelCheckpoint) -> None:\n",
    "        \"\"\"\n",
    "        Called after model checkpoint callback saves a new checkpoint.\n",
    "        \"\"\"\n",
    "        best_chkpt = torch.load(model_checkpoint.best_model_path)\n",
    "        # print(best_chkpt)\n",
    "        # print(best_chkpt['callbacks'])\n",
    "        checkpoint_for_mlflow = {\n",
    "            \"val loss\": float(best_chkpt['callbacks'][list(key for key in list(best_chkpt['callbacks'].keys()) if \"ModelCheckpoint\" in key)[0]]['current_score']),\n",
    "            \"train loss at step-1\": list(train_loss_metric.value for train_loss_metric in mlf_logger._mlflow_client.get_metric_history(run.info.run_id, \"Train loss\") if (int(train_loss_metric.step) == int(best_chkpt['global_step']-1)))[0],\n",
    "            \"global_step\": best_chkpt['global_step'],\n",
    "            \"model_state_dict\": best_chkpt['state_dict'],\n",
    "            \"checkpoint\": best_chkpt,\n",
    "\n",
    "        }\n",
    "        with TemporaryDirectory() as tmpdirname:\n",
    "            f_name = os.path.join(tmpdirname, f\"{run.info.run_id}-best_model_checkpoint-step_{best_chkpt['global_step']}.pt\")\n",
    "            torch.save(checkpoint_for_mlflow, f_name)\n",
    "            mlflow.log_artifact(f_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bc69ee-249e-4e53-8187-58269595c44d",
   "metadata": {},
   "source": [
    "Here the training is run, but not before some more model settings:timeout for training, naming of the MLflow experiement, defining when to validate, how to report progress in the notebook, and defining when to save a model. After training is run, another copy of the model is saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "959986bc-8f6a-46c5-a538-21ee2c81de7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c2dade6-a531-43b9-a88c-dcfb92937ab0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name              </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ LSTM_upward       │ LSTM             │    464 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ LSTM_downward     │ LSTM             │    464 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ height_embedding  │ Embedding        │     70 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss_fn_base      │ CrossEntropyLoss │      0 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>│ scale_input_layer │ Conv1d           │      5 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5 </span>│ linearCap         │ Linear           │  5.0 K │\n",
       "└───┴───────────────────┴──────────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName             \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ LSTM_upward       │ LSTM             │    464 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ LSTM_downward     │ LSTM             │    464 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ height_embedding  │ Embedding        │     70 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss_fn_base      │ CrossEntropyLoss │      0 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m4\u001b[0m\u001b[2m \u001b[0m│ scale_input_layer │ Conv1d           │      5 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m5\u001b[0m\u001b[2m \u001b[0m│ linearCap         │ Linear           │  5.0 K │\n",
       "└───┴───────────────────┴──────────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 6.0 K                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 6.0 K                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 6.0 K                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 6.0 K                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2850cdebbb3f497fbff0cfad9f523fa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/11/24 13:25:52 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during pytorch autologging: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ended run d93a372192cd4e58b64272d251ce0507\n"
     ]
    }
   ],
   "source": [
    "max_time = \"00:02:00:00\"  # dd:hh:mm:ss\n",
    "\n",
    "hparams_for_mlflow[\"Training timeout\"] = max_time\n",
    "\n",
    "timestamp_template = '{dt.year:04d}{dt.month:02d}{dt.day:02d}T{dt.hour:02d}{dt.minute:02d}{dt.second:02d}'\n",
    "run_name_template = 'cbh_challenge_{network_name}_' + timestamp_template\n",
    "current_run_name = run_name_template.format(network_name=model.__class__.__name__,\n",
    "                                                dt=datetime.datetime.now()\n",
    "                                               )\n",
    "\n",
    "# with Profiler() as prof, ResourceProfiler(dt=0.25) as rprof, CacheProfiler() as cprof:\n",
    "with mlflow.start_run(experiment_id=mlf_exp.experiment_id, run_name=current_run_name) as run:\n",
    "\n",
    "    mlflow.pytorch.autolog()\n",
    "    mlf_logger = MLFlowLogger(experiment_name=experiment_name, tracking_uri=mlflow_server_uri, run_id=run.info.run_id)\n",
    "\n",
    "\n",
    "    # define trainer\n",
    "    time_for_checkpoint = datetime.timedelta(minutes=15)\n",
    "    checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "        train_time_interval=time_for_checkpoint,\n",
    "        dirpath=run.info.artifact_uri,\n",
    "        monitor=\"Val loss\",\n",
    "        save_on_train_epoch_end=False,\n",
    "        mode=\"min\"\n",
    "    )\n",
    "    callbacks = [checkpoint_callback, RichProgressBar()]\n",
    "    trainer_hparams = {\n",
    "        'max_epochs':epochs,\n",
    "        'deterministic':True,\n",
    "        'val_check_interval':0.05, # val every percentage of the data\n",
    "        'devices':\"auto\",\n",
    "        'accelerator':\"auto\",\n",
    "        'max_time':max_time,\n",
    "        'replace_sampler_ddp':False,\n",
    "        'enable_checkpointing':True,\n",
    "        'strategy':None,\n",
    "        'callbacks':callbacks,\n",
    "        'logger':mlf_logger,\n",
    "    }\n",
    "    hparams_for_mlflow[\"Trainer hparams\"] = trainer_hparams\n",
    "    mlf_logger.log_hyperparams(hparams_for_mlflow)\n",
    "    trainer = pl.Trainer(\n",
    "        **trainer_hparams\n",
    "    )\n",
    "    \n",
    "    \n",
    "    trainer.fit(model=model, datamodule=datamodule)\n",
    "    path_to_save = '{dt.year:04d}{dt.month:02d}{dt.day:02d}-{dt.hour:02d}{dt.minute:02d}{dt.second:02d}'.format(dt=datetime.datetime.now())\n",
    "    trainer.save_checkpoint(filepath=run.info.artifact_uri + f'/post_epoch_modelchkpt_{path_to_save}')\n",
    "    with TemporaryDirectory() as tmpdirname:\n",
    "            f_name = os.path.join(tmpdirname, f\"{run.info.run_id}-post_epoch_checkpoint_logged.pt\")\n",
    "            trainer.save_checkpoint(filepath=f_name)\n",
    "            mlflow.log_artifact(f_name)\n",
    "print(\"Ended run\", run.info.run_id)\n",
    "    # print(visualize([prof, rprof, cprof], filename='profile_loop.html', save=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba52d2c-1212-4894-ad05-3a9f7761ccf2",
   "metadata": {},
   "source": [
    "## Display and evaluate results\n",
    "\n",
    "After training, explore some of the results from our model. tracking of experiment progress can be done during training, but it is a good idea to get an idea of final performance, or quickly investigate aspects of the model which cannot be monitored during training such as class imbalance of predictions. More ensurement of properties of the training can also be performed in this section, such as recalling MLflow variables in order to double check correct logging functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "888b7d7e-5158-42a9-b3f2-046dca3a218c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_id: 46d9e245379b45da81c8c07c7440f233\n",
      "artifacts: []\n",
      "params: {}\n",
      "metrics: {}\n",
      "tags: {}\n"
     ]
    }
   ],
   "source": [
    "def print_auto_logged_info(r):\n",
    "\n",
    "    tags = {k: v for k, v in r.data.tags.items() if not k.startswith(\"mlflow.\")}\n",
    "    artifacts = [f.path for f in MlflowClient().list_artifacts(r.info.run_id, \"model\")]\n",
    "    print(\"run_id: {}\".format(r.info.run_id))\n",
    "    print(\"artifacts: {}\".format(artifacts))\n",
    "    print(\"params: {}\".format(r.data.params))\n",
    "    print(\"metrics: {}\".format(r.data.metrics))\n",
    "    print(\"tags: {}\".format(tags))\n",
    "print_auto_logged_info(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ce386db-e33d-42aa-90ff-8a4a4dd3be76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2080, 70]) prediction output\n",
      "(2080,) prediction label shape\n",
      "(2080,) targ shape\n",
      "Correct samples: 806\n",
      "Total samples tested: 2080\n",
      "Accuracy: 38.75 %\n",
      "Model predictions binned: (Class labels), (Counts): (array([ 0,  3,  4,  6, 10, 23, 25, 26, 29, 32, 36, 37, 38, 39, 40, 41, 42,\n",
      "       69]), array([981,   8,   3,   1,   1,   2,  37,  52,   1,   4,   2,   1,   4,\n",
      "         5,   3,   1,   1, 973]))\n",
      "Model targets binned: (Class labels), (Counts): (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
      "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 69]), array([441,  33,  43,  37,  48,  47,  58,  57,  45,  60,  54,  66,  48,\n",
      "        32,  34,  21,  13,  15,  13,  13,  17,  14,  16,  15,  14,  28,\n",
      "        23,   7,  16,  11,   8,  14,  23,  18,  12,  12,  25,  22,  17,\n",
      "        22,  21,  16,  11,   9,  10,   1,   3, 497]))\n"
     ]
    }
   ],
   "source": [
    "# test model functionality\n",
    "example_batch = next(iter(datamodule.train_dataloader()))\n",
    "inputs = example_batch[0]\n",
    "try:\n",
    "    preds, _ = model(inputs, heights)\n",
    "except:\n",
    "    if model_picked == \"LSTM\":\n",
    "        inputs = example_batch[0]\n",
    "    else:     \n",
    "        print(example_batch[0].shape, \"inp pre-flat\")\n",
    "        inputs = torch.flatten(example_batch[0], start_dim=1)\n",
    "    preds = model(inputs)\n",
    "print(preds.shape, \"prediction output\")\n",
    "pred_label = np.argmax(preds.detach().numpy(), axis=1)\n",
    "print(pred_label.shape, \"prediction label shape\")\n",
    "targs = example_batch[1]\n",
    "targs = np.array(targs)\n",
    "print(targs.shape, \"targ shape\")\n",
    "correct = targs == pred_label\n",
    "print(\"Correct samples:\", np.count_nonzero(correct))\n",
    "print(\"Total samples tested:\", len(correct))\n",
    "print(\"Accuracy:\", (np.count_nonzero(correct) / len(correct) * 100), \"%\")\n",
    "print(\n",
    "    \"Model predictions binned: (Class labels), (Counts):\",\n",
    "    np.unique(pred_label, return_counts=True),\n",
    ")\n",
    "print(\n",
    "    \"Model targets binned: (Class labels), (Counts):\",\n",
    "    np.unique(targs, return_counts=True),\n",
    ")\n",
    "eg_batch_metrics = {\n",
    "    \"Correct samples\" : np.count_nonzero(correct),\n",
    "    \"Total samples tested\" : len(correct),\n",
    "    \"Accuracy\" : (np.count_nonzero(correct) / len(correct) * 100),\n",
    "\n",
    "    \"Model predictions binned: (Class labels), (Counts)\"\n",
    "     : str(np.unique(pred_label, return_counts=True)),\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5a6d3a-5b0b-4fe5-b6d3-664fa93f6498",
   "metadata": {},
   "outputs": [],
   "source": [
    "eg_batch_metrics = {\n",
    "    \"Single batch example validation metrics/Correct samples\" : np.count_nonzero(correct),\n",
    "    \"Single batch example validation metrics/Total samples tested\" : len(correct),\n",
    "    \"Single batch example validation metrics/Accuracy\" : np.count_nonzero(correct) / len(correct) * 100,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b42f978-4908-4d20-95e4-b2d7adf48bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlf_logger.log_metrics(eg_batch_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c108cb0a-4886-40ac-8ab8-af913c5d3b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display mlflow output\n",
    "print_auto_logged_info(mlflow.get_run(run_id=run.info.run_id))\n",
    "mlflow.end_run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda-py-lightning Python (Conda)",
   "language": "python",
   "name": "conda-env-.conda-py-lightning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
