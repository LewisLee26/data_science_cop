{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19a7bbf4-00f4-4b5d-97a9-d6d9138d0f8a",
   "metadata": {},
   "source": [
    "Make initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b97e418c-c396-4b0d-9157-8f201bb9d374",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cbh_data_definitions\n",
    "import pathlib\n",
    "import os\n",
    "\n",
    "import optuna\n",
    "import pytorch_lightning as pl\n",
    "import mlflow\n",
    "from ray import tune\n",
    "import ray\n",
    "import ray.tune\n",
    "import ray.tune.search\n",
    "import ray.tune.search.optuna\n",
    "from ray.tune.search.optuna import OptunaSearch\n",
    "from ray.tune.integration.mlflow import mlflow_mixin\n",
    "from ray.tune.search import ConcurrencyLimiter\n",
    "import numpy as np\n",
    "import datetime\n",
    "import cbh_torch_MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16443e15-8512-4a3f-a3eb-222764cd03f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# intialize some settings: mlflow, data directory, resources\n",
    "root_data_directory = pathlib.Path(os.environ[\"SCRATCH\"]) / \"cbh_data\"\n",
    "\n",
    "dev_data_path = root_data_directory / \"analysis_ready\" / \"dev_randomized.zarr\"\n",
    "training_data_path = root_data_directory / \"analysis_ready\" / \"train_randomized.zarr\"\n",
    "\n",
    "mlflow_command_line_run = \"\"\"\n",
    "    mlflow server --port 5001 --backend-store-uri sqlite:///mlflowSQLserver.db  --default-artifact-root ./mlflow_artifacts/\n",
    "\"\"\"\n",
    "mlflow_server_address = 'vld425'\n",
    "mlflow_server_port = 5001\n",
    "mlflow_server_uri = f'http://{mlflow_server_address}:{mlflow_server_port:d}'\n",
    "mlflow_artifact_root = pathlib.Path('./mlflow_artifacts/')\n",
    "\n",
    "hparams_for_mlflow = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b14327c-6a24-4cb2-93da-f2697a78be1e",
   "metadata": {},
   "source": [
    "redefine data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5cba65e-0d9a-4924-93fb-47b4aacc9bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded zarr, file information:\n",
      " Name              : /\n",
      "Type              : zarr.hierarchy.Group\n",
      "Read-only         : False\n",
      "Synchronizer type : zarr.sync.ThreadSynchronizer\n",
      "Store type        : zarr.storage.DirectoryStore\n",
      "No. members       : 2\n",
      "No. arrays        : 2\n",
      "No. groups        : 0\n",
      "Arrays            : cloud_base_label_y.zarr, humidity_temp_pressure_x.zarr\n",
      " \n",
      "\n",
      "Loaded zarr, file information:\n",
      " Name              : /\n",
      "Type              : zarr.hierarchy.Group\n",
      "Read-only         : False\n",
      "Synchronizer type : zarr.sync.ThreadSynchronizer\n",
      "Store type        : zarr.storage.DirectoryStore\n",
      "No. members       : 2\n",
      "No. arrays        : 2\n",
      "No. groups        : 0\n",
      "Arrays            : cloud_base_label_y.zarr, humidity_temp_pressure_x.zarr\n",
      " \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table>\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 87.48 GiB </td>\n",
       "                        <td> 1.82 GiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (111820800, 70, 3) </td>\n",
       "                        <td> (2329600, 70, 3) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Count </th>\n",
       "                        <td> 2 Graph Layers </td>\n",
       "                        <td> 48 Chunks </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                    <th> Type </th>\n",
       "                    <td> float32 </td>\n",
       "                    <td> numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"156\" height=\"146\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"80\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"10\" y1=\"25\" x2=\"80\" y2=\"96\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"10\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"12\" y1=\"2\" x2=\"12\" y2=\"28\" />\n",
       "  <line x1=\"17\" y1=\"7\" x2=\"17\" y2=\"32\" />\n",
       "  <line x1=\"20\" y1=\"10\" x2=\"20\" y2=\"35\" />\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"24\" y2=\"40\" />\n",
       "  <line x1=\"27\" y1=\"17\" x2=\"27\" y2=\"43\" />\n",
       "  <line x1=\"32\" y1=\"22\" x2=\"32\" y2=\"47\" />\n",
       "  <line x1=\"35\" y1=\"25\" x2=\"35\" y2=\"50\" />\n",
       "  <line x1=\"39\" y1=\"29\" x2=\"39\" y2=\"54\" />\n",
       "  <line x1=\"42\" y1=\"32\" x2=\"42\" y2=\"57\" />\n",
       "  <line x1=\"46\" y1=\"36\" x2=\"46\" y2=\"62\" />\n",
       "  <line x1=\"49\" y1=\"39\" x2=\"49\" y2=\"65\" />\n",
       "  <line x1=\"54\" y1=\"44\" x2=\"54\" y2=\"69\" />\n",
       "  <line x1=\"57\" y1=\"47\" x2=\"57\" y2=\"72\" />\n",
       "  <line x1=\"61\" y1=\"51\" x2=\"61\" y2=\"76\" />\n",
       "  <line x1=\"64\" y1=\"54\" x2=\"64\" y2=\"79\" />\n",
       "  <line x1=\"68\" y1=\"58\" x2=\"68\" y2=\"84\" />\n",
       "  <line x1=\"71\" y1=\"61\" x2=\"71\" y2=\"87\" />\n",
       "  <line x1=\"76\" y1=\"66\" x2=\"76\" y2=\"91\" />\n",
       "  <line x1=\"80\" y1=\"70\" x2=\"80\" y2=\"96\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 80.58823529411765,70.58823529411765 80.58823529411765,96.00085180870013 10.0,25.412616514582485\" style=\"fill:#8B4903A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"35\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"12\" y1=\"2\" x2=\"38\" y2=\"2\" />\n",
       "  <line x1=\"17\" y1=\"7\" x2=\"42\" y2=\"7\" />\n",
       "  <line x1=\"20\" y1=\"10\" x2=\"45\" y2=\"10\" />\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"50\" y2=\"14\" />\n",
       "  <line x1=\"27\" y1=\"17\" x2=\"53\" y2=\"17\" />\n",
       "  <line x1=\"32\" y1=\"22\" x2=\"57\" y2=\"22\" />\n",
       "  <line x1=\"35\" y1=\"25\" x2=\"60\" y2=\"25\" />\n",
       "  <line x1=\"39\" y1=\"29\" x2=\"64\" y2=\"29\" />\n",
       "  <line x1=\"42\" y1=\"32\" x2=\"67\" y2=\"32\" />\n",
       "  <line x1=\"46\" y1=\"36\" x2=\"72\" y2=\"36\" />\n",
       "  <line x1=\"49\" y1=\"39\" x2=\"75\" y2=\"39\" />\n",
       "  <line x1=\"54\" y1=\"44\" x2=\"79\" y2=\"44\" />\n",
       "  <line x1=\"57\" y1=\"47\" x2=\"82\" y2=\"47\" />\n",
       "  <line x1=\"61\" y1=\"51\" x2=\"86\" y2=\"51\" />\n",
       "  <line x1=\"64\" y1=\"54\" x2=\"89\" y2=\"54\" />\n",
       "  <line x1=\"68\" y1=\"58\" x2=\"94\" y2=\"58\" />\n",
       "  <line x1=\"71\" y1=\"61\" x2=\"97\" y2=\"61\" />\n",
       "  <line x1=\"76\" y1=\"66\" x2=\"101\" y2=\"66\" />\n",
       "  <line x1=\"80\" y1=\"70\" x2=\"106\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"80\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"35\" y1=\"0\" x2=\"106\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 35.41261651458248,0.0 106.00085180870013,70.58823529411765 80.58823529411765,70.58823529411765\" style=\"fill:#8B4903A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"80\" y1=\"70\" x2=\"106\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"80\" y1=\"96\" x2=\"106\" y2=\"96\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"80\" y1=\"70\" x2=\"80\" y2=\"96\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"106\" y1=\"70\" x2=\"106\" y2=\"96\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"80.58823529411765,70.58823529411765 106.00085180870013,70.58823529411765 106.00085180870013,96.00085180870013 80.58823529411765,96.00085180870013\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"93.294544\" y=\"116.000852\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >3</text>\n",
       "  <text x=\"126.000852\" y=\"83.294544\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(0,126.000852,83.294544)\">70</text>\n",
       "  <text x=\"35.294118\" y=\"80.706734\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(45,35.294118,80.706734)\">111820800</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<from-zarr, shape=(111820800, 70, 3), dtype=float32, chunksize=(2329600, 70, 3), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# init data\n",
    "(\n",
    "    train_input,\n",
    "    train_labels,\n",
    "    _,\n",
    ") = cbh_data_definitions.load_data_from_zarr(training_data_path)\n",
    "\n",
    "(\n",
    "    dev_input, \n",
    "    dev_labels, \n",
    "    _\n",
    ") = cbh_data_definitions.load_data_from_zarr(dev_data_path)\n",
    "\n",
    "# the cloud volume is not needed for the task, so isn't saved on the load\n",
    "# show a chunk\n",
    "train_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edeea09a-8bd8-4313-a7ea-7fd8d37bf4ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factors of chunk:  [1, 2, 4, 5, 7, 8, 10, 13, 14, 16, 20, 25, 26, 28, 32, 35, 40, 50, 52, 56, 64, 65, 70, 80, 91, 100, 104, 112, 128, 130, 140, 160, 175, 182, 200, 208, 224, 256, 260, 280, 320, 325, 350, 364, 400, 416, 448, 455, 512, 520, 560, 640, 650, 700, 728, 800, 832, 896, 910, 1024, 1040, 1120, 1280, 1300, 1400, 1456, 1600, 1664, 1792, 1820, 2080, 2240, 2275, 2560, 2600, 2800, 2912, 3200, 3328, 3584, 3640, 4160, 4480, 4550, 5120, 5200, 5600, 5824, 6400, 6656, 7168, 7280, 8320, 8960, 9100, 10400, 11200, 11648, 12800, 13312, 14560, 16640, 17920, 18200, 20800, 22400, 23296, 25600, 29120, 33280, 35840, 36400, 41600, 44800, 46592, 58240, 66560, 72800, 83200, 89600, 93184, 116480, 145600, 166400, 179200, 232960, 291200, 332800, 465920, 582400, 1164800, 2329600]\n"
     ]
    }
   ],
   "source": [
    "# limit the data by a factor for less data in a tuning trial\n",
    "factors_of_chunk = [n for n in range(1, train_input.chunksize[0] + 1) if train_input.chunksize[0] % n == 0]\n",
    "print(\"Factors of chunk: \", factors_of_chunk)\n",
    "hparams_for_mlflow['Limited sample number'] =  -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbae1c6-5501-40e7-a2ba-4b1ef270f170",
   "metadata": {},
   "source": [
    "setup study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90bd6235-7bfe-4bd1-aa06-ae1f5f86c223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE ALL SETTINGS FOR TRAINING, includes hparam space\n",
    "experiment_name = 'cbh-hparam-tuning'\n",
    "CPU_COUNT = 4\n",
    "RAM_GB = 6\n",
    "hparams_for_mlflow['CPU Count'] = CPU_COUNT\n",
    "hparams_for_mlflow['Compute Memory'] = RAM_GB\n",
    "thread_count_for_dask = CPU_COUNT\n",
    "dataset_method = '1chunk'\n",
    "randomize_chunkwise_1chunk = False\n",
    "shuffle_train_data = False\n",
    "collate_fn = None # alt: cbh_data_definitions.dataloader_collate_with_dask\n",
    "num_workers_dataloader = 0 # alt: CPU_COUNT +-\n",
    "global_trail_number = 0\n",
    "max_time_for_trial = \"00:02:00:00\"  # dd:hh:mm:ss\n",
    "hparams_for_mlflow[\"Training timeout\"] = max_time_for_trial\n",
    "\n",
    "max_node_num_exclusive = 513\n",
    "factors_for_hparam_choice = [factor for factor in factors_of_chunk if (factor<3300 and factor>3)]\n",
    "mlp_search_space = {\n",
    "    \"epoch\": 1,\n",
    "    \"lr\": tune.quniform(0.0001, 0.01, 0.00005),\n",
    "    \"data_limit\": tune.randint(4, int(len(train_labels.chunks[0]) / 4)), # multiple chunk ind by chunklen: train_input.chunksize[0])\n",
    "    # \"activation\": tune.choice([\"relu\", \"tanh\"]),\n",
    "    \"batch_size\": tune.choice(factors_for_hparam_choice),\n",
    "    \"arch_name\":\"MLP\",\n",
    "    \"hidden_layers\":tune.randint(1,11),\n",
    "    \"activation\":tune.choice([\"relu\", \"tanh\"]),\n",
    "    \"input_size\":(train_input.shape[2] * train_input.shape[1]),\n",
    "    \"output_size\": train_input.shape[1],\n",
    "    \"layer_node_num\": tune.sample_from(lambda spec: 8*np.random.randint(1,int(max_node_num_exclusive/8), size=spec.config.hidden_layers)),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aaa35a93-c33d-4e81-b5f9-4a235028ac38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating experiment\n",
      "Caught\n",
      "RESOURCE_ALREADY_EXISTS: Experiment(name=cbh-hparam-tuning) already exists. Error: (raised as a result of Query-invoked autoflush; consider using a session.no_autoflush block if this flush is occurring prematurely)\n",
      "(sqlite3.IntegrityError) UNIQUE constraint failed: experiments.name\n",
      "[SQL: INSERT INTO experiments (name, artifact_location, lifecycle_stage, creation_time, last_update_time) VALUES (?, ?, ?, ?, ?)]\n",
      "[parameters: ('cbh-hparam-tuning', '', 'active', 1668101925780, 1668101925780)]\n",
      "(Background on this error at: https://sqlalche.me/e/14/gkpj)\n",
      "Success\n"
     ]
    }
   ],
   "source": [
    "class MLFlowLogger(pl.loggers.MLFlowLogger): #overwrite mlflogger\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def after_save_checkpoint(self, model_checkpoint: pl.callbacks.ModelCheckpoint) -> None:\n",
    "        \"\"\"\n",
    "        Called after model checkpoint callback saves a new checkpoint.\n",
    "        \"\"\"\n",
    "        best_chkpt = torch.load(model_checkpoint.best_model_path)\n",
    "        checkpoint_for_mlflow = {\n",
    "            \"val loss\": float(best_chkpt['callbacks'][list(key for key in list(best_chkpt['callbacks'].keys()) if \"ModelCheckpoint\" in key)[0]]['current_score']),\n",
    "            \"train loss at step-1\": list(train_loss_metric.value for train_loss_metric in mlf_logger._mlflow_client.get_metric_history(run.info.run_id, \"Train loss\") if (int(train_loss_metric.step) == int(best_chkpt['global_step']-1)))[0],\n",
    "            \"global_step\": best_chkpt['global_step'],\n",
    "            \"model_state_dict\": best_chkpt['state_dict'],\n",
    "            \"checkpoint\": best_chkpt,\n",
    "        }\n",
    "        with TemporaryDirectory() as tmpdirname:\n",
    "            f_name = os.path.join(tmpdirname, f\"{run.info.run_id}-best_model_checkpoint-step_{best_chkpt['global_step']}.pt\")\n",
    "            torch.save(checkpoint_for_mlflow, f_name)\n",
    "            mlflow.log_artifact(f_name)\n",
    "\n",
    "mlflow.set_tracking_uri(mlflow_server_uri)\n",
    "# make vars global\n",
    "mlf_exp = None\n",
    "mlf_exp_id = None\n",
    "try: \n",
    "    print('Creating experiment')\n",
    "    mlf_exp_id = mlflow.create_experiment(experiment_name)\n",
    "    mlf_exp = mlflow.get_experiment(mlf_exp_id)\n",
    "except mlflow.exceptions.RestException as e:\n",
    "    print(\"Caught\")\n",
    "    print(e)\n",
    "    mlf_exp = mlflow.get_experiment_by_name(experiment_name)\n",
    "print(\"Success\")\n",
    "\n",
    "mlp_search_space[\"mlflow\"] = {\n",
    "    \"tracking_uri\":mlflow_server_uri,\n",
    "    \"experiment_id\":mlf_exp_id,\n",
    "    \"experiment_name\":experiment_name,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "076ee9ae-57f6-4d17-90f3-e44b920af3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@mlflow_mixin\n",
    "def objective(ray_config):\n",
    "    # def model hparams with config\n",
    "    print(ray_config)\n",
    "    print(dir(ray_config))\n",
    "    # def data\n",
    "    datamodule = cbh_data_definitions.CBH_DataModule(\n",
    "        train_input, train_labels,\n",
    "        dev_input, dev_labels,\n",
    "        thread_count_for_dask,\n",
    "        ray_config['batch_size'],\n",
    "        num_workers = num_workers_dataloader,\n",
    "        collate_fn = collate_fn,\n",
    "        shuffle = shuffle_train_data,\n",
    "        randomize_chunkwise = randomize_chunkwise_1chunk,\n",
    "        method=dataset_method,\n",
    "    )\n",
    "    #def model\n",
    "    model = cbh_torch_MLP.CloudBaseMLP(\n",
    "        ray_config['input_size'],\n",
    "        ray_config['layer_node_num'],\n",
    "        ray_config['output_size'],\n",
    "        ray_config['hidden_layers'],\n",
    "        ray_config['activation'],\n",
    "        ray_config['lr'],\n",
    "    )\n",
    "    # def experiment naming\n",
    "    timestamp_template = '{dt.year:04d}{dt.month:02d}{dt.day:02d}T{dt.hour:02d}{dt.minute:02d}{dt.second:02d}'\n",
    "    run_name_template = 'cbh_challenge_{network_name}_' + timestamp_template\n",
    "    global global_trail_number\n",
    "    current_run_name = run_name_template.format(network_name=model.__class__.__name__,\n",
    "                                                    dt=datetime.datetime.now()\n",
    "                                                   )\n",
    "    \n",
    "    # begin mlflow experiment run\n",
    "    with mlflow.start_run(experiment_id=mlf_exp.experiment_id, run_name=current_run_name, nested=True) as run:\n",
    "    \n",
    "        mlflow.pytorch.autolog()\n",
    "        mlf_logger = MLFlowLogger(experiment_name=experiment_name, tracking_uri=mlflow_server_uri, run_id=run.info.run_id)\n",
    "        return {\"val_loss\":1.0}\n",
    "        # define trainer\n",
    "        time_for_checkpoint = datetime.timedelta(minutes=15)\n",
    "        checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "            train_time_interval=time_for_checkpoint,\n",
    "            dirpath=run.info.artifact_uri,\n",
    "            monitor=\"Val loss\",\n",
    "            save_on_train_epoch_end=False,\n",
    "            mode=\"min\"\n",
    "        )\n",
    "        callbacks = [checkpoint_callback, RichProgressBar()]\n",
    "        \n",
    "        trainer_hparams = {\n",
    "            'max_epochs':epochs,\n",
    "            'deterministic':True,\n",
    "            'val_check_interval':0.05, # val every percentage of the data\n",
    "            'devices':\"auto\",\n",
    "            'accelerator':\"auto\",\n",
    "            'max_time':max_time,\n",
    "            'replace_sampler_ddp':False,\n",
    "            'enable_checkpointing':True,\n",
    "            'strategy':None,\n",
    "            'callbacks':callbacks,\n",
    "            'logger':mlf_logger,\n",
    "        }\n",
    "        \n",
    "        hparams_for_mlflow[\"Trainer hparams\"] = trainer_hparams\n",
    "        mlf_logger.log_hyperparams(hparams_for_mlflow)\n",
    "        \n",
    "        trainer = pl.Trainer(\n",
    "            **trainer_hparams\n",
    "        )\n",
    "\n",
    "        trainer.fit(model=model, train_dataloaders=train_loader, val_dataloaders=val_loader)\n",
    "        path_to_save = '{dt.year:04d}{dt.month:02d}{dt.day:02d}-{dt.hour:02d}{dt.minute:02d}{dt.second:02d}'.format(dt=datetime.datetime.now())\n",
    "        trainer.save_checkpoint(filepath=run.info.artifact_uri + f'/post_epoch_modelchkpt_{path_to_save}')\n",
    "    return trainer.callback_metrics[\"val_acc\"].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "475ff4ee-30a6-4224-8833-da8301e9edc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-11-10 17:40:15 (running for 00:00:28.63)<br>Memory usage on this node: 4.9/7.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/4 CPUs, 0/0 GPUs, 0.0/2.25 GiB heap, 0.0/1.12 GiB objects<br>Result logdir: /home/h02/hsouth/ray_results/objective_2022-11-10_17-39-46<br>Number of trials: 4/4 (4 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name           </th><th>status    </th><th>loc                </th><th>activation  </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  data_limit</th><th style=\"text-align: right;\">  hidden_layers</th><th>layer_node_num      </th><th style=\"text-align: right;\">     lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  val_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>objective_ab147_00000</td><td>TERMINATED</td><td>10.152.49.117:68201</td><td>tanh        </td><td style=\"text-align: right;\">           5</td><td style=\"text-align: right;\">           7</td><td style=\"text-align: right;\">              5</td><td>[256  24 304 32_efd0</td><td style=\"text-align: right;\">0.0073 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       0.0885732</td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>objective_ab147_00001</td><td>TERMINATED</td><td>10.152.49.117:68287</td><td>tanh        </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">             10</td><td>[ 64 192 280 38_c0f0</td><td style=\"text-align: right;\">0.00645</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       0.126102 </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>objective_ab147_00002</td><td>TERMINATED</td><td>10.152.49.117:68333</td><td>relu        </td><td style=\"text-align: right;\">         140</td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">              2</td><td>[152 176]           </td><td style=\"text-align: right;\">0.00155</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       0.103521 </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>objective_ab147_00003</td><td>TERMINATED</td><td>10.152.49.117:68369</td><td>relu        </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">              9</td><td>[440   8 312 40_9e30</td><td style=\"text-align: right;\">0.00865</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       0.245827 </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(objective pid=68201)\u001b[0m {'epoch': 1, 'lr': 0.0073, 'data_limit': 7, 'batch_size': 5, 'arch_name': 'MLP', 'hidden_layers': 5, 'activation': 'tanh', 'input_size': 210, 'output_size': 70, 'layer_node_num': array([256,  24, 304, 328, 192]), 'mlflow': {'tracking_uri': 'http://vld425:5001', 'experiment_id': None, 'experiment_name': 'cbh-hparam-tuning'}}\n",
      "\u001b[2m\u001b[36m(objective pid=68201)\u001b[0m ['__class__', '__class_getitem__', '__contains__', '__delattr__', '__delitem__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__ior__', '__iter__', '__le__', '__len__', '__lt__', '__ne__', '__new__', '__or__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__ror__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'clear', 'copy', 'fromkeys', 'get', 'items', 'keys', 'pop', 'popitem', 'setdefault', 'update', 'values']\n",
      "\u001b[2m\u001b[36m(objective pid=68287)\u001b[0m {'epoch': 1, 'lr': 0.00645, 'data_limit': 8, 'batch_size': 64, 'arch_name': 'MLP', 'hidden_layers': 10, 'activation': 'tanh', 'input_size': 210, 'output_size': 70, 'layer_node_num': array([ 64, 192, 280, 384,  56, 416, 216, 464, 176, 504]), 'mlflow': {'tracking_uri': 'http://vld425:5001', 'experiment_id': None, 'experiment_name': 'cbh-hparam-tuning'}}\n",
      "\u001b[2m\u001b[36m(objective pid=68287)\u001b[0m ['__class__', '__class_getitem__', '__contains__', '__delattr__', '__delitem__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__ior__', '__iter__', '__le__', '__len__', '__lt__', '__ne__', '__new__', '__or__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__ror__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'clear', 'copy', 'fromkeys', 'get', 'items', 'keys', 'pop', 'popitem', 'setdefault', 'update', 'values']\n",
      "\u001b[2m\u001b[36m(objective pid=68333)\u001b[0m {'epoch': 1, 'lr': 0.0015500000000000002, 'data_limit': 4, 'batch_size': 140, 'arch_name': 'MLP', 'hidden_layers': 2, 'activation': 'relu', 'input_size': 210, 'output_size': 70, 'layer_node_num': array([152, 176]), 'mlflow': {'tracking_uri': 'http://vld425:5001', 'experiment_id': None, 'experiment_name': 'cbh-hparam-tuning'}}\n",
      "\u001b[2m\u001b[36m(objective pid=68333)\u001b[0m ['__class__', '__class_getitem__', '__contains__', '__delattr__', '__delitem__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__ior__', '__iter__', '__le__', '__len__', '__lt__', '__ne__', '__new__', '__or__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__ror__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'clear', 'copy', 'fromkeys', 'get', 'items', 'keys', 'pop', 'popitem', 'setdefault', 'update', 'values']\n",
      "Result for objective_ab147_00000:\n",
      "  date: 2022-11-10_17-39-55\n",
      "  done: false\n",
      "  experiment_id: 216b2145504b40b0acfeb2db88751245\n",
      "  hostname: vld425\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 10.152.49.117\n",
      "  pid: 68201\n",
      "  time_since_restore: 0.08857321739196777\n",
      "  time_this_iter_s: 0.08857321739196777\n",
      "  time_total_s: 0.08857321739196777\n",
      "  timestamp: 1668101995\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: ab147_00000\n",
      "  val_loss: 1.0\n",
      "  warmup_time: 0.26276159286499023\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-10 17:40:14,904\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'layer_node_num': array([256,  24, 304, 328, 192])}\n",
      "2022-11-10 17:40:14,950\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'layer_node_num': array([152, 176])}\n",
      "2022-11-10 17:40:14,977\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'layer_node_num': array([ 64, 192, 280, 384,  56, 416, 216, 464, 176, 504])}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for objective_ab147_00000:\n",
      "  date: 2022-11-10_17-39-55\n",
      "  done: true\n",
      "  experiment_id: 216b2145504b40b0acfeb2db88751245\n",
      "  experiment_tag: 0_activation=tanh,batch_size=5,data_limit=7,hidden_layers=5,layer_node_num=256_24_304_328_192,lr=0.0073\n",
      "  hostname: vld425\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 10.152.49.117\n",
      "  pid: 68201\n",
      "  time_since_restore: 0.08857321739196777\n",
      "  time_this_iter_s: 0.08857321739196777\n",
      "  time_total_s: 0.08857321739196777\n",
      "  timestamp: 1668101995\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: ab147_00000\n",
      "  val_loss: 1.0\n",
      "  warmup_time: 0.26276159286499023\n",
      "  \n",
      "Result for objective_ab147_00002:\n",
      "  date: 2022-11-10_17-40-09\n",
      "  done: false\n",
      "  experiment_id: 8e857ff3ce074279adf98c569d083f6f\n",
      "  hostname: vld425\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 10.152.49.117\n",
      "  pid: 68333\n",
      "  time_since_restore: 0.10352063179016113\n",
      "  time_this_iter_s: 0.10352063179016113\n",
      "  time_total_s: 0.10352063179016113\n",
      "  timestamp: 1668102009\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: ab147_00002\n",
      "  val_loss: 1.0\n",
      "  warmup_time: 0.21908855438232422\n",
      "  \n",
      "Result for objective_ab147_00001:\n",
      "  date: 2022-11-10_17-40-03\n",
      "  done: false\n",
      "  experiment_id: 40f7ff910bea4ddaa75e94d997d510e2\n",
      "  hostname: vld425\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 10.152.49.117\n",
      "  pid: 68287\n",
      "  time_since_restore: 0.12610173225402832\n",
      "  time_this_iter_s: 0.12610173225402832\n",
      "  time_total_s: 0.12610173225402832\n",
      "  timestamp: 1668102003\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: ab147_00001\n",
      "  val_loss: 1.0\n",
      "  warmup_time: 0.25042009353637695\n",
      "  \n",
      "\u001b[2m\u001b[36m(objective pid=68369)\u001b[0m {'epoch': 1, 'lr': 0.00865, 'data_limit': 4, 'batch_size': 16, 'arch_name': 'MLP', 'hidden_layers': 9, 'activation': 'relu', 'input_size': 210, 'output_size': 70, 'layer_node_num': array([440,   8, 312, 400, 128, 312, 208,  80,  48]), 'mlflow': {'tracking_uri': 'http://vld425:5001', 'experiment_id': None, 'experiment_name': 'cbh-hparam-tuning'}}\n",
      "\u001b[2m\u001b[36m(objective pid=68369)\u001b[0m ['__class__', '__class_getitem__', '__contains__', '__delattr__', '__delitem__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__ior__', '__iter__', '__le__', '__len__', '__lt__', '__ne__', '__new__', '__or__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__ror__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'clear', 'copy', 'fromkeys', 'get', 'items', 'keys', 'pop', 'popitem', 'setdefault', 'update', 'values']\n",
      "Result for objective_ab147_00002:\n",
      "  date: 2022-11-10_17-40-09\n",
      "  done: true\n",
      "  experiment_id: 8e857ff3ce074279adf98c569d083f6f\n",
      "  experiment_tag: 2_activation=relu,batch_size=140,data_limit=4,hidden_layers=2,layer_node_num=152_176,lr=0.0016\n",
      "  hostname: vld425\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 10.152.49.117\n",
      "  pid: 68333\n",
      "  time_since_restore: 0.10352063179016113\n",
      "  time_this_iter_s: 0.10352063179016113\n",
      "  time_total_s: 0.10352063179016113\n",
      "  timestamp: 1668102009\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: ab147_00002\n",
      "  val_loss: 1.0\n",
      "  warmup_time: 0.21908855438232422\n",
      "  \n",
      "Result for objective_ab147_00001:\n",
      "  date: 2022-11-10_17-40-03\n",
      "  done: true\n",
      "  experiment_id: 40f7ff910bea4ddaa75e94d997d510e2\n",
      "  experiment_tag: 1_activation=tanh,batch_size=64,data_limit=8,hidden_layers=10,layer_node_num=64_192_280_384_56_416_216_464_176_504,lr=0.0065\n",
      "  hostname: vld425\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 10.152.49.117\n",
      "  pid: 68287\n",
      "  time_since_restore: 0.12610173225402832\n",
      "  time_this_iter_s: 0.12610173225402832\n",
      "  time_total_s: 0.12610173225402832\n",
      "  timestamp: 1668102003\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: ab147_00001\n",
      "  val_loss: 1.0\n",
      "  warmup_time: 0.25042009353637695\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-10 17:40:15,138\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'layer_node_num': array([440,   8, 312, 400, 128, 312, 208,  80,  48])}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for objective_ab147_00003:\n",
      "  date: 2022-11-10_17-40-15\n",
      "  done: false\n",
      "  experiment_id: a5f8f16baa4e442186e2ec5d16f7bbcd\n",
      "  hostname: vld425\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 10.152.49.117\n",
      "  pid: 68369\n",
      "  time_since_restore: 0.24582695960998535\n",
      "  time_this_iter_s: 0.24582695960998535\n",
      "  time_total_s: 0.24582695960998535\n",
      "  timestamp: 1668102015\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: ab147_00003\n",
      "  val_loss: 1.0\n",
      "  warmup_time: 0.22005677223205566\n",
      "  \n",
      "Result for objective_ab147_00003:\n",
      "  date: 2022-11-10_17-40-15\n",
      "  done: true\n",
      "  experiment_id: a5f8f16baa4e442186e2ec5d16f7bbcd\n",
      "  experiment_tag: 3_activation=relu,batch_size=16,data_limit=4,hidden_layers=9,layer_node_num=440_8_312_400_128_312_208_80_48,lr=0.0086\n",
      "  hostname: vld425\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 10.152.49.117\n",
      "  pid: 68369\n",
      "  time_since_restore: 0.24582695960998535\n",
      "  time_this_iter_s: 0.24582695960998535\n",
      "  time_total_s: 0.24582695960998535\n",
      "  timestamp: 1668102015\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: ab147_00003\n",
      "  val_loss: 1.0\n",
      "  warmup_time: 0.22005677223205566\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-10 17:40:15,331\tINFO tune.py:758 -- Total run time: 28.79 seconds (28.59 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "searcher = OptunaSearch(metric=[\"val_loss\"], mode=[\"min\"])\n",
    "algo = ConcurrencyLimiter(searcher, max_concurrent=int(CPU_COUNT*(3/4)))\n",
    "num_hparam_trials = 4\n",
    "\n",
    "tuner = tune.Tuner(\n",
    "    objective,\n",
    "    tune_config=tune.TuneConfig(\n",
    "        # search_alg=algo,\n",
    "        num_samples=num_hparam_trials,\n",
    "    ),\n",
    "    param_space=mlp_search_space,\n",
    ")\n",
    "results = tuner.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49343e87-1030-400c-b6f3-2e01095ca66b",
   "metadata": {},
   "source": [
    "ensure mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acfae81-73a0-4c54-8093-7ca61e4fa6a0",
   "metadata": {},
   "source": [
    "run study"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b082d416-89a5-4f64-a7a1-ae0b9efb8c48",
   "metadata": {},
   "source": [
    "eval"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
