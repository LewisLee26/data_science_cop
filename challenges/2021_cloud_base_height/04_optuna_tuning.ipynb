{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19a7bbf4-00f4-4b5d-97a9-d6d9138d0f8a",
   "metadata": {},
   "source": [
    "Make initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b97e418c-c396-4b0d-9157-8f201bb9d374",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cbh_data_definitions\n",
    "import pathlib\n",
    "import os\n",
    "\n",
    "import optuna\n",
    "import pytorch_lightning as pl\n",
    "import mlflow\n",
    "from ray import tune\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16443e15-8512-4a3f-a3eb-222764cd03f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# intialize some settings: mlflow, data directory, resources\n",
    "root_data_directory = pathlib.Path(os.environ[\"SCRATCH\"]) / \"cbh_data\"\n",
    "\n",
    "dev_data_path = root_data_directory / \"analysis_ready\" / \"dev_randomized.zarr\"\n",
    "training_data_path = root_data_directory / \"analysis_ready\" / \"train_randomized.zarr\"\n",
    "\n",
    "mlflow_command_line_run = \"\"\"\n",
    "    mlflow server --port 5001 --backend-store-uri sqlite:///mlflowSQLserver.db  --default-artifact-root ./mlflow_artifacts/\n",
    "\"\"\"\n",
    "mlflow_server_address = 'vld425'\n",
    "mlflow_server_port = 5001\n",
    "mlflow_server_uri = f'http://{mlflow_server_address}:{mlflow_server_port:d}'\n",
    "mlflow_artifact_root = pathlib.Path('./mlflow_artifacts/')\n",
    "\n",
    "hparams_for_mlflow = {}\n",
    "\n",
    "CPU_COUNT = 4\n",
    "RAM_GB = 6\n",
    "hparams_for_mlflow['CPU Count'] = CPU_COUNT\n",
    "hparams_for_mlflow['Compute Memory'] = RAM_GB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b14327c-6a24-4cb2-93da-f2697a78be1e",
   "metadata": {},
   "source": [
    "redefine data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e5cba65e-0d9a-4924-93fb-47b4aacc9bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded zarr, file information:\n",
      " Name              : /\n",
      "Type              : zarr.hierarchy.Group\n",
      "Read-only         : False\n",
      "Synchronizer type : zarr.sync.ThreadSynchronizer\n",
      "Store type        : zarr.storage.DirectoryStore\n",
      "No. members       : 2\n",
      "No. arrays        : 2\n",
      "No. groups        : 0\n",
      "Arrays            : cloud_base_label_y.zarr, humidity_temp_pressure_x.zarr\n",
      " \n",
      "\n",
      "Loaded zarr, file information:\n",
      " Name              : /\n",
      "Type              : zarr.hierarchy.Group\n",
      "Read-only         : False\n",
      "Synchronizer type : zarr.sync.ThreadSynchronizer\n",
      "Store type        : zarr.storage.DirectoryStore\n",
      "No. members       : 2\n",
      "No. arrays        : 2\n",
      "No. groups        : 0\n",
      "Arrays            : cloud_base_label_y.zarr, humidity_temp_pressure_x.zarr\n",
      " \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table>\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 87.48 GiB </td>\n",
       "                        <td> 1.82 GiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (111820800, 70, 3) </td>\n",
       "                        <td> (2329600, 70, 3) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Count </th>\n",
       "                        <td> 2 Graph Layers </td>\n",
       "                        <td> 48 Chunks </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                    <th> Type </th>\n",
       "                    <td> float32 </td>\n",
       "                    <td> numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"156\" height=\"146\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"80\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"10\" y1=\"25\" x2=\"80\" y2=\"96\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"10\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"12\" y1=\"2\" x2=\"12\" y2=\"28\" />\n",
       "  <line x1=\"17\" y1=\"7\" x2=\"17\" y2=\"32\" />\n",
       "  <line x1=\"20\" y1=\"10\" x2=\"20\" y2=\"35\" />\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"24\" y2=\"40\" />\n",
       "  <line x1=\"27\" y1=\"17\" x2=\"27\" y2=\"43\" />\n",
       "  <line x1=\"32\" y1=\"22\" x2=\"32\" y2=\"47\" />\n",
       "  <line x1=\"35\" y1=\"25\" x2=\"35\" y2=\"50\" />\n",
       "  <line x1=\"39\" y1=\"29\" x2=\"39\" y2=\"54\" />\n",
       "  <line x1=\"42\" y1=\"32\" x2=\"42\" y2=\"57\" />\n",
       "  <line x1=\"46\" y1=\"36\" x2=\"46\" y2=\"62\" />\n",
       "  <line x1=\"49\" y1=\"39\" x2=\"49\" y2=\"65\" />\n",
       "  <line x1=\"54\" y1=\"44\" x2=\"54\" y2=\"69\" />\n",
       "  <line x1=\"57\" y1=\"47\" x2=\"57\" y2=\"72\" />\n",
       "  <line x1=\"61\" y1=\"51\" x2=\"61\" y2=\"76\" />\n",
       "  <line x1=\"64\" y1=\"54\" x2=\"64\" y2=\"79\" />\n",
       "  <line x1=\"68\" y1=\"58\" x2=\"68\" y2=\"84\" />\n",
       "  <line x1=\"71\" y1=\"61\" x2=\"71\" y2=\"87\" />\n",
       "  <line x1=\"76\" y1=\"66\" x2=\"76\" y2=\"91\" />\n",
       "  <line x1=\"80\" y1=\"70\" x2=\"80\" y2=\"96\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 80.58823529411765,70.58823529411765 80.58823529411765,96.00085180870013 10.0,25.412616514582485\" style=\"fill:#8B4903A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"35\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"12\" y1=\"2\" x2=\"38\" y2=\"2\" />\n",
       "  <line x1=\"17\" y1=\"7\" x2=\"42\" y2=\"7\" />\n",
       "  <line x1=\"20\" y1=\"10\" x2=\"45\" y2=\"10\" />\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"50\" y2=\"14\" />\n",
       "  <line x1=\"27\" y1=\"17\" x2=\"53\" y2=\"17\" />\n",
       "  <line x1=\"32\" y1=\"22\" x2=\"57\" y2=\"22\" />\n",
       "  <line x1=\"35\" y1=\"25\" x2=\"60\" y2=\"25\" />\n",
       "  <line x1=\"39\" y1=\"29\" x2=\"64\" y2=\"29\" />\n",
       "  <line x1=\"42\" y1=\"32\" x2=\"67\" y2=\"32\" />\n",
       "  <line x1=\"46\" y1=\"36\" x2=\"72\" y2=\"36\" />\n",
       "  <line x1=\"49\" y1=\"39\" x2=\"75\" y2=\"39\" />\n",
       "  <line x1=\"54\" y1=\"44\" x2=\"79\" y2=\"44\" />\n",
       "  <line x1=\"57\" y1=\"47\" x2=\"82\" y2=\"47\" />\n",
       "  <line x1=\"61\" y1=\"51\" x2=\"86\" y2=\"51\" />\n",
       "  <line x1=\"64\" y1=\"54\" x2=\"89\" y2=\"54\" />\n",
       "  <line x1=\"68\" y1=\"58\" x2=\"94\" y2=\"58\" />\n",
       "  <line x1=\"71\" y1=\"61\" x2=\"97\" y2=\"61\" />\n",
       "  <line x1=\"76\" y1=\"66\" x2=\"101\" y2=\"66\" />\n",
       "  <line x1=\"80\" y1=\"70\" x2=\"106\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"80\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"35\" y1=\"0\" x2=\"106\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 35.41261651458248,0.0 106.00085180870013,70.58823529411765 80.58823529411765,70.58823529411765\" style=\"fill:#8B4903A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"80\" y1=\"70\" x2=\"106\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"80\" y1=\"96\" x2=\"106\" y2=\"96\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"80\" y1=\"70\" x2=\"80\" y2=\"96\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"106\" y1=\"70\" x2=\"106\" y2=\"96\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"80.58823529411765,70.58823529411765 106.00085180870013,70.58823529411765 106.00085180870013,96.00085180870013 80.58823529411765,96.00085180870013\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"93.294544\" y=\"116.000852\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >3</text>\n",
       "  <text x=\"126.000852\" y=\"83.294544\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(0,126.000852,83.294544)\">70</text>\n",
       "  <text x=\"35.294118\" y=\"80.706734\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(45,35.294118,80.706734)\">111820800</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<from-zarr, shape=(111820800, 70, 3), dtype=float32, chunksize=(2329600, 70, 3), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# init data\n",
    "(\n",
    "    train_input,\n",
    "    train_labels,\n",
    "    _,\n",
    ") = cbh_data_definitions.load_data_from_zarr(training_data_path)\n",
    "\n",
    "(\n",
    "    dev_input, \n",
    "    dev_labels, \n",
    "    _\n",
    ") = cbh_data_definitions.load_data_from_zarr(dev_data_path)\n",
    "\n",
    "# the cloud volume is not needed for the task, so isn't saved on the load\n",
    "# show a chunk\n",
    "train_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "edeea09a-8bd8-4313-a7ea-7fd8d37bf4ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factors of chunk:  [1, 2, 4, 5, 7, 8, 10, 13, 14, 16, 20, 25, 26, 28, 32, 35, 40, 50, 52, 56, 64, 65, 70, 80, 91, 100, 104, 112, 128, 130, 140, 160, 175, 182, 200, 208, 224, 256, 260, 280, 320, 325, 350, 364, 400, 416, 448, 455, 512, 520, 560, 640, 650, 700, 728, 800, 832, 896, 910, 1024, 1040, 1120, 1280, 1300, 1400, 1456, 1600, 1664, 1792, 1820, 2080, 2240, 2275, 2560, 2600, 2800, 2912, 3200, 3328, 3584, 3640, 4160, 4480, 4550, 5120, 5200, 5600, 5824, 6400, 6656, 7168, 7280, 8320, 8960, 9100, 10400, 11200, 11648, 12800, 13312, 14560, 16640, 17920, 18200, 20800, 22400, 23296, 25600, 29120, 33280, 35840, 36400, 41600, 44800, 46592, 58240, 66560, 72800, 83200, 89600, 93184, 116480, 145600, 166400, 179200, 232960, 291200, 332800, 465920, 582400, 1164800, 2329600]\n"
     ]
    }
   ],
   "source": [
    "# limit the data by a factor for less data in a tuning trial\n",
    "factors_of_chunk = [n for n in range(1, train_input.chunksize[0] + 1) if train_input.chunksize[0] % n == 0]\n",
    "print(\"Factors of chunk: \", factors_of_chunk)\n",
    "hparams_for_mlflow['Limited sample number'] =  -1\n",
    "factors_for_hparam_choice = [factor for factor in factors_of_chunk if (factor<3300 and factor>3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbae1c6-5501-40e7-a2ba-4b1ef270f170",
   "metadata": {},
   "source": [
    "setup study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aaa35a93-c33d-4e81-b5f9-4a235028ac38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating experiment\n",
      "Success\n"
     ]
    }
   ],
   "source": [
    "class MLFlowLogger(pl.loggers.MLFlowLogger): #overwrite mlflogger\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def after_save_checkpoint(self, model_checkpoint: pl.callbacks.ModelCheckpoint) -> None:\n",
    "        \"\"\"\n",
    "        Called after model checkpoint callback saves a new checkpoint.\n",
    "        \"\"\"\n",
    "        best_chkpt = torch.load(model_checkpoint.best_model_path)\n",
    "        # print(best_chkpt)\n",
    "        # print(best_chkpt['callbacks'])\n",
    "        checkpoint_for_mlflow = {\n",
    "            \"val loss\": float(best_chkpt['callbacks'][list(key for key in list(best_chkpt['callbacks'].keys()) if \"ModelCheckpoint\" in key)[0]]['current_score']),\n",
    "            \"train loss at step-1\": list(train_loss_metric.value for train_loss_metric in mlf_logger._mlflow_client.get_metric_history(run.info.run_id, \"Train loss\") if (int(train_loss_metric.step) == int(best_chkpt['global_step']-1)))[0],\n",
    "            \"global_step\": best_chkpt['global_step'],\n",
    "            \"model_state_dict\": best_chkpt['state_dict'],\n",
    "            \"checkpoint\": best_chkpt,\n",
    "        }\n",
    "        with TemporaryDirectory() as tmpdirname:\n",
    "            f_name = os.path.join(tmpdirname, f\"{run.info.run_id}-best_model_checkpoint-step_{best_chkpt['global_step']}.pt\")\n",
    "            torch.save(checkpoint_for_mlflow, f_name)\n",
    "            mlflow.log_artifact(f_name)\n",
    "\n",
    "experiment_name = 'cbh-hparam-tuning'\n",
    "\n",
    "mlflow.set_tracking_uri(mlflow_server_uri)\n",
    "# make vars global\n",
    "mlf_exp = None\n",
    "mlf_exp_id = None\n",
    "try: \n",
    "    print('Creating experiment')\n",
    "    mlf_exp_id = mlflow.create_experiment(experiment_name)\n",
    "    mlf_exp = mlflow.get_experiment(mlf_exp_id)\n",
    "except mlflow.exceptions.RestException:\n",
    "    mlf_exp = mlflow.get_experiment_by_name(experiment_name)\n",
    "print(\"Success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "90bd6235-7bfe-4bd1-aa06-ae1f5f86c223",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_node_num_exclusive = 513\n",
    "'num_workers':WORKERS_CPU_COUNT,\n",
    "'pin_memory':False,\n",
    "'collate_fn':collate_fn,\n",
    "'thread_count_for_dask':CPU_COUNT\n",
    "max_time = \"00:02:00:00\"  # dd:hh:mm:ss\n",
    "hparams_for_mlflow[\"Training timeout\"] = max_time\n",
    "\n",
    "mlp_search_space = {\n",
    "    \"epoch\": 1,\n",
    "    \"lr\": tune.quniform(0.0001, 0.01, 0.00005),\n",
    "    \"data_limit\": tune.randint(4, int(len(train_labels.chunks[0]) / 4)), # multiple chunk ind by chunklen: train_input.chunksize[0])\n",
    "    # \"activation\": tune.choice([\"relu\", \"tanh\"]),\n",
    "    \"batch_size\": tune.choice(factors_for_hparam_choice),\n",
    "    \"arch_name\":\"MLP\",\n",
    "    \"layers\":tune.randint(1,11),\n",
    "    \"activation\":tune.choice([\"relu\", \"tanh\"]),\n",
    "    \"input_size\":(train_input.shape[2] * train_input.shape[1]),\n",
    "    \"output_size\": train_input.shape[1],\n",
    "    \"layer_node_num\": tune.sample_from(lambda spec: 8*np.random.randint(1,int(max_node_num_exclusive/8), size=spec.config.layers)),\n",
    "    \n",
    "}\n",
    "                     \n",
    "                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "076ee9ae-57f6-4d17-90f3-e44b920af3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(ray_config):\n",
    "    # def model hparams with config\n",
    "    print(ray_config)\n",
    "\n",
    "    # def data (to ensure new data for each trial)\n",
    "    train_loader = cbh_data_definitions.define_data_get_loader_1chunk(\n",
    "        train_input,\n",
    "        train_labels,\n",
    "        shuffle=shuffle_training_data,\n",
    "        **data_loader_hparam_dict\n",
    "    )\n",
    "    val_loader = cbh_data_definitions.define_data_get_loader_1chunk(\n",
    "        dev_input,\n",
    "        dev_labels,\n",
    "        shuffle=False,\n",
    "        **data_loader_hparam_dict\n",
    "    )\n",
    "    # def trainer\n",
    "\n",
    "    timestamp_template = '{dt.year:04d}{dt.month:02d}{dt.day:02d}T{dt.hour:02d}{dt.minute:02d}{dt.second:02d}'\n",
    "    run_name_template = 'cbh_challenge_{network_name}_' + timestamp_template\n",
    "    current_run_name = run_name_template.format(network_name=model.__class__.__name__,\n",
    "                                                    dt=datetime.datetime.now()\n",
    "                                                   )\n",
    "\n",
    "# with Profiler() as prof, ResourceProfiler(dt=0.25) as rprof, CacheProfiler() as cprof:\n",
    "    with mlflow.start_run(experiment_id=mlf_exp.experiment_id, run_name=current_run_name) as run:\n",
    "\n",
    "        mlflow.pytorch.autolog()\n",
    "        mlf_logger = MLFlowLogger(experiment_name=experiment_name, tracking_uri=mlflow_server_uri, run_id=run.info.run_id)\n",
    "\n",
    "        # define trainer\n",
    "        time_for_checkpoint = datetime.timedelta(minutes=15)\n",
    "        checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "            train_time_interval=time_for_checkpoint,\n",
    "            dirpath=run.info.artifact_uri,\n",
    "            monitor=\"Val loss\",\n",
    "            save_on_train_epoch_end=False,\n",
    "            mode=\"min\"\n",
    "        )\n",
    "        callbacks = [checkpoint_callback, RichProgressBar()]\n",
    "        \n",
    "        trainer_hparams = {\n",
    "            'max_epochs':epochs,\n",
    "            'deterministic':True,\n",
    "            'val_check_interval':0.05, # val every percentage of the data\n",
    "            'devices':\"auto\",\n",
    "            'accelerator':\"auto\",\n",
    "            'max_time':max_time,\n",
    "            'replace_sampler_ddp':False,\n",
    "            'enable_checkpointing':True,\n",
    "            'strategy':None,\n",
    "            'callbacks':callbacks,\n",
    "            'logger':mlf_logger,\n",
    "        }\n",
    "        \n",
    "        hparams_for_mlflow[\"Trainer hparams\"] = trainer_hparams\n",
    "        mlf_logger.log_hyperparams(hparams_for_mlflow)\n",
    "        \n",
    "        trainer = pl.Trainer(\n",
    "            **trainer_hparams\n",
    "        )\n",
    "\n",
    "        trainer.fit(model=model, train_dataloaders=train_loader, val_dataloaders=val_loader)\n",
    "        path_to_save = '{dt.year:04d}{dt.month:02d}{dt.day:02d}-{dt.hour:02d}{dt.minute:02d}{dt.second:02d}'.format(dt=datetime.datetime.now())\n",
    "        trainer.save_checkpoint(filepath=run.info.artifact_uri + f'/post_epoch_modelchkpt_{path_to_save}')\n",
    "    return trainer.callback_metrics[\"val_acc\"].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "475ff4ee-30a6-4224-8833-da8301e9edc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-10 13:40:32,210\tINFO worker.py:1518 -- Started a local Ray instance.\n",
      "2022-11-10 13:40:33,924\tWARNING function_trainable.py:619 -- Function checkpointing is disabled. This may result in unexpected behavior when using checkpointing features or certain schedulers. To enable, set the train function arguments to be `func(config, checkpoint_dir=None)`.\n",
      "/home/h02/hsouth/.conda/envs/py-lightning/lib/python3.10/site-packages/ray/tune/search/optuna/optuna_search.py:679: FutureWarning: DiscreteUniformDistribution has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :class:`~optuna.distributions.FloatDistribution` instead.\n",
      "  return ot.distributions.DiscreteUniformDistribution(\n",
      "/home/h02/hsouth/.conda/envs/py-lightning/lib/python3.10/site-packages/ray/tune/search/optuna/optuna_search.py:694: FutureWarning: IntUniformDistribution has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :class:`~optuna.distributions.IntDistribution` instead.\n",
      "  return ot.distributions.IntUniformDistribution(\n",
      "/home/h02/hsouth/.conda/envs/py-lightning/lib/python3.10/site-packages/optuna/distributions.py:683: UserWarning: The distribution is specified by [4, 12] and step=2329600, but the range is not divisible by `step`. It will be replaced by [4, 4].\n",
      "  warnings.warn(\n",
      "/home/h02/hsouth/.conda/envs/py-lightning/lib/python3.10/site-packages/optuna/distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {'arch_name': 'MLP', 'layers': <ray.tune.search.sample.Integer object at 0x7fb639f94be0>, 'nodes_in_layers': <ray.tune.search.sample.Integer object at 0x7fb639f94c10>, 'activation': <ray.tune.search.sample.Categorical object at 0x7fb639f94cd0>, 'input_size': 210, 'output_size': 70} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "/home/h02/hsouth/.conda/envs/py-lightning/lib/python3.10/site-packages/optuna/distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {'arch_name': 'LSTM', 'input_size': 3, 'lstm_layers': 1, 'lstm_hidden_size': 8, 'output_size': 1, 'height_dimension': 70, 'embed_size': 1, 'BILSTM': False, 'batch_first': True} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "\u001b[32m[I 2022-11-10 13:40:33,975]\u001b[0m A new study created in memory with name: optuna\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-11-10 13:40:41 (running for 00:00:06.99)<br>Memory usage on this node: 5.4/7.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/4 CPUs, 0/0 GPUs, 0.0/1.96 GiB heap, 0.0/0.98 GiB objects<br>Result logdir: /home/h02/hsouth/ray_results/objective_2022-11-10_13-40-26<br>Number of trials: 1/50 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name        </th><th>status  </th><th>loc                </th><th>arch_choice/BILSTM  </th><th>arch_choice/arch_...  </th><th>arch_choice/batch...  </th><th style=\"text-align: right;\">  arch_choice/embed...</th><th style=\"text-align: right;\">  arch_choice/heigh...</th><th style=\"text-align: right;\">  arch_choice/input...</th><th style=\"text-align: right;\">  arch_choice/lstm_...</th><th style=\"text-align: right;\">  arch_choice/lstm_...</th><th style=\"text-align: right;\">  arch_choice/outpu...</th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  data_limit</th><th style=\"text-align: right;\">     lr</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>objective_4066a0a2</td><td>RUNNING </td><td>10.152.49.117:43885</td><td>False               </td><td>LSTM                  </td><td>True                  </td><td style=\"text-align: right;\">                     1</td><td style=\"text-align: right;\">                    70</td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">                     8</td><td style=\"text-align: right;\">                     1</td><td style=\"text-align: right;\">                     1</td><td style=\"text-align: right;\">         910</td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">0.00485</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/h02/hsouth/.conda/envs/py-lightning/lib/python3.10/site-packages/optuna/distributions.py:766: FutureWarning: DiscreteUniformDistribution(high=0.01, low=0.0001, q=5e-05) is deprecated and internally converted to FloatDistribution(high=0.01, log=False, low=0.0001, step=5e-05). See https://github.com/optuna/optuna/issues/2941.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/h02/hsouth/.conda/envs/py-lightning/lib/python3.10/site-packages/optuna/distributions.py:766: FutureWarning: IntUniformDistribution(high=4, low=4, step=2329600) is deprecated and internally converted to IntDistribution(high=4, log=False, low=4, step=2329600). See https://github.com/optuna/optuna/issues/2941.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(objective pid=43885)\u001b[0m {'epoch': 1, 'lr': 0.00485, 'data_limit': 4, 'batch_size': 910, 'arch_choice': {'arch_name': 'LSTM', 'input_size': 3, 'lstm_layers': 1, 'lstm_hidden_size': 8, 'output_size': 1, 'height_dimension': 70, 'embed_size': 1, 'BILSTM': False, 'batch_first': True}}\n"
     ]
    },
    {
     "ename": "TuneError",
     "evalue": "Tune run failed. Please use tuner = Tuner.restore(\"/home/h02/hsouth/ray_results/objective_2022-11-10_13-40-26\") to resume.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/.conda/envs/py-lightning/lib/python3.10/site-packages/ray/tune/execution/trial_runner.py:846\u001b[0m, in \u001b[0;36mTrialRunner._wait_and_handle_event\u001b[0;34m(self, next_trial)\u001b[0m\n\u001b[1;32m    845\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m _ExecutorEventType\u001b[38;5;241m.\u001b[39mTRAINING_RESULT:\n\u001b[0;32m--> 846\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_on_training_result\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[43m_ExecutorEvent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mKEY_FUTURE_RESULT\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/py-lightning/lib/python3.10/site-packages/ray/tune/execution/trial_runner.py:971\u001b[0m, in \u001b[0;36mTrialRunner._on_training_result\u001b[0;34m(self, trial, result)\u001b[0m\n\u001b[1;32m    970\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m warn_if_slow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprocess_trial_result\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 971\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_trial_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/py-lightning/lib/python3.10/site-packages/ray/tune/execution/trial_runner.py:1055\u001b[0m, in \u001b[0;36mTrialRunner._process_trial_results\u001b[0;34m(self, trial, results)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m warn_if_slow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprocess_trial_result\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1055\u001b[0m     decision \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_trial_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1056\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m decision \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1057\u001b[0m     \u001b[38;5;66;03m# If we didn't get a decision, this means a\u001b[39;00m\n\u001b[1;32m   1058\u001b[0m     \u001b[38;5;66;03m# non-training future (e.g. a save) was scheduled.\u001b[39;00m\n\u001b[1;32m   1059\u001b[0m     \u001b[38;5;66;03m# We do not allow processing more results then.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/py-lightning/lib/python3.10/site-packages/ray/tune/execution/trial_runner.py:1092\u001b[0m, in \u001b[0;36mTrialRunner._process_trial_result\u001b[0;34m(self, trial, result)\u001b[0m\n\u001b[1;32m   1091\u001b[0m flat_result \u001b[38;5;241m=\u001b[39m flatten_dict(result)\n\u001b[0;32m-> 1092\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_result_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflat_result\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1094\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stopper(trial\u001b[38;5;241m.\u001b[39mtrial_id, result) \u001b[38;5;129;01mor\u001b[39;00m trial\u001b[38;5;241m.\u001b[39mshould_stop(flat_result):\n",
      "File \u001b[0;32m~/.conda/envs/py-lightning/lib/python3.10/site-packages/ray/tune/execution/trial_runner.py:1188\u001b[0m, in \u001b[0;36mTrialRunner._validate_result_metrics\u001b[0;34m(self, result)\u001b[0m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m report_metric:\n\u001b[0;32m-> 1188\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1189\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrial returned a result which did not include the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1190\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspecified metric(s) `\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m` that `\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m` expects. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1191\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMake sure your calls to `tune.report()` include the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1192\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetric, or set the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTUNE_DISABLE_STRICT_METRIC_CHECKING \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1194\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menvironment variable to 1. Result: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1195\u001b[0m             report_metric, location, result\n\u001b[1;32m   1196\u001b[0m         )\n\u001b[1;32m   1197\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Trial returned a result which did not include the specified metric(s) `val_loss` that `SearchGenerator` expects. Make sure your calls to `tune.report()` include the metric, or set the TUNE_DISABLE_STRICT_METRIC_CHECKING environment variable to 1. Result: {'_metric': 1, 'time_this_iter_s': 0.016492366790771484, 'done': False, 'timesteps_total': None, 'episodes_total': None, 'training_iteration': 1, 'trial_id': '4066a0a2', 'experiment_id': 'bde28f947ee34c83af24bd9e51890165', 'date': '2022-11-10_13-40-41', 'timestamp': 1668087641, 'time_total_s': 0.016492366790771484, 'pid': 43885, 'hostname': 'vld425', 'node_ip': '10.152.49.117', 'time_since_restore': 0.016492366790771484, 'timesteps_since_restore': 0, 'iterations_since_restore': 1, 'warmup_time': 0.005758762359619141, 'config/epoch': 1, 'config/lr': 0.00485, 'config/data_limit': 4, 'config/batch_size': 910, 'config/arch_choice/arch_name': 'LSTM', 'config/arch_choice/input_size': 3, 'config/arch_choice/lstm_layers': 1, 'config/arch_choice/lstm_hidden_size': 8, 'config/arch_choice/output_size': 1, 'config/arch_choice/height_dimension': 70, 'config/arch_choice/embed_size': 1, 'config/arch_choice/BILSTM': False, 'config/arch_choice/batch_first': True}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTuneError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/.conda/envs/py-lightning/lib/python3.10/site-packages/ray/tune/tuner.py:234\u001b[0m, in \u001b[0;36mTuner.fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_local_tuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.conda/envs/py-lightning/lib/python3.10/site-packages/ray/tune/impl/tuner_internal.py:283\u001b[0m, in \u001b[0;36mTunerInternal.fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    282\u001b[0m     param_space \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_param_space)\n\u001b[0;32m--> 283\u001b[0m     analysis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_space\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/py-lightning/lib/python3.10/site-packages/ray/tune/impl/tuner_internal.py:380\u001b[0m, in \u001b[0;36mTunerInternal._fit_internal\u001b[0;34m(self, trainable, param_space)\u001b[0m\n\u001b[1;32m    367\u001b[0m args \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    368\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tune_run_arguments(trainable),\n\u001b[1;32m    369\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mdict\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    378\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tuner_kwargs,\n\u001b[1;32m    379\u001b[0m }\n\u001b[0;32m--> 380\u001b[0m analysis \u001b[38;5;241m=\u001b[39m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m analysis\n",
      "File \u001b[0;32m~/.conda/envs/py-lightning/lib/python3.10/site-packages/ray/tune/tune.py:722\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, local_dir, search_alg, scheduler, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, sync_config, export_formats, max_failures, fail_fast, restore, server_port, resume, reuse_actors, trial_executor, raise_on_failed_trial, callbacks, max_concurrent_trials, _experiment_checkpoint_dir, _remote)\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mis_finished() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msignal\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m--> 722\u001b[0m     \u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    723\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m has_verbosity(Verbosity\u001b[38;5;241m.\u001b[39mV1_EXPERIMENT):\n",
      "File \u001b[0;32m~/.conda/envs/py-lightning/lib/python3.10/site-packages/ray/tune/execution/trial_runner.py:879\u001b[0m, in \u001b[0;36mTrialRunner.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    877\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot new trial to run: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnext_trial\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 879\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_and_handle_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnext_trial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop_experiment_if_needed()\n",
      "File \u001b[0;32m~/.conda/envs/py-lightning/lib/python3.10/site-packages/ray/tune/execution/trial_runner.py:858\u001b[0m, in \u001b[0;36mTrialRunner._wait_and_handle_event\u001b[0;34m(self, next_trial)\u001b[0m\n\u001b[1;32m    857\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 858\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m TuneError(traceback\u001b[38;5;241m.\u001b[39mformat_exc())\n",
      "\u001b[0;31mTuneError\u001b[0m: Traceback (most recent call last):\n  File \"/home/h02/hsouth/.conda/envs/py-lightning/lib/python3.10/site-packages/ray/tune/execution/trial_runner.py\", line 846, in _wait_and_handle_event\n    self._on_training_result(\n  File \"/home/h02/hsouth/.conda/envs/py-lightning/lib/python3.10/site-packages/ray/tune/execution/trial_runner.py\", line 971, in _on_training_result\n    self._process_trial_results(trial, result)\n  File \"/home/h02/hsouth/.conda/envs/py-lightning/lib/python3.10/site-packages/ray/tune/execution/trial_runner.py\", line 1055, in _process_trial_results\n    decision = self._process_trial_result(trial, result)\n  File \"/home/h02/hsouth/.conda/envs/py-lightning/lib/python3.10/site-packages/ray/tune/execution/trial_runner.py\", line 1092, in _process_trial_result\n    self._validate_result_metrics(flat_result)\n  File \"/home/h02/hsouth/.conda/envs/py-lightning/lib/python3.10/site-packages/ray/tune/execution/trial_runner.py\", line 1188, in _validate_result_metrics\n    raise ValueError(\nValueError: Trial returned a result which did not include the specified metric(s) `val_loss` that `SearchGenerator` expects. Make sure your calls to `tune.report()` include the metric, or set the TUNE_DISABLE_STRICT_METRIC_CHECKING environment variable to 1. Result: {'_metric': 1, 'time_this_iter_s': 0.016492366790771484, 'done': False, 'timesteps_total': None, 'episodes_total': None, 'training_iteration': 1, 'trial_id': '4066a0a2', 'experiment_id': 'bde28f947ee34c83af24bd9e51890165', 'date': '2022-11-10_13-40-41', 'timestamp': 1668087641, 'time_total_s': 0.016492366790771484, 'pid': 43885, 'hostname': 'vld425', 'node_ip': '10.152.49.117', 'time_since_restore': 0.016492366790771484, 'timesteps_since_restore': 0, 'iterations_since_restore': 1, 'warmup_time': 0.005758762359619141, 'config/epoch': 1, 'config/lr': 0.00485, 'config/data_limit': 4, 'config/batch_size': 910, 'config/arch_choice/arch_name': 'LSTM', 'config/arch_choice/input_size': 3, 'config/arch_choice/lstm_layers': 1, 'config/arch_choice/lstm_hidden_size': 8, 'config/arch_choice/output_size': 1, 'config/arch_choice/height_dimension': 70, 'config/arch_choice/embed_size': 1, 'config/arch_choice/BILSTM': False, 'config/arch_choice/batch_first': True}\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTuneError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [46], line 19\u001b[0m\n\u001b[1;32m      9\u001b[0m num_hparam_trials \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m\n\u001b[1;32m     11\u001b[0m tuner \u001b[38;5;241m=\u001b[39m tune\u001b[38;5;241m.\u001b[39mTuner(\n\u001b[1;32m     12\u001b[0m     objective,\n\u001b[1;32m     13\u001b[0m     tune_config\u001b[38;5;241m=\u001b[39mtune\u001b[38;5;241m.\u001b[39mTuneConfig(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m     param_space\u001b[38;5;241m=\u001b[39msearch_space\n\u001b[1;32m     18\u001b[0m )\n\u001b[0;32m---> 19\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/py-lightning/lib/python3.10/site-packages/ray/tune/tuner.py:236\u001b[0m, in \u001b[0;36mTuner.fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_local_tuner\u001b[38;5;241m.\u001b[39mfit()\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 236\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m TuneError(\n\u001b[1;32m    237\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTune run failed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    238\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPlease use tuner = Tuner.restore(\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    239\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_local_tuner\u001b[38;5;241m.\u001b[39mget_experiment_checkpoint_dir()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m) to resume.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    240\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    242\u001b[0m     experiment_checkpoint_dir \u001b[38;5;241m=\u001b[39m ray\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m    243\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_remote_tuner\u001b[38;5;241m.\u001b[39mget_experiment_checkpoint_dir\u001b[38;5;241m.\u001b[39mremote()\n\u001b[1;32m    244\u001b[0m     )\n",
      "\u001b[0;31mTuneError\u001b[0m: Tune run failed. Please use tuner = Tuner.restore(\"/home/h02/hsouth/ray_results/objective_2022-11-10_13-40-26\") to resume."
     ]
    }
   ],
   "source": [
    "import ray\n",
    "import ray.tune\n",
    "import ray.tune.search\n",
    "import ray.tune.search.optuna\n",
    "from ray.tune.search.optuna import OptunaSearch\n",
    "from ray.tune.search import ConcurrencyLimiter\n",
    "searcher = OptunaSearch(metric=[\"val_loss\"], mode=[\"min\"])\n",
    "algo = ConcurrencyLimiter(searcher, max_concurrent=int(CPU_COUNT*(3/4)))\n",
    "num_hparam_trials = 50\n",
    "\n",
    "tuner = tune.Tuner(\n",
    "    objective,\n",
    "    tune_config=tune.TuneConfig(\n",
    "        search_alg=algo,\n",
    "        num_samples=num_hparam_trials,\n",
    "    ),\n",
    "    param_space=search_space\n",
    ")\n",
    "results = tuner.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49343e87-1030-400c-b6f3-2e01095ca66b",
   "metadata": {},
   "source": [
    "ensure mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acfae81-73a0-4c54-8093-7ca61e4fa6a0",
   "metadata": {},
   "source": [
    "run study"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b082d416-89a5-4f64-a7a1-ae0b9efb8c48",
   "metadata": {},
   "source": [
    "eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a683d4b2-63da-4950-9da1-ccb8439213f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
