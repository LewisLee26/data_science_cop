{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19a7bbf4-00f4-4b5d-97a9-d6d9138d0f8a",
   "metadata": {},
   "source": [
    "Make initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b97e418c-c396-4b0d-9157-8f201bb9d374",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cbh_data_definitions\n",
    "import pathlib\n",
    "import os\n",
    "\n",
    "import optuna\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import mlflow\n",
    "from ray import tune\n",
    "import ray\n",
    "import ray.tune\n",
    "from tempfile import TemporaryDirectory\n",
    "import ray.tune.search\n",
    "import ray.tune.search.optuna\n",
    "from ray.tune.search.optuna import OptunaSearch\n",
    "from ray.tune.integration.mlflow import mlflow_mixin\n",
    "from ray.tune.search import ConcurrencyLimiter\n",
    "from pytorch_lightning.callbacks import TQDMProgressBar\n",
    "from ray.tune.integration.pytorch_lightning import TuneReportCallback\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "import datetime\n",
    "import cbh_torch_MLP\n",
    "import cbh_torch_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16443e15-8512-4a3f-a3eb-222764cd03f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# intialize some settings: mlflow, data directory, resources\n",
    "root_data_directory = pathlib.Path(os.environ[\"SCRATCH\"]) / \"cbh_data\"\n",
    "\n",
    "dev_data_path = root_data_directory / \"analysis_ready\" / \"dev_randomized.zarr\"\n",
    "training_data_path = root_data_directory / \"analysis_ready\" / \"train_randomized.zarr\"\n",
    "\n",
    "mlflow_command_line_run = \"\"\"\n",
    "    mlflow server --port 5001 --backend-store-uri sqlite:///mlflowSQLserver.db  --default-artifact-root ./mlflow_artifacts/\n",
    "\"\"\"\n",
    "mlflow_server_address = 'vld425'\n",
    "mlflow_server_port = 5001\n",
    "mlflow_server_uri = f'http://{mlflow_server_address}:{mlflow_server_port:d}'\n",
    "mlflow_artifact_root = pathlib.Path('./mlflow_artifacts/')\n",
    "\n",
    "hparams_for_mlflow = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b14327c-6a24-4cb2-93da-f2697a78be1e",
   "metadata": {},
   "source": [
    "redefine data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5cba65e-0d9a-4924-93fb-47b4aacc9bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded zarr, file information:\n",
      " Name              : /\n",
      "Type              : zarr.hierarchy.Group\n",
      "Read-only         : False\n",
      "Synchronizer type : zarr.sync.ThreadSynchronizer\n",
      "Store type        : zarr.storage.DirectoryStore\n",
      "No. members       : 2\n",
      "No. arrays        : 2\n",
      "No. groups        : 0\n",
      "Arrays            : cloud_base_label_y.zarr, humidity_temp_pressure_x.zarr\n",
      " \n",
      "\n",
      "Loaded zarr, file information:\n",
      " Name              : /\n",
      "Type              : zarr.hierarchy.Group\n",
      "Read-only         : False\n",
      "Synchronizer type : zarr.sync.ThreadSynchronizer\n",
      "Store type        : zarr.storage.DirectoryStore\n",
      "No. members       : 2\n",
      "No. arrays        : 2\n",
      "No. groups        : 0\n",
      "Arrays            : cloud_base_label_y.zarr, humidity_temp_pressure_x.zarr\n",
      " \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table>\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 87.48 GiB </td>\n",
       "                        <td> 1.82 GiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (111820800, 70, 3) </td>\n",
       "                        <td> (2329600, 70, 3) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Count </th>\n",
       "                        <td> 2 Graph Layers </td>\n",
       "                        <td> 48 Chunks </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                    <th> Type </th>\n",
       "                    <td> float32 </td>\n",
       "                    <td> numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"156\" height=\"146\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"80\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"10\" y1=\"25\" x2=\"80\" y2=\"96\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"10\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"12\" y1=\"2\" x2=\"12\" y2=\"28\" />\n",
       "  <line x1=\"17\" y1=\"7\" x2=\"17\" y2=\"32\" />\n",
       "  <line x1=\"20\" y1=\"10\" x2=\"20\" y2=\"35\" />\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"24\" y2=\"40\" />\n",
       "  <line x1=\"27\" y1=\"17\" x2=\"27\" y2=\"43\" />\n",
       "  <line x1=\"32\" y1=\"22\" x2=\"32\" y2=\"47\" />\n",
       "  <line x1=\"35\" y1=\"25\" x2=\"35\" y2=\"50\" />\n",
       "  <line x1=\"39\" y1=\"29\" x2=\"39\" y2=\"54\" />\n",
       "  <line x1=\"42\" y1=\"32\" x2=\"42\" y2=\"57\" />\n",
       "  <line x1=\"46\" y1=\"36\" x2=\"46\" y2=\"62\" />\n",
       "  <line x1=\"49\" y1=\"39\" x2=\"49\" y2=\"65\" />\n",
       "  <line x1=\"54\" y1=\"44\" x2=\"54\" y2=\"69\" />\n",
       "  <line x1=\"57\" y1=\"47\" x2=\"57\" y2=\"72\" />\n",
       "  <line x1=\"61\" y1=\"51\" x2=\"61\" y2=\"76\" />\n",
       "  <line x1=\"64\" y1=\"54\" x2=\"64\" y2=\"79\" />\n",
       "  <line x1=\"68\" y1=\"58\" x2=\"68\" y2=\"84\" />\n",
       "  <line x1=\"71\" y1=\"61\" x2=\"71\" y2=\"87\" />\n",
       "  <line x1=\"76\" y1=\"66\" x2=\"76\" y2=\"91\" />\n",
       "  <line x1=\"80\" y1=\"70\" x2=\"80\" y2=\"96\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 80.58823529411765,70.58823529411765 80.58823529411765,96.00085180870013 10.0,25.412616514582485\" style=\"fill:#8B4903A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"35\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"12\" y1=\"2\" x2=\"38\" y2=\"2\" />\n",
       "  <line x1=\"17\" y1=\"7\" x2=\"42\" y2=\"7\" />\n",
       "  <line x1=\"20\" y1=\"10\" x2=\"45\" y2=\"10\" />\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"50\" y2=\"14\" />\n",
       "  <line x1=\"27\" y1=\"17\" x2=\"53\" y2=\"17\" />\n",
       "  <line x1=\"32\" y1=\"22\" x2=\"57\" y2=\"22\" />\n",
       "  <line x1=\"35\" y1=\"25\" x2=\"60\" y2=\"25\" />\n",
       "  <line x1=\"39\" y1=\"29\" x2=\"64\" y2=\"29\" />\n",
       "  <line x1=\"42\" y1=\"32\" x2=\"67\" y2=\"32\" />\n",
       "  <line x1=\"46\" y1=\"36\" x2=\"72\" y2=\"36\" />\n",
       "  <line x1=\"49\" y1=\"39\" x2=\"75\" y2=\"39\" />\n",
       "  <line x1=\"54\" y1=\"44\" x2=\"79\" y2=\"44\" />\n",
       "  <line x1=\"57\" y1=\"47\" x2=\"82\" y2=\"47\" />\n",
       "  <line x1=\"61\" y1=\"51\" x2=\"86\" y2=\"51\" />\n",
       "  <line x1=\"64\" y1=\"54\" x2=\"89\" y2=\"54\" />\n",
       "  <line x1=\"68\" y1=\"58\" x2=\"94\" y2=\"58\" />\n",
       "  <line x1=\"71\" y1=\"61\" x2=\"97\" y2=\"61\" />\n",
       "  <line x1=\"76\" y1=\"66\" x2=\"101\" y2=\"66\" />\n",
       "  <line x1=\"80\" y1=\"70\" x2=\"106\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"80\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"35\" y1=\"0\" x2=\"106\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 35.41261651458248,0.0 106.00085180870013,70.58823529411765 80.58823529411765,70.58823529411765\" style=\"fill:#8B4903A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"80\" y1=\"70\" x2=\"106\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"80\" y1=\"96\" x2=\"106\" y2=\"96\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"80\" y1=\"70\" x2=\"80\" y2=\"96\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"106\" y1=\"70\" x2=\"106\" y2=\"96\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"80.58823529411765,70.58823529411765 106.00085180870013,70.58823529411765 106.00085180870013,96.00085180870013 80.58823529411765,96.00085180870013\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"93.294544\" y=\"116.000852\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >3</text>\n",
       "  <text x=\"126.000852\" y=\"83.294544\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(0,126.000852,83.294544)\">70</text>\n",
       "  <text x=\"35.294118\" y=\"80.706734\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(45,35.294118,80.706734)\">111820800</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<from-zarr, shape=(111820800, 70, 3), dtype=float32, chunksize=(2329600, 70, 3), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# init data\n",
    "(\n",
    "    train_input,\n",
    "    train_labels,\n",
    "    _,\n",
    ") = cbh_data_definitions.load_data_from_zarr(training_data_path)\n",
    "\n",
    "(\n",
    "    dev_input, \n",
    "    dev_labels, \n",
    "    _\n",
    ") = cbh_data_definitions.load_data_from_zarr(dev_data_path)\n",
    "\n",
    "# the cloud volume is not needed for the task, so isn't saved on the load\n",
    "# show a chunk\n",
    "train_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edeea09a-8bd8-4313-a7ea-7fd8d37bf4ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factors of chunk:  [1, 2, 4, 5, 7, 8, 10, 13, 14, 16, 20, 25, 26, 28, 32, 35, 40, 50, 52, 56, 64, 65, 70, 80, 91, 100, 104, 112, 128, 130, 140, 160, 175, 182, 200, 208, 224, 256, 260, 280, 320, 325, 350, 364, 400, 416, 448, 455, 512, 520, 560, 640, 650, 700, 728, 800, 832, 896, 910, 1024, 1040, 1120, 1280, 1300, 1400, 1456, 1600, 1664, 1792, 1820, 2080, 2240, 2275, 2560, 2600, 2800, 2912, 3200, 3328, 3584, 3640, 4160, 4480, 4550, 5120, 5200, 5600, 5824, 6400, 6656, 7168, 7280, 8320, 8960, 9100, 10400, 11200, 11648, 12800, 13312, 14560, 16640, 17920, 18200, 20800, 22400, 23296, 25600, 29120, 33280, 35840, 36400, 41600, 44800, 46592, 58240, 66560, 72800, 83200, 89600, 93184, 116480, 145600, 166400, 179200, 232960, 291200, 332800, 465920, 582400, 1164800, 2329600]\n"
     ]
    }
   ],
   "source": [
    "# limit the data by a factor for less data in a tuning trial\n",
    "factors_of_chunk = [n for n in range(1, train_input.chunksize[0] + 1) if train_input.chunksize[0] % n == 0]\n",
    "print(\"Factors of chunk: \", factors_of_chunk)\n",
    "hparams_for_mlflow['Limited sample number'] =  -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbae1c6-5501-40e7-a2ba-4b1ef270f170",
   "metadata": {},
   "source": [
    "setup study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90bd6235-7bfe-4bd1-aa06-ae1f5f86c223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 1, 'lr': <ray.tune.search.sample.Float object at 0x2b5781714ca0>, 'data_limit': 4, 'batch_size': <ray.tune.search.sample.Categorical object at 0x2b5781715d50>, 'arch_name': 'MLP', 'hidden_layers': <ray.tune.search.sample.Integer object at 0x2b5781715de0>, 'activation': <ray.tune.search.sample.Categorical object at 0x2b5781715e70>, 'input_size': 210, 'output_size': 70, 'deterministic': False, 'chkpt_time': datetime.timedelta(seconds=900), 'max_time': '00:11:50:00', 'layer_node_number_0_div_8': <ray.tune.search.sample.Integer object at 0x2b57816df130>, 'layer_node_number_1_div_8': <ray.tune.search.sample.Integer object at 0x2b57816dd090>, 'layer_node_number_2_div_8': <ray.tune.search.sample.Integer object at 0x2b57816de920>, 'layer_node_number_3_div_8': <ray.tune.search.sample.Integer object at 0x2b578173f5e0>, 'layer_node_number_4_div_8': <ray.tune.search.sample.Integer object at 0x2b578173f820>, 'layer_node_number_5_div_8': <ray.tune.search.sample.Integer object at 0x2b578173e080>, 'layer_node_number_6_div_8': <ray.tune.search.sample.Integer object at 0x2b578173f3a0>, 'layer_node_number_7_div_8': <ray.tune.search.sample.Integer object at 0x2b578173f310>, 'layer_node_number_8_div_8': <ray.tune.search.sample.Integer object at 0x2b578173e1d0>, 'layer_node_number_9_div_8': <ray.tune.search.sample.Integer object at 0x2b578173e110>, 'layer_node_number_10_div_8': <ray.tune.search.sample.Integer object at 0x2b578173fa90>, 'layer_node_number_11_div_8': <ray.tune.search.sample.Integer object at 0x2b578173feb0>}\n"
     ]
    }
   ],
   "source": [
    "# DEFINE ALL SETTINGS FOR TRAINING, includes hparam space\n",
    "experiment_name = 'cbh-hparam-tuning'\n",
    "CPU_COUNT = 8\n",
    "RAM_GB = 128\n",
    "hparams_for_mlflow['CPU Count'] = CPU_COUNT\n",
    "hparams_for_mlflow['Compute Memory'] = RAM_GB\n",
    "thread_count_for_dask = CPU_COUNT\n",
    "dataset_method = '1chunk'\n",
    "randomize_chunkwise_1chunk = False\n",
    "shuffle_train_data = False\n",
    "collate_fn = None # alt: cbh_data_definitions.dataloader_collate_with_dask\n",
    "num_workers_dataloader = 0 # alt: CPU_COUNT +-\n",
    "global_trail_number = 0\n",
    "max_time_for_trial = \"00:11:50:00\"  # dd:hh:mm:ss\n",
    "hparams_for_mlflow[\"Training timeout\"] = max_time_for_trial\n",
    "\n",
    "max_node_num_exclusive = 513\n",
    "max_layers = 12\n",
    "factors_for_hparam_choice = [factor for factor in factors_of_chunk if (factor<3300 and factor>3)]\n",
    "mlp_search_space = {\n",
    "    \"epoch\": 1,\n",
    "    \"lr\": tune.quniform(0.001, 0.01, 0.0005),\n",
    "    \"data_limit\": 4,\n",
    "    \"batch_size\": tune.choice(factors_for_hparam_choice),\n",
    "    \"arch_name\":\"MLP\",\n",
    "    \"hidden_layers\":tune.randint(1,max_layers),\n",
    "    \"activation\":tune.choice([\"relu\", \"tanh\"]),\n",
    "    \"input_size\":(train_input.shape[2] * train_input.shape[1]),\n",
    "    \"output_size\": train_input.shape[1],\n",
    "    \"deterministic\":False,\n",
    "    \"chkpt_time\":datetime.timedelta(minutes=15),\n",
    "    \"max_time\":max_time_for_trial\n",
    "}\n",
    "lstm_search_space = {\n",
    "    \"epoch\": 1,\n",
    "    \"lr\": tune.quniform(0.0001, 0.005, 0.000005),\n",
    "    \"data_limit\": 4,\n",
    "    \"batch_size\": tune.choice(factors_for_hparam_choice),\n",
    "    \"arch_name\":\"LSTM\",\n",
    "    \"lstm_layers\":tune.randint(1,max_layers),\n",
    "    \"input_size\": train_input.shape[2],\n",
    "    \"lstm_output_size\": tune.randint(1,int(max_node_num_exclusive/(4))),\n",
    "    \"deterministic\":False,\n",
    "    \"chkpt_time\":datetime.timedelta(minutes=15),\n",
    "    \"max_time\":max_time_for_trial,\n",
    "    \"lstm_nodesize\":tune.randint(1,int(max_node_num_exclusive/8)),\n",
    "    \"height_dimension\": train_input.shape[1],\n",
    "    \"embed_size\": tune.randint(0,26),\n",
    "    \"BILSTM\": tune.choice([False, True]),\n",
    "    \"backward_lstm_differing_transitions\": tune.choice([False, True]),\n",
    "    \"batch_first\":True, \n",
    "    \"skip_connection\": tune.choice([False, True]),\n",
    "    \"norm_method\": tune.choice([\"p_l_p_f\", 'p_f', 'layer_relative']),\n",
    "    \"linear_instead_of_conv_cap\": tune.choice([False, True]),\n",
    "    \"conv_cap_window\":tune.randint(1,int(train_input.shape[1]/2)),\n",
    "}\n",
    "p_l_p_f_m = np.load(\"./per_level_per_feat_mean.npz\")\n",
    "p_l_p_f_s = np.load(\"./per_level_per_feat_std.npz\")\n",
    "p_f_m = np.load(\"./per_feat_mean.npz\")\n",
    "p_f_s = np.load(\"./per_feat_std.npz\")\n",
    "p_l_p_f_s += 5.0e-12 # prevent divide by 0\n",
    "layer_pattern = 'layer_node_number_{layer_num}_div_8'\n",
    "for layer_num in range(max_layers):\n",
    "    mlp_search_space[layer_pattern.format(layer_num=layer_num)] = tune.randint(1,int(max_node_num_exclusive/8))\n",
    "print(mlp_search_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aaa35a93-c33d-4e81-b5f9-4a235028ac38",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLFlowLogger(pl.loggers.MLFlowLogger): #overwrite mlflogger\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    # do nothing, no need to checkpoint during HPT, as larger training run will be run deterministically with best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "076ee9ae-57f6-4d17-90f3-e44b920af3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose_objective = False\n",
    "# @mlflow_mixin\n",
    "def objective(ray_config):\n",
    "    \n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    \n",
    "    mlflow.set_tracking_uri(mlflow_server_uri)\n",
    "    # make vars global\n",
    "    mlf_exp = None\n",
    "    mlf_exp_id = None\n",
    "    try: \n",
    "        if verbose_objective: print('Creating experiment')\n",
    "        mlf_exp_id = mlflow.create_experiment(experiment_name)\n",
    "        mlf_exp = mlflow.get_experiment(mlf_exp_id)\n",
    "    except mlflow.exceptions.RestException as e:\n",
    "        if verbose_objective: print(\"Caught\")\n",
    "        if False:\n",
    "            print(e)\n",
    "        mlf_exp = mlflow.get_experiment_by_name(experiment_name)\n",
    "    if verbose_objective: print(\"Success\")\n",
    "    \n",
    "    datamodule = cbh_data_definitions.CBH_DataModule(\n",
    "        train_input, train_labels,\n",
    "        dev_input, dev_labels,\n",
    "        thread_count_for_dask,\n",
    "        ray_config['batch_size'],\n",
    "        num_workers = num_workers_dataloader,\n",
    "        collate_fn = collate_fn,\n",
    "        shuffle = shuffle_train_data,\n",
    "        randomize_chunkwise = randomize_chunkwise_1chunk,\n",
    "        method=dataset_method,\n",
    "        val_batch_size=6400,\n",
    "        data_limit=ray_config['data_limit']\n",
    "    )\n",
    "    #def model\n",
    "    if ray_config['arch_name'] == \"MLP\":\n",
    "        ff_nodes_strings = []\n",
    "        for key in ray_config:\n",
    "            if key.startswith(\"layer_node_number_\"):\n",
    "                ff_nodes_strings.append(key)\n",
    "        ff_nodes_strings = sorted(ff_nodes_strings)\n",
    "        ff_nodes = [(8*ray_config[ff_node_num]) for ff_node_num in ff_nodes_strings]\n",
    "        if verbose_objective: print(ray_config['hidden_layers'])\n",
    "        if verbose_objective: print(ff_nodes)\n",
    "        model = cbh_torch_MLP.CloudBaseMLP(\n",
    "            ray_config['input_size'],\n",
    "            ff_nodes,\n",
    "            ray_config['output_size'],\n",
    "            ray_config['hidden_layers'],\n",
    "            ray_config['activation'],\n",
    "            ray_config['lr'],\n",
    "        )\n",
    "        \n",
    "    elif ray_config['arch_name'] == \"LSTM\":\n",
    "        if ray_config['norm_method'] == \"p_l_p_f\":\n",
    "            norm_mat_m = torch.from_numpy(p_l_p_f_m.astype(np.float32))\n",
    "            norm_mat_s = torch.from_numpy(p_l_p_f_s.astype(np.float32))\n",
    "        elif ray_config['norm_method'] == \"p_f\":\n",
    "            norm_mat_m = torch.from_numpy(p_f_m.astype(np.float32))\n",
    "            norm_mat_s = torch.from_numpy(p_f_s.astype(np.float32))\n",
    "        else:\n",
    "            norm_mat_m = None\n",
    "            norm_mat_s = None\n",
    "        lstm_node_dim = ray_config['lstm_nodesize'] * 8\n",
    "        model = cbh_torch_lstm.CloudBaseLSTM(\n",
    "            ray_config['input_size'], \n",
    "            ray_config['lstm_layers'], \n",
    "            lstm_node_dim, \n",
    "            ray_config['lstm_output_size'], \n",
    "            ray_config['height_dimension'],\n",
    "            ray_config['embed_size'], \n",
    "            ray_config['BILSTM'], \n",
    "            ray_config['backward_lstm_differing_transitions'], \n",
    "            ray_config['batch_first'], \n",
    "            ray_config['lr'], \n",
    "            ray_config['skip_connection'],\n",
    "            ray_config['norm_method'],\n",
    "            norm_mat_std=norm_mat_s,\n",
    "            norm_mat_mean=norm_mat_m,\n",
    "            linear_instead_of_conv_cap=ray_config['linear_instead_of_conv_cap']\n",
    "        )\n",
    "    if verbose_objective: print(\"Finished model init\")\n",
    "    timestamp_template = '{dt.year:04d}{dt.month:02d}{dt.day:02d}T{dt.hour:02d}{dt.minute:02d}{dt.second:02d}'\n",
    "    run_name_template = 'cbh_challenge_{network_name}_' + timestamp_template\n",
    "    current_run_name = run_name_template.format(network_name=model.__class__.__name__,\n",
    "                                                    dt=datetime.datetime.now()\n",
    "                                                   )\n",
    "    # begin mlflow experiment run\n",
    "    with mlflow.start_run(experiment_id=mlf_exp.experiment_id, run_name=current_run_name) as run:\n",
    "        mlflow.pytorch.autolog()\n",
    "        mlf_logger = MLFlowLogger(experiment_name=experiment_name, tracking_uri=mlflow_server_uri, run_id=run.info.run_id)\n",
    "        if verbose_objective: print(\"Finished init logger\")\n",
    "        # define trainer\n",
    "        time_for_checkpoint = ray_config['chkpt_time']\n",
    "        checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "            train_time_interval=time_for_checkpoint,\n",
    "            dirpath=run.info.artifact_uri,\n",
    "            monitor=\"val_loss_mean\",\n",
    "            save_on_train_epoch_end=False,\n",
    "            mode=\"min\"\n",
    "        )\n",
    "        callbacks = [\n",
    "            checkpoint_callback, \n",
    "            TQDMProgressBar(refresh_rate=0), \n",
    "            TuneReportCallback(\n",
    "                {\"val_loss_mean\": \"val_loss_mean\",},\n",
    "                on=\"validation_end\"\n",
    "            ),\n",
    "            EarlyStopping(\n",
    "                \"val_loss_mean\", min_delta=0.0, patience=40,\n",
    "                divergence_threshold=30.\n",
    "            ),\n",
    "        ] # rich progress bar does not show on tune.   set default to 0 to prevent multiple lines of output (tracking done in mlflow)\n",
    "        \n",
    "        if verbose_objective: print(\"Finished define callbacks\")\n",
    "        trainer_hparams = {\n",
    "            'max_epochs':ray_config['epoch'],\n",
    "            'deterministic':ray_config['deterministic'],\n",
    "            'val_check_interval':0.01, # val every percentage of the epoch or an INT for after a number of batches\n",
    "            'devices':\"auto\",\n",
    "            'accelerator':\"auto\",\n",
    "            'max_time':ray_config['max_time'], ## Don't give tuning maxtime, as rewards favor low batch size / small networks able to perform more steps in the given time\n",
    "            'replace_sampler_ddp':False,\n",
    "            'enable_checkpointing':True,\n",
    "            'strategy':None,\n",
    "            'callbacks':callbacks,\n",
    "            'logger':mlf_logger,\n",
    "        }\n",
    "        if verbose_objective: print(\"Finished init hparams kwargs\")\n",
    "        hparams_for_mlflow['ray_config'] = ray_config\n",
    "        mlf_logger.log_hyperparams(hparams_for_mlflow)\n",
    "        if verbose_objective: print(\"Finished log hparams mlflow\")\n",
    "        if verbose_objective: print(trainer_hparams)\n",
    "        trainer = pl.Trainer(\n",
    "            **trainer_hparams\n",
    "        )\n",
    "        if verbose_objective: print(\"REACH all init before fit\")\n",
    "        trainer.fit(model=model, datamodule=datamodule)\n",
    "        path_to_save = '{dt.year:04d}{dt.month:02d}{dt.day:02d}-{dt.hour:02d}{dt.minute:02d}{dt.second:02d}'.format(dt=datetime.datetime.now())\n",
    "        trainer.save_checkpoint(filepath=run.info.artifact_uri + f'/post_epoch_modelchkpt_{path_to_save}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f79513f-45d4-4ba1-a382-8644d506628d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "475ff4ee-30a6-4224-8833-da8301e9edc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-28 17:15:02,146\tINFO worker.py:1528 -- Started a local Ray instance.\n",
      "2022-11-28 17:15:17,726\tWARNING function_trainable.py:586 -- Function checkpointing is disabled. This may result in unexpected behavior when using checkpointing features or certain schedulers. To enable, set the train function arguments to be `func(config, checkpoint_dir=None)`.\n",
      "\u001b[32m[I 2022-11-28 17:15:17,745]\u001b[0m A new study created in memory with name: optuna\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2022-11-28 17:18:47</td></tr>\n",
       "<tr><td>Running for: </td><td>00:03:29.78        </td></tr>\n",
       "<tr><td>Memory:      </td><td>113.1/251.8 GiB    </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Resources requested: 6.0/48 CPUs, 0/0 GPUs, 0.0/76.9 GiB heap, 0.0/36.95 GiB objects\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name        </th><th>status  </th><th>loc              </th><th>BILSTM  </th><th>backward_lstm_differ\n",
       "ing_transitions      </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_cap_window</th><th style=\"text-align: right;\">  embed_size</th><th>linear_instead_of_co\n",
       "nv_cap      </th><th style=\"text-align: right;\">      lr</th><th style=\"text-align: right;\">  lstm_layers</th><th style=\"text-align: right;\">  lstm_nodesize</th><th style=\"text-align: right;\">  lstm_output_size</th><th>norm_method   </th><th>skip_connection  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>objective_3b1cfb5e</td><td>RUNNING </td><td>10.154.1.31:15320</td><td>False   </td><td>False</td><td style=\"text-align: right;\">          80</td><td style=\"text-align: right;\">               13</td><td style=\"text-align: right;\">          22</td><td>True </td><td style=\"text-align: right;\">0.004495</td><td style=\"text-align: right;\">            6</td><td style=\"text-align: right;\">             26</td><td style=\"text-align: right;\">                 1</td><td>layer_relative</td><td>True             </td></tr>\n",
       "<tr><td>objective_41442bd8</td><td>RUNNING </td><td>10.154.1.31:15396</td><td>True    </td><td>True </td><td style=\"text-align: right;\">        2600</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">          12</td><td>True </td><td style=\"text-align: right;\">0.00415 </td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">              5</td><td style=\"text-align: right;\">                95</td><td>layer_relative</td><td>True             </td></tr>\n",
       "<tr><td>objective_464d9b46</td><td>RUNNING </td><td>10.154.1.31:15432</td><td>False   </td><td>True </td><td style=\"text-align: right;\">         140</td><td style=\"text-align: right;\">               11</td><td style=\"text-align: right;\">           8</td><td>False</td><td style=\"text-align: right;\">0.00336 </td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">             16</td><td style=\"text-align: right;\">                24</td><td>p_f           </td><td>True             </td></tr>\n",
       "<tr><td>objective_4a9f7f98</td><td>RUNNING </td><td>10.154.1.31:15534</td><td>False   </td><td>False</td><td style=\"text-align: right;\">         520</td><td style=\"text-align: right;\">                8</td><td style=\"text-align: right;\">           9</td><td>True </td><td style=\"text-align: right;\">0.002785</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">             51</td><td style=\"text-align: right;\">               101</td><td>p_l_p_f       </td><td>True             </td></tr>\n",
       "<tr><td>objective_4f56d842</td><td>RUNNING </td><td>10.154.1.31:15574</td><td>True    </td><td>True </td><td style=\"text-align: right;\">          52</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">          20</td><td>False</td><td style=\"text-align: right;\">0.00269 </td><td style=\"text-align: right;\">            8</td><td style=\"text-align: right;\">             49</td><td style=\"text-align: right;\">                14</td><td>layer_relative</td><td>True             </td></tr>\n",
       "<tr><td>objective_53979ea0</td><td>RUNNING </td><td>10.154.1.31:15623</td><td>True    </td><td>True </td><td style=\"text-align: right;\">        1024</td><td style=\"text-align: right;\">               31</td><td style=\"text-align: right;\">           6</td><td>False</td><td style=\"text-align: right;\">0.001685</td><td style=\"text-align: right;\">            8</td><td style=\"text-align: right;\">             21</td><td style=\"text-align: right;\">                73</td><td>layer_relative</td><td>True             </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(objective pid=15320)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(objective pid=15320)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(objective pid=15320)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(objective pid=15320)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(objective pid=15320)\u001b[0m \n",
      "\u001b[2m\u001b[36m(objective pid=15320)\u001b[0m   | Name              | Type             | Params\n",
      "\u001b[2m\u001b[36m(objective pid=15320)\u001b[0m -------------------------------------------------------\n",
      "\u001b[2m\u001b[36m(objective pid=15320)\u001b[0m 0 | LSTM_upward       | LSTM             | 41.2 K\n",
      "\u001b[2m\u001b[36m(objective pid=15320)\u001b[0m 1 | height_embedding  | Embedding        | 1.5 K \n",
      "\u001b[2m\u001b[36m(objective pid=15320)\u001b[0m 2 | loss_fn_base      | CrossEntropyLoss | 0     \n",
      "\u001b[2m\u001b[36m(objective pid=15320)\u001b[0m 3 | scale_input_layer | Conv1d           | 26    \n",
      "\u001b[2m\u001b[36m(objective pid=15320)\u001b[0m 4 | cap_layer         | Linear           | 5.0 K \n",
      "\u001b[2m\u001b[36m(objective pid=15320)\u001b[0m -------------------------------------------------------\n",
      "\u001b[2m\u001b[36m(objective pid=15320)\u001b[0m 47.7 K    Trainable params\n",
      "\u001b[2m\u001b[36m(objective pid=15320)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(objective pid=15320)\u001b[0m 47.7 K    Total params\n",
      "\u001b[2m\u001b[36m(objective pid=15320)\u001b[0m 0.191     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(objective pid=15396)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(objective pid=15396)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(objective pid=15396)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(objective pid=15396)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(objective pid=15396)\u001b[0m \n",
      "\u001b[2m\u001b[36m(objective pid=15396)\u001b[0m   | Name              | Type             | Params\n",
      "\u001b[2m\u001b[36m(objective pid=15396)\u001b[0m -------------------------------------------------------\n",
      "\u001b[2m\u001b[36m(objective pid=15396)\u001b[0m 0 | LSTM_upward       | LSTM             | 96.3 K\n",
      "\u001b[2m\u001b[36m(objective pid=15396)\u001b[0m 1 | LSTM_downward     | LSTM             | 96.3 K\n",
      "\u001b[2m\u001b[36m(objective pid=15396)\u001b[0m 2 | height_embedding  | Embedding        | 840   \n",
      "\u001b[2m\u001b[36m(objective pid=15396)\u001b[0m 3 | loss_fn_base      | CrossEntropyLoss | 0     \n",
      "\u001b[2m\u001b[36m(objective pid=15396)\u001b[0m 4 | scale_input_layer | Conv1d           | 640   \n",
      "\u001b[2m\u001b[36m(objective pid=15396)\u001b[0m 5 | cap_layer         | Linear           | 196 K \n",
      "\u001b[2m\u001b[36m(objective pid=15396)\u001b[0m -------------------------------------------------------\n",
      "\u001b[2m\u001b[36m(objective pid=15396)\u001b[0m 390 K     Trainable params\n",
      "\u001b[2m\u001b[36m(objective pid=15396)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(objective pid=15396)\u001b[0m 390 K     Total params\n",
      "\u001b[2m\u001b[36m(objective pid=15396)\u001b[0m 1.561     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(objective pid=15432)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(objective pid=15432)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(objective pid=15432)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(objective pid=15432)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(objective pid=15432)\u001b[0m \n",
      "\u001b[2m\u001b[36m(objective pid=15432)\u001b[0m   | Name              | Type             | Params\n",
      "\u001b[2m\u001b[36m(objective pid=15432)\u001b[0m -------------------------------------------------------\n",
      "\u001b[2m\u001b[36m(objective pid=15432)\u001b[0m 0 | LSTM_upward       | LSTM             | 50.7 K\n",
      "\u001b[2m\u001b[36m(objective pid=15432)\u001b[0m 1 | LSTM_downward     | LSTM             | 50.7 K\n",
      "\u001b[2m\u001b[36m(objective pid=15432)\u001b[0m 2 | height_embedding  | Embedding        | 560   \n",
      "\u001b[2m\u001b[36m(objective pid=15432)\u001b[0m 3 | loss_fn_base      | CrossEntropyLoss | 0     \n",
      "\u001b[2m\u001b[36m(objective pid=15432)\u001b[0m 4 | scale_input_layer | Conv1d           | 288   \n",
      "\u001b[2m\u001b[36m(objective pid=15432)\u001b[0m 5 | cap_layer         | Conv1d           | 121   \n",
      "\u001b[2m\u001b[36m(objective pid=15432)\u001b[0m -------------------------------------------------------\n",
      "\u001b[2m\u001b[36m(objective pid=15432)\u001b[0m 102 K     Trainable params\n",
      "\u001b[2m\u001b[36m(objective pid=15432)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(objective pid=15432)\u001b[0m 102 K     Total params\n",
      "\u001b[2m\u001b[36m(objective pid=15432)\u001b[0m 0.409     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(objective pid=15534)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(objective pid=15534)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(objective pid=15534)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(objective pid=15534)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(objective pid=15534)\u001b[0m \n",
      "\u001b[2m\u001b[36m(objective pid=15534)\u001b[0m   | Name              | Type             | Params\n",
      "\u001b[2m\u001b[36m(objective pid=15534)\u001b[0m -------------------------------------------------------\n",
      "\u001b[2m\u001b[36m(objective pid=15534)\u001b[0m 0 | LSTM_upward       | LSTM             | 603 K \n",
      "\u001b[2m\u001b[36m(objective pid=15534)\u001b[0m 1 | height_embedding  | Embedding        | 630   \n",
      "\u001b[2m\u001b[36m(objective pid=15534)\u001b[0m 2 | loss_fn_base      | CrossEntropyLoss | 0     \n",
      "\u001b[2m\u001b[36m(objective pid=15534)\u001b[0m 3 | scale_input_layer | Conv1d           | 1.3 K \n",
      "\u001b[2m\u001b[36m(objective pid=15534)\u001b[0m 4 | cap_layer         | Linear           | 494 K \n",
      "\u001b[2m\u001b[36m(objective pid=15534)\u001b[0m -------------------------------------------------------\n",
      "\u001b[2m\u001b[36m(objective pid=15534)\u001b[0m 1.1 M     Trainable params\n",
      "\u001b[2m\u001b[36m(objective pid=15534)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(objective pid=15534)\u001b[0m 1.1 M     Total params\n",
      "\u001b[2m\u001b[36m(objective pid=15534)\u001b[0m 4.400     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(objective pid=15574)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(objective pid=15574)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(objective pid=15574)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(objective pid=15574)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(objective pid=15623)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(objective pid=15623)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(objective pid=15623)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(objective pid=15623)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(objective pid=15574)\u001b[0m \n",
      "\u001b[2m\u001b[36m(objective pid=15574)\u001b[0m   | Name              | Type             | Params\n",
      "\u001b[2m\u001b[36m(objective pid=15574)\u001b[0m -------------------------------------------------------\n",
      "\u001b[2m\u001b[36m(objective pid=15574)\u001b[0m 0 | LSTM_upward       | LSTM             | 1.2 M \n",
      "\u001b[2m\u001b[36m(objective pid=15574)\u001b[0m 1 | LSTM_downward     | LSTM             | 1.2 M \n",
      "\u001b[2m\u001b[36m(objective pid=15574)\u001b[0m 2 | height_embedding  | Embedding        | 1.4 K \n",
      "\u001b[2m\u001b[36m(objective pid=15574)\u001b[0m 3 | loss_fn_base      | CrossEntropyLoss | 0     \n",
      "\u001b[2m\u001b[36m(objective pid=15574)\u001b[0m 4 | scale_input_layer | Conv1d           | 336   \n",
      "\u001b[2m\u001b[36m(objective pid=15574)\u001b[0m 5 | cap_layer         | Conv1d           | 71    \n",
      "\u001b[2m\u001b[36m(objective pid=15574)\u001b[0m -------------------------------------------------------\n",
      "\u001b[2m\u001b[36m(objective pid=15574)\u001b[0m 2.4 M     Trainable params\n",
      "\u001b[2m\u001b[36m(objective pid=15574)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(objective pid=15574)\u001b[0m 2.4 M     Total params\n",
      "\u001b[2m\u001b[36m(objective pid=15574)\u001b[0m 9.415     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(objective pid=15623)\u001b[0m \n",
      "\u001b[2m\u001b[36m(objective pid=15623)\u001b[0m   | Name              | Type             | Params\n",
      "\u001b[2m\u001b[36m(objective pid=15623)\u001b[0m -------------------------------------------------------\n",
      "\u001b[2m\u001b[36m(objective pid=15623)\u001b[0m 0 | LSTM_upward       | LSTM             | 2.4 M \n",
      "\u001b[2m\u001b[36m(objective pid=15623)\u001b[0m 1 | LSTM_downward     | LSTM             | 2.4 M \n",
      "\u001b[2m\u001b[36m(objective pid=15623)\u001b[0m 2 | height_embedding  | Embedding        | 420   \n",
      "\u001b[2m\u001b[36m(objective pid=15623)\u001b[0m 3 | loss_fn_base      | CrossEntropyLoss | 0     \n",
      "\u001b[2m\u001b[36m(objective pid=15623)\u001b[0m 4 | scale_input_layer | Conv1d           | 730   \n",
      "\u001b[2m\u001b[36m(objective pid=15623)\u001b[0m 5 | cap_layer         | Conv1d           | 366   \n",
      "\u001b[2m\u001b[36m(objective pid=15623)\u001b[0m -------------------------------------------------------\n",
      "\u001b[2m\u001b[36m(objective pid=15623)\u001b[0m 4.8 M     Trainable params\n",
      "\u001b[2m\u001b[36m(objective pid=15623)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(objective pid=15623)\u001b[0m 4.8 M     Total params\n",
      "\u001b[2m\u001b[36m(objective pid=15623)\u001b[0m 19.112    Total estimated model params size (MB)\n",
      "2022-11-28 17:18:46,612\tWARNING tune.py:705 -- Stop signal received (e.g. via SIGINT/Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C (or send SIGINT/SIGKILL/SIGTERM) to skip. \n",
      "\u001b[2m\u001b[36m(objective pid=15320)\u001b[0m 2022-11-28 17:18:47,778\tERROR worker.py:763 -- Worker exits with an exit code 1.\n",
      "\u001b[2m\u001b[36m(objective pid=15320)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(objective pid=15320)\u001b[0m   File \"python/ray/_raylet.pyx\", line 1032, in ray._raylet.task_execution_handler\n",
      "\u001b[2m\u001b[36m(objective pid=15320)\u001b[0m   File \"python/ray/_raylet.pyx\", line 812, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(objective pid=15320)\u001b[0m   File \"python/ray/_raylet.pyx\", line 852, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(objective pid=15320)\u001b[0m   File \"python/ray/_raylet.pyx\", line 859, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(objective pid=15320)\u001b[0m   File \"python/ray/_raylet.pyx\", line 863, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(objective pid=15320)\u001b[0m   File \"python/ray/_raylet.pyx\", line 810, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(objective pid=15320)\u001b[0m   File \"/home/h02/hsouth/.conda/envs/py-lightning/lib/python3.10/site-packages/ray/_private/function_manager.py\", line 674, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(objective pid=15320)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(objective pid=15320)\u001b[0m   File \"/home/h02/hsouth/.conda/envs/py-lightning/lib/python3.10/site-packages/ray/util/tracing/tracing_helper.py\", line 466, in _resume_span\n",
      "\u001b[2m\u001b[36m(objective pid=15320)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(objective pid=15320)\u001b[0m   File \"/home/h02/hsouth/.conda/envs/py-lightning/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 352, in train\n",
      "\u001b[2m\u001b[36m(objective pid=15320)\u001b[0m     result = self.step()\n",
      "\u001b[2m\u001b[36m(objective pid=15320)\u001b[0m   File \"/home/h02/hsouth/.conda/envs/py-lightning/lib/python3.10/site-packages/ray/util/tracing/tracing_helper.py\", line 466, in _resume_span\n",
      "\u001b[2m\u001b[36m(objective pid=15320)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(objective pid=15320)\u001b[0m   File \"/home/h02/hsouth/.conda/envs/py-lightning/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 365, in step\n",
      "\u001b[2m\u001b[36m(objective pid=15320)\u001b[0m     result = self._results_queue.get(\n",
      "\u001b[2m\u001b[36m(objective pid=15320)\u001b[0m   File \"/home/h02/hsouth/.conda/envs/py-lightning/lib/python3.10/queue.py\", line 180, in get\n",
      "\u001b[2m\u001b[36m(objective pid=15320)\u001b[0m     self.not_empty.wait(remaining)\n",
      "\u001b[2m\u001b[36m(objective pid=15320)\u001b[0m   File \"/home/h02/hsouth/.conda/envs/py-lightning/lib/python3.10/threading.py\", line 324, in wait\n",
      "\u001b[2m\u001b[36m(objective pid=15320)\u001b[0m     gotit = waiter.acquire(True, timeout)\n",
      "\u001b[2m\u001b[36m(objective pid=15320)\u001b[0m   File \"/home/h02/hsouth/.conda/envs/py-lightning/lib/python3.10/site-packages/ray/_private/worker.py\", line 760, in sigterm_handler\n",
      "\u001b[2m\u001b[36m(objective pid=15320)\u001b[0m     sys.exit(1)\n",
      "\u001b[2m\u001b[36m(objective pid=15320)\u001b[0m SystemExit: 1\n",
      "2022-11-28 17:18:47,901\tERROR tune.py:773 -- Trials did not complete: [objective_3b1cfb5e, objective_41442bd8, objective_464d9b46, objective_4a9f7f98, objective_4f56d842, objective_53979ea0]\n",
      "2022-11-28 17:18:47,902\tINFO tune.py:777 -- Total run time: 210.18 seconds (209.76 seconds for the tuning loop).\n",
      "2022-11-28 17:18:47,903\tWARNING tune.py:783 -- Experiment has been interrupted, but the most recent state was saved. You can continue running this experiment by passing `resume=True` to `tune.run()`\n"
     ]
    }
   ],
   "source": [
    "searcher = OptunaSearch(metric=[\"val_loss_mean\"], mode=[\"min\"])\n",
    "max_concurrent_trails = CPU_COUNT-2#int(CPU_COUNT*(3/4))#1\n",
    "algo = ConcurrencyLimiter(searcher, max_concurrent=max_concurrent_trails)\n",
    "num_hparam_trials = 500\n",
    "\n",
    "tuner = tune.Tuner(\n",
    "    objective,\n",
    "    tune_config=tune.TuneConfig(\n",
    "        search_alg=algo,\n",
    "        num_samples=num_hparam_trials,\n",
    "        time_budget_s=datetime.timedelta(hours=71.5)\n",
    "    ),\n",
    "    run_config=ray.air.config.RunConfig(\n",
    "        local_dir=str(pathlib.Path(os.environ[\"SCRATCH\"]) / \"cbh_data\")\n",
    "        \n",
    "    ),\n",
    "    param_space=lstm_search_space,\n",
    ")\n",
    "results = tuner.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49343e87-1030-400c-b6f3-2e01095ca66b",
   "metadata": {},
   "source": [
    "ensure mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acfae81-73a0-4c54-8093-7ca61e4fa6a0",
   "metadata": {},
   "source": [
    "run study"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b082d416-89a5-4f64-a7a1-ae0b9efb8c48",
   "metadata": {},
   "source": [
    "eval"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda-py-lightning Python (Conda)",
   "language": "python",
   "name": "conda-env-.conda-py-lightning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
