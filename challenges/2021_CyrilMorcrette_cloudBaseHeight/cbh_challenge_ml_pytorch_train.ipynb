{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6729aad1-261a-48fa-ae59-986428165ebd",
   "metadata": {},
   "source": [
    "# Training a neural network in PyTorch\n",
    "\n",
    "This notebook demonstrates training a classifier in PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea2ebc23-4958-4cc3-8f6b-c30686f571eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pl ver: 1.6.4\n"
     ]
    }
   ],
   "source": [
    "# file handling\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "import dask\n",
    "import dask.array\n",
    "\n",
    "# math operators\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "# ml\n",
    "import torch\n",
    "import zarr\n",
    "\n",
    "print(\"pl ver:\", pl.__version__)\n",
    "\n",
    "import datetime\n",
    "\n",
    "# training helpers\n",
    "import mlflow.pytorch\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "# import dask.distributed # sometimes breaks things\n",
    "# from dask.diagnostics import Profiler, ResourceProfiler, CacheProfiler\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "from pytorch_lightning.callbacks import (\n",
    "    RichProgressBar,\n",
    ")  # this progress bar works through jupyterHub on spice\n",
    "\n",
    "# defined in directory (model related definitions)\n",
    "import cbh_data_definitions\n",
    "import cbh_torch_lstm\n",
    "import cbh_torch_MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "508614de-9142-42df-811b-bba77c76bea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'cbh_data_definitions' from '/net/home/h02/hsouth/github_committing/data_science_cop/challenges/2021_CyrilMorcrette_cloudBaseHeight/cbh_data_definitions.py'>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(cbh_torch_lstm)\n",
    "importlib.reload(cbh_torch_MLP)\n",
    "importlib.reload(cbh_data_definitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2d53e4d-26b1-4d18-a0b7-3f7232f73063",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_data_directory = pathlib.Path(os.environ[\"SCRATCH\"]) / \"cbh_data\"\n",
    "\n",
    "dev_data_path = root_data_directory / \"analysis_ready\" / \"dev.zarr\"\n",
    "training_data_path = root_data_directory / \"analysis_ready\" / \"train.zarr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c96b79fe-a8c4-4026-a77f-39d048642745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded zarr, file information:\n",
      " Name        : /\n",
      "Type        : zarr.hierarchy.Group\n",
      "Read-only   : False\n",
      "Store type  : zarr.storage.DirectoryStore\n",
      "No. members : 3\n",
      "No. arrays  : 3\n",
      "No. groups  : 0\n",
      "Arrays      : cloud_volume_fraction_y.zarr, humidity_temp_pressure_x.zarr,\n",
      "            : onehot_cloud_base_height_y.zarr\n",
      " \n",
      "\n",
      "Loaded zarr, file information:\n",
      " Name        : /\n",
      "Type        : zarr.hierarchy.Group\n",
      "Read-only   : False\n",
      "Store type  : zarr.storage.DirectoryStore\n",
      "No. members : 3\n",
      "No. arrays  : 3\n",
      "No. groups  : 0\n",
      "Arrays      : cloud_volume_fraction_y.zarr, humidity_temp_pressure_x.zarr,\n",
      "            : onehot_cloud_base_height_y.zarr\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    train_input,\n",
    "    train_labels,\n",
    "    train_cloud_volume,\n",
    ") = cbh_data_definitions.load_data_from_zarr(training_data_path)\n",
    "dev_input, dev_labels, dev_cloud_volume = cbh_data_definitions.load_data_from_zarr(\n",
    "    dev_data_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c8b8915-497a-4d90-8ec2-971caa896dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "LIMIT_DATA = True\n",
    "LIMIT_DATA_INT = 1000000\n",
    "if LIMIT_DATA:\n",
    "    train_input = train_input[:LIMIT_DATA_INT]\n",
    "    train_labels = train_labels[:LIMIT_DATA_INT]\n",
    "    train_cloud_volume = train_cloud_volume[:LIMIT_DATA_INT]\n",
    "    dev_input = dev_input[:LIMIT_DATA_INT]\n",
    "    dev_labels = dev_labels[:LIMIT_DATA_INT]\n",
    "    dev_cloud_volume = dev_cloud_volume[:LIMIT_DATA_INT]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffba27b-d62f-4bcd-8132-e668c3479e3b",
   "metadata": {},
   "source": [
    "## Define the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b83e7351-b657-4e9b-8997-2d4022f8b5e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# enforce reproducibility\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0ab5c4-12e5-48cb-a947-f4f70a0e520e",
   "metadata": {},
   "source": [
    "## Perform the network initialization and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ce919a8-22f0-46c1-a895-6b7c07ccdba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_LSTM = False\n",
    "TRAIN_MLP = True\n",
    "\n",
    "if TRAIN_LSTM:\n",
    "    height_dim = train_input.shape[1]\n",
    "\n",
    "    # define model and hyperparameters\n",
    "    layers = 1\n",
    "    input_size = train_input.shape[2]  # input size is the cell input (feat dim)\n",
    "    output_size = 1  # for each height layer, predict one value for cloud base prob\n",
    "    hidden_size = 8\n",
    "    embed_size = 1\n",
    "    BILSTM = False\n",
    "    batch_first = True\n",
    "\n",
    "    learn_rate = 0.003\n",
    "\n",
    "    model = cbh_torch_lstm.CloudBaseLSTM(\n",
    "        input_size,\n",
    "        layers,\n",
    "        hidden_size,\n",
    "        output_size,\n",
    "        height_dim,\n",
    "        embed_size,\n",
    "        BILSTM,\n",
    "        batch_first,\n",
    "        lr=learn_rate,\n",
    "    )\n",
    "\n",
    "elif TRAIN_MLP:\n",
    "    # input is the flat sample on data\n",
    "    input_size = train_input.shape[2] * train_input.shape[1]\n",
    "    ff_nodes = 256\n",
    "    output_size = train_input.shape[1]\n",
    "    learn_rate = 1.0e-4\n",
    "    \n",
    "    model = cbh_torch_MLP.CloudBaseMLP(\n",
    "        input_size,\n",
    "        ff_nodes,\n",
    "        output_size,\n",
    "        learn_rate\n",
    "    )\n",
    "# define training related hyperparameters\n",
    "\n",
    "epochs = 1\n",
    "max_time = \"00:02:20:00\"  # dd:hh:mm:ss\n",
    "\n",
    "# after training parameters defined, load datasets into dataloaders (enforce 0 as workers on sys to prevent multiple packages\n",
    "# trying to parallelise while not communicating\n",
    "workers_on_system = 0\n",
    "collate_fn = cbh_data_definitions.dataloader_collate_with_dask\n",
    "batch_size = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "adc82bd5-20a8-4072-a266-4c162e41ed41",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader = None, None\n",
    "INTO_MEMORY = True\n",
    "if INTO_MEMORY:\n",
    "    train_loader = cbh_data_definitions.define_data_get_loader_into_memory(\n",
    "        train_input,\n",
    "        train_cloud_volume,\n",
    "        train_labels,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=workers_on_system,\n",
    "        collate_fn=collate_fn,\n",
    "    )\n",
    "    val_loader = cbh_data_definitions.define_data_get_loader_into_memory(\n",
    "        dev_input,\n",
    "        dev_cloud_volume,\n",
    "        dev_labels,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=workers_on_system,\n",
    "        collate_fn=collate_fn,\n",
    "    )\n",
    "else:\n",
    "    train_loader = cbh_data_definitions.define_data_get_loader(\n",
    "        train_input,\n",
    "        train_cloud_volume,\n",
    "        train_labels,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=workers_on_system,\n",
    "        collate_fn=collate_fn,\n",
    "    )\n",
    "    val_loader = cbh_data_definitions.define_data_get_loader(\n",
    "        dev_input,\n",
    "        dev_cloud_volume,\n",
    "        dev_labels,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=workers_on_system,\n",
    "        collate_fn=collate_fn,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2763eaf2-bedd-4834-a1f2-030b170d1899",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# define trainer\n",
    "\n",
    "time_for_checkpoint = datetime.timedelta(minutes=20)\n",
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "    train_time_interval=time_for_checkpoint\n",
    ")\n",
    "callbacks = [checkpoint_callback, RichProgressBar()]\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=epochs,\n",
    "    deterministic=True,\n",
    "    check_val_every_n_epoch=1,\n",
    "    devices=\"auto\",\n",
    "    accelerator=\"auto\",\n",
    "    max_time=max_time,\n",
    "    enable_checkpointing=True,\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39551462-62c9-4181-a41b-640463f4196c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup mlflow logging\n",
    "\n",
    "mlflow.pytorch.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c2dade6-a531-43b9-a88c-dcfb92937ab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Epoch 0   </span> <span style=\"color: #6206e0; text-decoration-color: #6206e0\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">6536/6536</span> <span style=\"color: #8a8a8a; text-decoration-color: #8a8a8a\">0:03:59 • 0:00:00</span> <span style=\"color: #b2b2b2; text-decoration-color: #b2b2b2\">27.26it/s</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">loss: 2.68 v_num: 8434021 </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[37mEpoch 0   \u001b[0m \u001b[38;2;98;6;224m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[37m6536/6536\u001b[0m \u001b[38;5;245m0:03:59 • 0:00:00\u001b[0m \u001b[38;5;249m27.26it/s\u001b[0m \u001b[37mloss: 2.68 v_num: 8434021 \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/09/01 10:45:15 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during pytorch autologging: cannot pickle '_thread.RLock' object\n"
     ]
    }
   ],
   "source": [
    "# run the training function\n",
    "with mlflow.start_run() as run:\n",
    "    trainer.fit(model=model, train_dataloaders=train_loader, val_dataloaders=val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba52d2c-1212-4894-ad05-3a9f7761ccf2",
   "metadata": {},
   "source": [
    "## Display and evaluate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "888b7d7e-5158-42a9-b3f2-046dca3a218c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_auto_logged_info(r):\n",
    "\n",
    "    tags = {k: v for k, v in r.data.tags.items() if not k.startswith(\"mlflow.\")}\n",
    "    artifacts = [f.path for f in MlflowClient().list_artifacts(r.info.run_id, \"model\")]\n",
    "    print(\"run_id: {}\".format(r.info.run_id))\n",
    "    print(\"artifacts: {}\".format(artifacts))\n",
    "    print(\"params: {}\".format(r.data.params))\n",
    "    print(\"metrics: {}\".format(r.data.metrics))\n",
    "    print(\"tags: {}\".format(tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c108cb0a-4886-40ac-8ab8-af913c5d3b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_id: e285eddb762f4a5786d9ec95fa6b987c\n",
      "artifacts: []\n",
      "params: {'epochs': '1', 'optimizer_name': 'Adam', 'lr': '0.0001', 'betas': '(0.9, 0.999)', 'eps': '1e-08', 'weight_decay': '0', 'amsgrad': 'False'}\n",
      "metrics: {'training loss': 2.511777639389038, 'validation loss': 2.922545909881592}\n",
      "tags: {'Mode': 'training'}\n"
     ]
    }
   ],
   "source": [
    "# display mlflow output\n",
    "print_auto_logged_info(mlflow.get_run(run_id=run.info.run_id))\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7a9ef9b-ef4f-4c02-9b9f-23fa53a1b263",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_save_str_element = str(datetime.datetime.now())\n",
    "save_str = \"model_out\" + \"_\" + unique_save_str_element + '.ckpt'\n",
    "trainer.save_checkpoint(save_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1ce386db-e33d-42aa-90ff-8a4a4dd3be76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([200, 70, 3]) inp pre-flat\n",
      "torch.Size([200, 210]) inp\n",
      "torch.Size([200, 70]) preds\n",
      "tensor([10,  0,  8, 69,  0]) targ ex\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1406, 0.2969, 0.0312, 0.9219,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5625,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0312, 0.0469, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5781, 0.7812, 0.8750, 0.9375, 0.9844, 1.0000, 0.2500, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.1406, 0.0000, 0.2656, 0.5000, 0.4219, 0.0781, 0.9062,\n",
      "         0.9219, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3281, 0.3750,\n",
      "         0.2500, 0.1875, 0.1250, 0.0781, 0.0156, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.5156, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2812, 0.5625, 1.0000, 0.4844,\n",
      "         0.0625, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1875, 0.6719,\n",
      "         0.1719, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1719, 0.2188, 0.2969, 0.3594, 0.3906, 0.4062, 0.3906, 0.1875, 0.2188,\n",
      "         0.2344, 0.2500, 0.2656, 0.2812, 0.3438, 0.4688, 0.6406, 0.6875, 0.7188,\n",
      "         0.7500, 0.7812, 0.8125, 0.8281, 0.8281, 0.8438, 0.8438, 0.8438, 0.8281,\n",
      "         0.8750, 0.8906, 0.6562, 0.3594, 0.1719, 0.0938, 0.0312, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]) targ verif\n",
      "torch.Size([200])\n"
     ]
    }
   ],
   "source": [
    "# test model functionality\n",
    "example_batch = next(iter(train_loader))\n",
    "print(example_batch['x'].shape, 'inp pre-flat')\n",
    "inputs = torch.flatten(example_batch['x'], start_dim=1)\n",
    "print(inputs.shape, 'inp')\n",
    "preds = model(inputs)\n",
    "print(preds.shape, 'preds')\n",
    "targs = example_batch['cloud_base_target']\n",
    "print(targs[0:5], 'targ ex')\n",
    "print(example_batch['cloud_volume_target'][0:5], 'targ verif')\n",
    "print(targs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd60b0f-c588-4c71-83d8-8c904474c458",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
