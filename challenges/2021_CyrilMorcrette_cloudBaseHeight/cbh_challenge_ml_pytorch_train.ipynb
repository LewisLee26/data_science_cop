{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6729aad1-261a-48fa-ae59-986428165ebd",
   "metadata": {},
   "source": [
    "# Training a neural network in PyTorch\n",
    "\n",
    "This notebook demonstrates training a classifier in PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea2ebc23-4958-4cc3-8f6b-c30686f571eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pl ver: 1.6.4\n"
     ]
    }
   ],
   "source": [
    "# file handling\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "import dask\n",
    "import dask.array\n",
    "\n",
    "# math operators\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "# ml\n",
    "import torch\n",
    "import zarr\n",
    "\n",
    "print(\"pl ver:\", pl.__version__)\n",
    "\n",
    "import datetime\n",
    "\n",
    "# training helpers\n",
    "import mlflow.pytorch\n",
    "from dask.diagnostics import CacheProfiler, Profiler, ResourceProfiler\n",
    "from mlflow.tracking import MlflowClient\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "from pytorch_lightning.callbacks import (\n",
    "    RichProgressBar,\n",
    ")  # this progress bar works through jupyterHub on spice\n",
    "\n",
    "# defined in directory (model related definitions)\n",
    "import cbh_data_definitions\n",
    "import cbh_torch_lstm\n",
    "import cbh_torch_MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "508614de-9142-42df-811b-bba77c76bea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "RELOAD_PACKAGES = True\n",
    "if RELOAD_PACKAGES:\n",
    "    import importlib\n",
    "\n",
    "    importlib.reload(cbh_torch_lstm)\n",
    "    importlib.reload(cbh_torch_MLP)\n",
    "    importlib.reload(cbh_data_definitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2d53e4d-26b1-4d18-a0b7-3f7232f73063",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_data_directory = pathlib.Path(os.environ[\"SCRATCH\"]) / \"cbh_data\"\n",
    "\n",
    "dev_data_path = root_data_directory / \"analysis_ready\" / \"dev.zarr\"\n",
    "training_data_path = root_data_directory / \"analysis_ready\" / \"train.zarr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c96b79fe-a8c4-4026-a77f-39d048642745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded zarr, file information:\n",
      " Name        : /\n",
      "Type        : zarr.hierarchy.Group\n",
      "Read-only   : False\n",
      "Store type  : zarr.storage.DirectoryStore\n",
      "No. members : 3\n",
      "No. arrays  : 3\n",
      "No. groups  : 0\n",
      "Arrays      : cloud_base_label_y.zarr, cloud_volume_fraction_y.zarr,\n",
      "            : humidity_temp_pressure_x.zarr\n",
      " \n",
      "\n",
      "Loaded zarr, file information:\n",
      " Name        : /\n",
      "Type        : zarr.hierarchy.Group\n",
      "Read-only   : False\n",
      "Store type  : zarr.storage.DirectoryStore\n",
      "No. members : 3\n",
      "No. arrays  : 3\n",
      "No. groups  : 0\n",
      "Arrays      : cloud_base_label_y.zarr, cloud_volume_fraction_y.zarr,\n",
      "            : humidity_temp_pressure_x.zarr\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    train_input,\n",
    "    train_labels,\n",
    "    train_cloud_volume,\n",
    ") = cbh_data_definitions.load_data_from_zarr(training_data_path)\n",
    "\n",
    "(dev_input, dev_labels, dev_cloud_volume) = cbh_data_definitions.load_data_from_zarr(\n",
    "    dev_data_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c8b8915-497a-4d90-8ec2-971caa896dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "LIMIT_DATA = True\n",
    "LIMIT_DATA_INT = 5024000\n",
    "if LIMIT_DATA:\n",
    "    train_input = train_input[:LIMIT_DATA_INT]\n",
    "    train_labels = train_labels[:LIMIT_DATA_INT]\n",
    "    train_cloud_volume = train_cloud_volume[:LIMIT_DATA_INT]\n",
    "    dev_input = dev_input[:LIMIT_DATA_INT]\n",
    "    dev_labels = dev_labels[:LIMIT_DATA_INT]\n",
    "    dev_cloud_volume = dev_cloud_volume[:LIMIT_DATA_INT]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffba27b-d62f-4bcd-8132-e668c3479e3b",
   "metadata": {},
   "source": [
    "## Define the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b83e7351-b657-4e9b-8997-2d4022f8b5e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# enforce reproducibility\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0ab5c4-12e5-48cb-a947-f4f70a0e520e",
   "metadata": {},
   "source": [
    "## Perform the network initialization and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ce919a8-22f0-46c1-a895-6b7c07ccdba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model and hyperparameters\n",
    "model_hyperparameter_dictionary = {\n",
    "    \"LSTM\": {\n",
    "        \"input_size\": train_input.shape[2],  # input size is the cell input (feat dim)\n",
    "        \"lstm_layers\": 1,\n",
    "        \"lstm_hidden_size\": 8,\n",
    "        \"output_size\": 1,  # for each height layer, predict one value for cloud base prob\n",
    "        \"height_dimension\": train_input.shape[1],\n",
    "        \"embed_size\": 1,\n",
    "        \"BILSTM\": False,\n",
    "        \"batch_first\": True,\n",
    "        \"lr\": 0.003,\n",
    "    },\n",
    "    \"MLP\": {\n",
    "        \"input_size\": train_input.shape[2] * train_input.shape[1],\n",
    "        \"ff_nodes\": 256,\n",
    "        \"output_size\": train_input.shape[1],\n",
    "        \"lr\": 1.0e-4,\n",
    "    },\n",
    "}\n",
    "\n",
    "model_definition_dictionary = {\n",
    "    \"LSTM\": cbh_torch_lstm.CloudBaseLSTM(**model_hyperparameter_dictionary[\"LSTM\"]),\n",
    "    \"MLP\": cbh_torch_MLP.CloudBaseMLP(**model_hyperparameter_dictionary[\"MLP\"]),\n",
    "}\n",
    "\n",
    "model = model_definition_dictionary[\"LSTM\"]  # pick a model\n",
    "\n",
    "# define training related hyperparameters\n",
    "\n",
    "epochs = 1\n",
    "max_time = \"00:02:20:00\"  # dd:hh:mm:ss\n",
    "\n",
    "# after training parameters defined, load datasets into dataloaders (enforce 0 as workers on sys to prevent multiple packages\n",
    "# trying to parallelise while not communicating\n",
    "workers_on_system = 0\n",
    "collate_fn = cbh_data_definitions.dataloader_collate_with_dask\n",
    "batch_size = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adc82bd5-20a8-4072-a266-4c162e41ed41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing x...\n",
      "Computing y...\n",
      "Computing lab...\n",
      "Computing x...\n",
      "Computing y...\n",
      "Computing lab...\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader = None, None\n",
    "\n",
    "INTO_MEMORY = True\n",
    "if INTO_MEMORY:\n",
    "    train_loader = cbh_data_definitions.define_data_get_loader_into_memory(\n",
    "        train_input,\n",
    "        train_cloud_volume,\n",
    "        train_labels,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=workers_on_system,\n",
    "        collate_fn=collate_fn,\n",
    "    )\n",
    "    val_loader = cbh_data_definitions.define_data_get_loader_into_memory(\n",
    "        dev_input,\n",
    "        dev_cloud_volume,\n",
    "        dev_labels,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=workers_on_system,\n",
    "        collate_fn=collate_fn,\n",
    "    )\n",
    "\n",
    "else:\n",
    "    train_loader = cbh_data_definitions.define_data_get_loader(\n",
    "        train_input,\n",
    "        train_cloud_volume,\n",
    "        train_labels,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=workers_on_system,\n",
    "        collate_fn=collate_fn,\n",
    "    )\n",
    "    val_loader = cbh_data_definitions.define_data_get_loader(\n",
    "        dev_input,\n",
    "        dev_cloud_volume,\n",
    "        dev_labels,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=workers_on_system,\n",
    "        collate_fn=collate_fn,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2763eaf2-bedd-4834-a1f2-030b170d1899",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# define trainer\n",
    "\n",
    "time_for_checkpoint = datetime.timedelta(minutes=20)\n",
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "    train_time_interval=time_for_checkpoint\n",
    ")\n",
    "callbacks = [checkpoint_callback, RichProgressBar()]\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=epochs,\n",
    "    deterministic=True,\n",
    "    check_val_every_n_epoch=1,\n",
    "    devices=\"auto\",\n",
    "    accelerator=\"auto\",\n",
    "    max_time=max_time,\n",
    "    enable_checkpointing=True,\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39551462-62c9-4181-a41b-640463f4196c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup mlflow logging\n",
    "\n",
    "mlflow.pytorch.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c2dade6-a531-43b9-a88c-dcfb92937ab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Epoch 0   </span> <span style=\"color: #6206e0; text-decoration-color: #6206e0\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">5207/5207</span> <span style=\"color: #8a8a8a; text-decoration-color: #8a8a8a\">0:20:17 • 0:00:00</span> <span style=\"color: #b2b2b2; text-decoration-color: #b2b2b2\">6.49it/s</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">loss: 2.75 v_num: 2126682 </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[37mEpoch 0   \u001b[0m \u001b[38;2;98;6;224m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[37m5207/5207\u001b[0m \u001b[38;5;245m0:20:17 • 0:00:00\u001b[0m \u001b[38;5;249m6.49it/s\u001b[0m \u001b[37mloss: 2.75 v_num: 2126682 \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/10/04 14:26:45 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during pytorch autologging: serializing a string larger than 4 GiB requires pickle protocol 4 or higher\n"
     ]
    }
   ],
   "source": [
    "# run the training function\n",
    "with mlflow.start_run() as run:\n",
    "    trainer.fit(model=model, train_dataloaders=train_loader, val_dataloaders=val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba52d2c-1212-4894-ad05-3a9f7761ccf2",
   "metadata": {},
   "source": [
    "## Display and evaluate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "888b7d7e-5158-42a9-b3f2-046dca3a218c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_auto_logged_info(r):\n",
    "\n",
    "    tags = {k: v for k, v in r.data.tags.items() if not k.startswith(\"mlflow.\")}\n",
    "    artifacts = [f.path for f in MlflowClient().list_artifacts(r.info.run_id, \"model\")]\n",
    "    print(\"run_id: {}\".format(r.info.run_id))\n",
    "    print(\"artifacts: {}\".format(artifacts))\n",
    "    print(\"params: {}\".format(r.data.params))\n",
    "    print(\"metrics: {}\".format(r.data.metrics))\n",
    "    print(\"tags: {}\".format(tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c108cb0a-4886-40ac-8ab8-af913c5d3b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_id: 6dfe03b528b54577ac22e83a85627bfc\n",
      "artifacts: []\n",
      "params: {'epochs': '1', 'optimizer_name': 'Adam', 'lr': '0.003', 'betas': '(0.9, 0.999)', 'eps': '1e-08', 'weight_decay': '0', 'amsgrad': 'False'}\n",
      "metrics: {'training base height loss component': 2.7354509830474854, 'training loss': 2.7354509830474854, 'validation base height loss component': 3.0111770629882812, 'validation loss': 3.0111770629882812}\n",
      "tags: {'Mode': 'training'}\n"
     ]
    }
   ],
   "source": [
    "# display mlflow output\n",
    "print_auto_logged_info(mlflow.get_run(run_id=run.info.run_id))\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7a9ef9b-ef4f-4c02-9b9f-23fa53a1b263",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_save_str_element = str(datetime.datetime.now())\n",
    "save_str = \"model_out\" + \"_\" + unique_save_str_element + \".ckpt\"\n",
    "trainer.save_checkpoint(save_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ce386db-e33d-42aa-90ff-8a4a4dd3be76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 70, 3]) Input shape\n",
      "Height vector shape: torch.Size([1024, 70])\n",
      "torch.Size([1024, 70]) prediction output\n",
      "(1024,) prediction label shape\n",
      "(1024,) targ shape\n",
      "Correct samples: 366\n",
      "Total samples tested: 1024\n",
      "Accuracy: 35.7421875 %\n"
     ]
    }
   ],
   "source": [
    "# test model functionality\n",
    "example_batch = next(iter(train_loader))\n",
    "heights = example_batch[\"height_vector\"]\n",
    "inputs = example_batch[\"x\"]\n",
    "print(inputs.shape, \"Input shape\")\n",
    "print(\"Height vector shape:\", example_batch[\"height_vector\"].shape)\n",
    "try:\n",
    "    preds, _ = model(inputs, heights)\n",
    "except:\n",
    "    print(example_batch[\"x\"].shape, \"inp pre-flat\")\n",
    "    inputs = torch.flatten(example_batch[\"x\"], start_dim=1)\n",
    "    preds = model(inputs)\n",
    "print(preds.shape, \"prediction output\")\n",
    "pred_label = np.argmax(preds.detach().numpy(), axis=1)\n",
    "print(pred_label.shape, \"prediction label shape\")\n",
    "targs = example_batch[\"cloud_base_target\"]\n",
    "targs = np.array(targs)\n",
    "print(targs.shape, \"targ shape\")\n",
    "correct = targs == pred_label\n",
    "print(\"Correct samples:\", np.count_nonzero(correct))\n",
    "print(\"Total samples tested:\", len(correct))\n",
    "print(\"Accuracy:\", (np.count_nonzero(correct) / len(correct) * 100), \"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda-pl Python (Conda)",
   "language": "python",
   "name": "conda-env-.conda-pl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
