{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6729aad1-261a-48fa-ae59-986428165ebd",
   "metadata": {},
   "source": [
    "# Training a neural network in PyTorch\n",
    "\n",
    "This notebook demonstrates training a classifier in PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea2ebc23-4958-4cc3-8f6b-c30686f571eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pl ver: 1.7.7\n",
      "mlflow ver: 1.30.0\n",
      "torch ver: 1.12.1\n",
      "Python ver: sys.version_info(major=3, minor=10, micro=6, releaselevel='final', serial=0)\n"
     ]
    }
   ],
   "source": [
    "# file handling\n",
    "import os\n",
    "import pathlib\n",
    "import sys\n",
    "\n",
    "from pytorch_lightning.loggers import MLFlowLogger\n",
    "\n",
    "import dask\n",
    "import dask.array\n",
    "\n",
    "# math operators\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "# ml\n",
    "import torch\n",
    "import zarr\n",
    "\n",
    "import datetime\n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "# training helpers\n",
    "import mlflow.pytorch\n",
    "from dask.diagnostics import CacheProfiler, Profiler, ResourceProfiler, visualize\n",
    "from mlflow.tracking import MlflowClient\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "from pytorch_lightning.callbacks import (\n",
    "    RichProgressBar,\n",
    ")  # this progress bar works through jupyterHub on spice\n",
    "\n",
    "# defined in directory (model related definitions)\n",
    "import cbh_data_definitions\n",
    "cbh_data_definitions.register_cache()\n",
    "import cbh_torch_lstm\n",
    "import cbh_torch_MLP\n",
    "\n",
    "print(\"pl ver:\", pl.__version__)\n",
    "print(\"mlflow ver:\", mlflow.__version__)\n",
    "print(\"torch ver:\", torch.__version__)\n",
    "print(\"Python ver:\", sys.version_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "508614de-9142-42df-811b-bba77c76bea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "RELOAD_PACKAGES = True\n",
    "if RELOAD_PACKAGES:\n",
    "    import importlib\n",
    "    importlib.reload(cbh_torch_lstm)\n",
    "    importlib.reload(cbh_torch_MLP)\n",
    "    importlib.reload(cbh_data_definitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2d53e4d-26b1-4d18-a0b7-3f7232f73063",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_data_directory = pathlib.Path(os.environ[\"SCRATCH\"]) / \"cbh_data\"\n",
    "\n",
    "dev_data_path = root_data_directory / \"analysis_ready\" / \"dev.zarr\"\n",
    "training_data_path = root_data_directory / \"analysis_ready\" / \"train.zarr\"\n",
    "\n",
    "mlflow_command_line_run = \"\"\"\n",
    "    mlflow server --port 5001 --backend-store-uri sqlite:///mlflowSQLserver.db  --default-artifact-root ./mlflow_artifacts/\n",
    "\"\"\"\n",
    "mlflow_server_address = 'vld425'\n",
    "mlflow_server_port = 5001\n",
    "mlflow_server_uri = f'http://{mlflow_server_address}:{mlflow_server_port:d}'\n",
    "mlflow_artifact_root = pathlib.Path('./mlflow_artifacts/')\n",
    "\n",
    "hparams_for_mlflow = {}\n",
    "\n",
    "CPU_COUNT = 8\n",
    "RAM_GB = 64\n",
    "hparams_for_mlflow['CPU Count'] = CPU_COUNT\n",
    "hparams_for_mlflow['Compute Memory'] = RAM_GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c96b79fe-a8c4-4026-a77f-39d048642745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded zarr, file information:\n",
      " Name              : /\n",
      "Type              : zarr.hierarchy.Group\n",
      "Read-only         : False\n",
      "Synchronizer type : zarr.sync.ThreadSynchronizer\n",
      "Store type        : zarr.storage.DirectoryStore\n",
      "No. members       : 3\n",
      "No. arrays        : 3\n",
      "No. groups        : 0\n",
      "Arrays            : cloud_base_label_y.zarr, cloud_volume_fraction_y.zarr,\n",
      "                  : humidity_temp_pressure_x.zarr\n",
      " \n",
      "\n",
      "Loaded zarr, file information:\n",
      " Name              : /\n",
      "Type              : zarr.hierarchy.Group\n",
      "Read-only         : False\n",
      "Synchronizer type : zarr.sync.ThreadSynchronizer\n",
      "Store type        : zarr.storage.DirectoryStore\n",
      "No. members       : 3\n",
      "No. arrays        : 3\n",
      "No. groups        : 0\n",
      "Arrays            : cloud_base_label_y.zarr, cloud_volume_fraction_y.zarr,\n",
      "                  : humidity_temp_pressure_x.zarr\n",
      " \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table>\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 87.48 GiB </td>\n",
       "                        <td> 373.24 MiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (111820800, 70, 3) </td>\n",
       "                        <td> (465920, 70, 3) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Count </th>\n",
       "                        <td> 2 Graph Layers </td>\n",
       "                        <td> 240 Chunks </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                    <th> Type </th>\n",
       "                    <td> float32 </td>\n",
       "                    <td> numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"156\" height=\"146\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"80\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"10\" y1=\"25\" x2=\"80\" y2=\"96\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"10\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"13\" y1=\"3\" x2=\"13\" y2=\"28\" />\n",
       "  <line x1=\"17\" y1=\"7\" x2=\"17\" y2=\"32\" />\n",
       "  <line x1=\"20\" y1=\"10\" x2=\"20\" y2=\"36\" />\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"24\" y2=\"40\" />\n",
       "  <line x1=\"28\" y1=\"18\" x2=\"28\" y2=\"43\" />\n",
       "  <line x1=\"32\" y1=\"22\" x2=\"32\" y2=\"47\" />\n",
       "  <line x1=\"35\" y1=\"25\" x2=\"35\" y2=\"51\" />\n",
       "  <line x1=\"39\" y1=\"29\" x2=\"39\" y2=\"55\" />\n",
       "  <line x1=\"43\" y1=\"33\" x2=\"43\" y2=\"58\" />\n",
       "  <line x1=\"47\" y1=\"37\" x2=\"47\" y2=\"62\" />\n",
       "  <line x1=\"50\" y1=\"40\" x2=\"50\" y2=\"66\" />\n",
       "  <line x1=\"54\" y1=\"44\" x2=\"54\" y2=\"69\" />\n",
       "  <line x1=\"58\" y1=\"48\" x2=\"58\" y2=\"73\" />\n",
       "  <line x1=\"61\" y1=\"51\" x2=\"61\" y2=\"77\" />\n",
       "  <line x1=\"65\" y1=\"55\" x2=\"65\" y2=\"81\" />\n",
       "  <line x1=\"69\" y1=\"59\" x2=\"69\" y2=\"84\" />\n",
       "  <line x1=\"72\" y1=\"62\" x2=\"72\" y2=\"88\" />\n",
       "  <line x1=\"76\" y1=\"66\" x2=\"76\" y2=\"92\" />\n",
       "  <line x1=\"80\" y1=\"70\" x2=\"80\" y2=\"96\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 80.58823529411765,70.58823529411765 80.58823529411765,96.00085180870013 10.0,25.412616514582485\" style=\"fill:#8B4903A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"35\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"13\" y1=\"3\" x2=\"38\" y2=\"3\" />\n",
       "  <line x1=\"17\" y1=\"7\" x2=\"42\" y2=\"7\" />\n",
       "  <line x1=\"20\" y1=\"10\" x2=\"46\" y2=\"10\" />\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"50\" y2=\"14\" />\n",
       "  <line x1=\"28\" y1=\"18\" x2=\"53\" y2=\"18\" />\n",
       "  <line x1=\"32\" y1=\"22\" x2=\"57\" y2=\"22\" />\n",
       "  <line x1=\"35\" y1=\"25\" x2=\"61\" y2=\"25\" />\n",
       "  <line x1=\"39\" y1=\"29\" x2=\"65\" y2=\"29\" />\n",
       "  <line x1=\"43\" y1=\"33\" x2=\"68\" y2=\"33\" />\n",
       "  <line x1=\"47\" y1=\"37\" x2=\"72\" y2=\"37\" />\n",
       "  <line x1=\"50\" y1=\"40\" x2=\"76\" y2=\"40\" />\n",
       "  <line x1=\"54\" y1=\"44\" x2=\"79\" y2=\"44\" />\n",
       "  <line x1=\"58\" y1=\"48\" x2=\"83\" y2=\"48\" />\n",
       "  <line x1=\"61\" y1=\"51\" x2=\"87\" y2=\"51\" />\n",
       "  <line x1=\"65\" y1=\"55\" x2=\"91\" y2=\"55\" />\n",
       "  <line x1=\"69\" y1=\"59\" x2=\"94\" y2=\"59\" />\n",
       "  <line x1=\"72\" y1=\"62\" x2=\"98\" y2=\"62\" />\n",
       "  <line x1=\"76\" y1=\"66\" x2=\"102\" y2=\"66\" />\n",
       "  <line x1=\"80\" y1=\"70\" x2=\"106\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"80\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"35\" y1=\"0\" x2=\"106\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 35.41261651458248,0.0 106.00085180870013,70.58823529411765 80.58823529411765,70.58823529411765\" style=\"fill:#8B4903A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"80\" y1=\"70\" x2=\"106\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"80\" y1=\"96\" x2=\"106\" y2=\"96\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"80\" y1=\"70\" x2=\"80\" y2=\"96\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"106\" y1=\"70\" x2=\"106\" y2=\"96\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"80.58823529411765,70.58823529411765 106.00085180870013,70.58823529411765 106.00085180870013,96.00085180870013 80.58823529411765,96.00085180870013\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"93.294544\" y=\"116.000852\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >3</text>\n",
       "  <text x=\"126.000852\" y=\"83.294544\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(0,126.000852,83.294544)\">70</text>\n",
       "  <text x=\"35.294118\" y=\"80.706734\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(45,35.294118,80.706734)\">111820800</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<from-zarr, shape=(111820800, 70, 3), dtype=float32, chunksize=(465920, 70, 3), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    train_input,\n",
    "    train_labels,\n",
    "    _,\n",
    ") = cbh_data_definitions.load_data_from_zarr(training_data_path)\n",
    "\n",
    "(\n",
    "    dev_input, \n",
    "    dev_labels, \n",
    "    _\n",
    ") = cbh_data_definitions.load_data_from_zarr(dev_data_path)\n",
    "\n",
    "# the cloud volume is not needed for the task, so isn't saved on the load\n",
    "#show a chunk, used to inform dask cache size\n",
    "train_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c8b8915-497a-4d90-8ec2-971caa896dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "LIMIT_DATA = False\n",
    "LIMIT_DATA_INT = -1\n",
    "if LIMIT_DATA:\n",
    "    LIMIT_DATA_INT = 10024\n",
    "    train_input = train_input[:LIMIT_DATA_INT]\n",
    "    train_labels = train_labels[:LIMIT_DATA_INT]\n",
    "    # train_cloud_volume = train_cloud_volume[:LIMIT_DATA_INT]\n",
    "    dev_input = dev_input[:LIMIT_DATA_INT]\n",
    "    dev_labels = dev_labels[:LIMIT_DATA_INT]\n",
    "    # dev_cloud_volume = dev_cloud_volume[:LIMIT_DATA_INT]\n",
    "hparams_for_mlflow['Limited sample number'] =  LIMIT_DATA_INT  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffba27b-d62f-4bcd-8132-e668c3479e3b",
   "metadata": {},
   "source": [
    "## Define the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b83e7351-b657-4e9b-8997-2d4022f8b5e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "# enforce reproducibility\n",
    "seed_everything_int = 42\n",
    "seed_everything(seed_everything_int)\n",
    "hparams_for_mlflow['Random seed'] = seed_everything_int"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0ab5c4-12e5-48cb-a947-f4f70a0e520e",
   "metadata": {},
   "source": [
    "## Perform the network initialization and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ce919a8-22f0-46c1-a895-6b7c07ccdba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data chunk size: 465920\n",
      "Factors of chunk:  [1, 2, 4, 5, 7, 8, 10, 13, 14, 16, 20, 26, 28, 32, 35, 40, 52, 56, 64, 65, 70, 80, 91, 104, 112, 128, 130, 140, 160, 182, 208, 224, 256, 260, 280, 320, 364, 416, 448, 455, 512, 520, 560, 640, 728, 832, 896, 910, 1024, 1040, 1120, 1280, 1456, 1664, 1792, 1820, 2080, 2240, 2560, 2912, 3328, 3584, 3640, 4160, 4480, 5120, 5824, 6656, 7168, 7280, 8320, 8960, 11648, 13312, 14560, 16640, 17920, 23296, 29120, 33280, 35840, 46592, 58240, 66560, 93184, 116480, 232960, 465920]\n"
     ]
    }
   ],
   "source": [
    "# define model and hyperparameters\n",
    "model_hyperparameter_dictionary = {\n",
    "    \"LSTM\": {\n",
    "        \"input_size\": train_input.shape[2],  # input size is the cell input (feat dim)\n",
    "        \"lstm_layers\": 1,\n",
    "        \"lstm_hidden_size\": 8,\n",
    "        \"output_size\": 1,  # for each height layer, predict one value for cloud base prob\n",
    "        \"height_dimension\": train_input.shape[1],\n",
    "        \"embed_size\": 1,\n",
    "        \"BILSTM\": False,\n",
    "        \"batch_first\": True,\n",
    "        \"lr\": 0.003,\n",
    "    },\n",
    "    \"MLP\": {\n",
    "        \"input_size\": train_input.shape[2] * train_input.shape[1],\n",
    "        \"ff_nodes\": 32,\n",
    "        \"output_size\": train_input.shape[1],\n",
    "        \"lr\": 1.0e-4,\n",
    "    },\n",
    "}\n",
    "\n",
    "model_definition_dictionary = {\n",
    "    \"LSTM\": cbh_torch_lstm.CloudBaseLSTM(**model_hyperparameter_dictionary[\"LSTM\"]),\n",
    "    \"MLP\": cbh_torch_MLP.CloudBaseMLP(**model_hyperparameter_dictionary[\"MLP\"]),\n",
    "}\n",
    "model_picked = \"MLP\"\n",
    "model = model_definition_dictionary[model_picked]  # pick a model\n",
    "hparams_for_mlflow[\"Model defined hparams\"] = model_hyperparameter_dictionary[model_picked]\n",
    "\n",
    "\n",
    "# define training related hyperparameters\n",
    "\n",
    "epochs = 1\n",
    "hparams_for_mlflow[\"Max epochs\"] = epochs\n",
    "\n",
    "# after training parameters defined, load datasets into dataloaders (enforce 0 as workers on sys to prevent multiple packages\n",
    "# trying to parallelise while not communicating\n",
    "collate_fn = cbh_data_definitions.dataloader_collate_with_dask\n",
    "print(\"Data chunk size:\", train_input.chunksize[0])\n",
    "print(\"Factors of chunk: \", [n for n in range(1, train_input.chunksize[0] + 1) if train_input.chunksize[0] % n == 0])\n",
    "batch_size = 64\n",
    "hparams_for_mlflow[\"Batch size\"] = batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adc82bd5-20a8-4072-a266-4c162e41ed41",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader = None, None\n",
    "\n",
    "single_proc_workers = False # else crashes\n",
    "if single_proc_workers:\n",
    "    WORKERS_CPU_COUNT=0\n",
    "else:\n",
    "    WORKERS_CPU_COUNT = CPU_COUNT\n",
    "\n",
    "data_loader_hparam_dict = {\n",
    "    'batch_size':batch_size,\n",
    "    'num_workers':WORKERS_CPU_COUNT,\n",
    "    'pin_memory':False,\n",
    "    'collate_fn':collate_fn,\n",
    "    'thread_count_for_dask':CPU_COUNT\n",
    "}\n",
    "shuffle_training_data=False,\n",
    "\n",
    "INTO_MEMORY = False\n",
    "if INTO_MEMORY:\n",
    "    train_loader = cbh_data_definitions.define_data_get_loader_into_memory(\n",
    "        train_input,\n",
    "        train_labels,\n",
    "        shuffle=shuffle_training_data,\n",
    "        **data_loader_hparam_dict\n",
    "    )\n",
    "    val_loader = cbh_data_definitions.define_data_get_loader_into_memory(\n",
    "        dev_input,\n",
    "        dev_labels,\n",
    "        shuffle=False,\n",
    "        **data_loader_hparam_dict\n",
    "    )\n",
    "else:\n",
    "    train_loader = cbh_data_definitions.define_data_get_loader(\n",
    "        train_input,\n",
    "        train_labels,\n",
    "        shuffle=shuffle_training_data,\n",
    "        **data_loader_hparam_dict\n",
    "    )\n",
    "    val_loader = cbh_data_definitions.define_data_get_loader(\n",
    "        dev_input,\n",
    "        dev_labels,\n",
    "        shuffle=False,\n",
    "        **data_loader_hparam_dict\n",
    "    )\n",
    "data_loader_hparam_dict['shuffle_training_data']=shuffle_training_data\n",
    "hparams_for_mlflow[\"Data loaded into memory\"] = INTO_MEMORY\n",
    "hparams_for_mlflow['data loader hparams'] = data_loader_hparam_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39551462-62c9-4181-a41b-640463f4196c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating experiment\n"
     ]
    }
   ],
   "source": [
    "experiment_name = 'cbh-label-model-runs'\n",
    "experiment_name = 'test-setup-for-model-runs'\n",
    "\n",
    "# torch.set_num_threads(CPU_COUNT)\n",
    "\n",
    "mlflow.set_tracking_uri(mlflow_server_uri)\n",
    "# make vars global\n",
    "mlf_exp = None\n",
    "mlf_exp_id = None\n",
    "try: \n",
    "    print('Creating experiment')\n",
    "    mlf_exp_id = mlflow.create_experiment(experiment_name)\n",
    "    mlf_exp = mlflow.get_experiment(mlf_exp_id)\n",
    "except mlflow.exceptions.RestException:\n",
    "    mlf_exp = mlflow.get_experiment_by_name(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21185156-4866-4d28-8c57-f036993f8170",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLFlowLogger(pl.loggers.MLFlowLogger): #overwrite mlflogger\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def after_save_checkpoint(self, model_checkpoint: pl.callbacks.ModelCheckpoint) -> None:\n",
    "        \"\"\"\n",
    "        Called after model checkpoint callback saves a new checkpoint.\n",
    "        \"\"\"\n",
    "        best_chkpt = torch.load(capture_var.best_model_path)\n",
    "        # print(best_chkpt)\n",
    "        # print(best_chkpt['callbacks'])\n",
    "        checkpoint_for_mlflow = {\n",
    "            \"val loss\": float(best_chkpt['callbacks'][list(key for key in list(best_chkpt['callbacks'].keys()) if \"ModelCheckpoint\" in key)[0]]['current_score']),\n",
    "            \"train loss at step-1\": list(train_loss_metric.value for train_loss_metric in mlf_logger._mlflow_client.get_metric_history(run.info.run_id, \"Train loss\") if (int(train_loss_metric.step) == int(best_chkpt['global_step']-1)))[0],\n",
    "            \"global_step\": best_chkpt['global_step'],\n",
    "            \"model_state_dict\": best_chkpt['state_dict'],\n",
    "            \"checkpoint\": best_chkpt,\n",
    "\n",
    "        }\n",
    "        with TemporaryDirectory() as tmpdirname:\n",
    "            f_name = os.path.join(tmpdirname, f\"{run.info.run_id}-best_model_checkpoint-step_{best_chkpt['global_step']}.pt\")\n",
    "            torch.save(checkpoint_for_mlflow, f_name)\n",
    "            mlflow.log_artifact(f_name)\n",
    "        # print(trainer._checkpoint_connector.dump_checkpoint() == chkpt_state_dict)\n",
    "        # print(trainer._checkpoint_connector.dump_checkpoint()['state_dict'] == chkpt_state_dict)\n",
    "        # chkpt_state_dict.update(trainer._checkpoint_connector.dump_checkpoint()['state_dict'])\n",
    "        # # print(chkpt_state_dict)\n",
    "        # rmlist = [\"epoch\", \"global_step\", \"pytorch-lightning_version\", \"state_dict\", \"loops\", \"callbacks\", \"optimizer_states\", \"lr_schedulers\", \"hparams_name\", \"hyper_parameters\"]\n",
    "        # for elem in rmlist:\n",
    "        #     chkpt_state_dict.pop(elem)\n",
    "        \n",
    "        # torch_native_model = cbh_torch_MLP.CloudBaseMLP(**model_hyperparameter_dictionary[\"MLP\"])  # PLEASE GENERALIZE\n",
    "        # torch_native_model.load_state_dict(chkpt_state_dict)\n",
    "        # with TemporaryDirectory() as tmpdirname:\n",
    "        #     f_name = join(tmpdirname, f\"{run.info.run_id}-best_model_checkpoint.pt\")\n",
    "        #     torch.save(checkpoint, f_name)\n",
    "        #     mlflow.log_artifact(f_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c2dade6-a531-43b9-a88c-dcfb92937ab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Epoch 0/0 </span> <span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">176/1843200</span> <span style=\"color: #8a8a8a; text-decoration-color: #8a8a8a\">0:10:20 • 67 days, 9:12:14</span> <span style=\"color: #b2b2b2; text-decoration-color: #b2b2b2\">0.32it/s</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">loss: 4.06 v_num: 3223 </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[37mEpoch 0/0 \u001b[0m \u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[37m176/1843200\u001b[0m \u001b[38;5;245m0:10:20 • 67 days, 9:12:14\u001b[0m \u001b[38;5;249m0.32it/s\u001b[0m \u001b[37mloss: 4.06 v_num: 3223 \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/h02/hsouth/.conda/envs/py-lightning/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:653: \n",
       "UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
       "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/h02/hsouth/.conda/envs/py-lightning/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:653: \n",
       "UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
       "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/11/01 14:40:42 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during pytorch autologging: cannot pickle '_thread.RLock' object\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ended run 97a2587bf69049319b3dc98684a73223\n"
     ]
    }
   ],
   "source": [
    "# import traceback\n",
    "# import warnings\n",
    "# import sys\n",
    "# def warn_with_traceback(message, category, filename, lineno, file=None, line=None):\n",
    "#     log = file if hasattr(file,'write') else sys.stderr\n",
    "#     traceback.print_stack(file=log)\n",
    "#     log.write(warnings.formatwarning(message, category, filename, lineno, line))\n",
    "# warnings.showwarning = warn_with_traceback\n",
    "# warnings.simplefilter(\"always\")\n",
    "\n",
    "# run the training function\n",
    "# setup mlflow logging\n",
    "\n",
    "max_time = \"00:02:20:00\"  # dd:hh:mm:ss\n",
    "\n",
    "hparams_for_mlflow[\"Training timeout\"] = max_time\n",
    "\n",
    "timestamp_template = '{dt.year:04d}{dt.month:02d}{dt.day:02d}T{dt.hour:02d}{dt.minute:02d}{dt.second:02d}'\n",
    "run_name_template = 'cbh_challenge_{network_name}_' + timestamp_template\n",
    "current_run_name = run_name_template.format(network_name=model.__class__.__name__,\n",
    "                                                dt=datetime.datetime.now()\n",
    "                                               )\n",
    "\n",
    "# with Profiler() as prof, ResourceProfiler(dt=0.25) as rprof, CacheProfiler() as cprof:\n",
    "with mlflow.start_run(experiment_id=mlf_exp.experiment_id, run_name=current_run_name) as run:\n",
    "\n",
    "    mlflow.pytorch.autolog()\n",
    "    mlf_logger = MLFlowLogger(experiment_name=experiment_name, tracking_uri=mlflow_server_uri, run_id=run.info.run_id)\n",
    "\n",
    "\n",
    "    # define trainer\n",
    "    # time_for_checkpoint = datetime.timedelta(minutes=0.1)\n",
    "    checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "        # train_time_interval=time_for_checkpoint,\n",
    "        dirpath=run.info.artifact_uri,\n",
    "        monitor=\"Val loss\",\n",
    "        save_on_train_epoch_end=False,\n",
    "        mode=\"min\"\n",
    "    )\n",
    "    callbacks = [checkpoint_callback, RichProgressBar()]\n",
    "    trainer_hparams = {\n",
    "        'max_epochs':epochs,\n",
    "        'deterministic':True,\n",
    "        'val_check_interval':0.01, # save every percentage of the data\n",
    "        'devices':\"auto\",\n",
    "        'accelerator':\"auto\",\n",
    "        'max_time':max_time,\n",
    "        'enable_checkpointing':True,\n",
    "        'strategy':None,\n",
    "        'callbacks':callbacks,\n",
    "        'logger':mlf_logger,\n",
    "    }\n",
    "    hparams_for_mlflow[\"Trainer hparams\"] = trainer_hparams\n",
    "    mlf_logger.log_hyperparams(hparams_for_mlflow)\n",
    "    trainer = pl.Trainer(\n",
    "        **trainer_hparams\n",
    "    )\n",
    "    trainer.fit(model=model, train_dataloaders=train_loader, val_dataloaders=val_loader)\n",
    "print(\"Ended run\", run.info.run_id)\n",
    "    # print(visualize([prof, rprof, cprof], filename='profile_loop.html', save=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba52d2c-1212-4894-ad05-3a9f7761ccf2",
   "metadata": {},
   "source": [
    "## Display and evaluate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "888b7d7e-5158-42a9-b3f2-046dca3a218c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_id: 97a2587bf69049319b3dc98684a73223\n",
      "artifacts: []\n",
      "params: {}\n",
      "metrics: {}\n",
      "tags: {}\n"
     ]
    }
   ],
   "source": [
    "def print_auto_logged_info(r):\n",
    "\n",
    "    tags = {k: v for k, v in r.data.tags.items() if not k.startswith(\"mlflow.\")}\n",
    "    artifacts = [f.path for f in MlflowClient().list_artifacts(r.info.run_id, \"model\")]\n",
    "    print(\"run_id: {}\".format(r.info.run_id))\n",
    "    print(\"artifacts: {}\".format(artifacts))\n",
    "    print(\"params: {}\".format(r.data.params))\n",
    "    print(\"metrics: {}\".format(r.data.metrics))\n",
    "    print(\"tags: {}\".format(tags))\n",
    "print_auto_logged_info(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a9ef9b-ef4f-4c02-9b9f-23fa53a1b263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_save_str_element = str(datetime.datetime.now())\n",
    "# save_str = \"model_out\" + \"_\" + unique_save_str_element + \".ckpt\"\n",
    "# trainer.save_checkpoint(save_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce386db-e33d-42aa-90ff-8a4a4dd3be76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test model functionality\n",
    "example_batch = next(iter(train_loader))\n",
    "inputs = example_batch[0]\n",
    "print(inputs.shape, \"Input shape\")\n",
    "try:\n",
    "    preds, _ = model(inputs, heights)\n",
    "except:\n",
    "    print(example_batch[0].shape, \"inp pre-flat\")\n",
    "    inputs = torch.flatten(example_batch[0], start_dim=1)\n",
    "    preds = model(inputs)\n",
    "print(preds.shape, \"prediction output\")\n",
    "pred_label = np.argmax(preds.detach().numpy(), axis=1)\n",
    "print(pred_label.shape, \"prediction label shape\")\n",
    "targs = example_batch[1]\n",
    "targs = np.array(targs)\n",
    "print(targs.shape, \"targ shape\")\n",
    "correct = targs == pred_label\n",
    "print(\"Correct samples:\", np.count_nonzero(correct))\n",
    "print(\"Total samples tested:\", len(correct))\n",
    "print(\"Accuracy:\", (np.count_nonzero(correct) / len(correct) * 100), \"%\")\n",
    "print(\n",
    "    \"Model predictions binned: (Class labels), (Counts):\",\n",
    "    np.unique(pred_label, return_counts=True),\n",
    ")\n",
    "\n",
    "eg_batch_metrics = {\n",
    "    \"Correct samples\" : np.count_nonzero(correct),\n",
    "    \"Total samples tested\" : len(correct),\n",
    "    \"Accuracy\" : (np.count_nonzero(correct) / len(correct) * 100),\n",
    "\n",
    "    \"Model predictions binned: (Class labels), (Counts)\"\n",
    "     : str(np.unique(pred_label, return_counts=True)),\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5a6d3a-5b0b-4fe5-b6d3-664fa93f6498",
   "metadata": {},
   "outputs": [],
   "source": [
    "eg_batch_metrics = {\n",
    "    \"Single batch example validation metrics/Correct samples\" : np.count_nonzero(correct),\n",
    "    \"Single batch example validation metrics/Total samples tested\" : len(correct),\n",
    "    \"Single batch example validation metrics/Accuracy\" : np.count_nonzero(correct) / len(correct) * 100,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b42f978-4908-4d20-95e4-b2d7adf48bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlf_logger.log_metrics(eg_batch_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c108cb0a-4886-40ac-8ab8-af913c5d3b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display mlflow output\n",
    "print_auto_logged_info(mlflow.get_run(run_id=run.info.run_id))\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea68987-995b-433e-90c0-6a610b38ad06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda-py-lightning Python (Conda)",
   "language": "python",
   "name": "conda-env-.conda-py-lightning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
