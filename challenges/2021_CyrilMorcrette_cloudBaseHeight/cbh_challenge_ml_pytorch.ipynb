{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6729aad1-261a-48fa-ae59-986428165ebd",
   "metadata": {},
   "source": [
    "# Training a neural network in PyTorch\n",
    "This notebook demonstrates training a classifier in PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea2ebc23-4958-4cc3-8f6b-c30686f571eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6.4\n"
     ]
    }
   ],
   "source": [
    "import zarr\n",
    "import os\n",
    "import dask\n",
    "import dask.array \n",
    "import torch\n",
    "import numpy as np\n",
    "import pathlib\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "print(pl.__version__)\n",
    "\n",
    "import mlflow.pytorch\n",
    "from mlflow.tracking import MlflowClient\n",
    "# import dask.distributed\n",
    "from dask.diagnostics import Profiler, ResourceProfiler, CacheProfiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2d53e4d-26b1-4d18-a0b7-3f7232f73063",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_data_directory = pathlib.Path(os.environ['SCRATCH']) / 'cbh_data'\n",
    "\n",
    "dev_data_path = root_data_directory / 'analysis_ready' / 'dev.zarr' \n",
    "training_data_path = root_data_directory / 'analysis_ready' / 'train.zarr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d753ee3-ace0-41f2-9500-0e5bb764dcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the data\n",
    "def load_data_from_zarr(path):\n",
    "    \n",
    "    store = zarr.DirectoryStore(training_data_path)\n",
    "    zarr_group = zarr.group(store=store)\n",
    "    print('Loaded zarr, file information:\\n', zarr_group.info, '\\n')\n",
    "    \n",
    "    x = dask.array.from_zarr(zarr_group['humidity_temp_pressure_x.zarr'])\n",
    "    y_lab = dask.array.from_zarr(zarr_group['onehot_cloud_base_height_y.zarr'])\n",
    "    y_cont = dask.array.from_zarr(zarr_group['cloud_volume_fraction_y.zarr'])\n",
    "    \n",
    "    return x, y_lab, y_cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c96b79fe-a8c4-4026-a77f-39d048642745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded zarr, file information:\n",
      " Name        : /\n",
      "Type        : zarr.hierarchy.Group\n",
      "Read-only   : False\n",
      "Store type  : zarr.storage.DirectoryStore\n",
      "No. members : 3\n",
      "No. arrays  : 3\n",
      "No. groups  : 0\n",
      "Arrays      : cloud_volume_fraction_y.zarr, humidity_temp_pressure_x.zarr,\n",
      "            : onehot_cloud_base_height_y.zarr\n",
      " \n",
      "\n",
      "Loaded zarr, file information:\n",
      " Name        : /\n",
      "Type        : zarr.hierarchy.Group\n",
      "Read-only   : False\n",
      "Store type  : zarr.storage.DirectoryStore\n",
      "No. members : 3\n",
      "No. arrays  : 3\n",
      "No. groups  : 0\n",
      "Arrays      : cloud_volume_fraction_y.zarr, humidity_temp_pressure_x.zarr,\n",
      "            : onehot_cloud_base_height_y.zarr\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_input, train_labels, train_cloud_volume = load_data_from_zarr(training_data_path)\n",
    "dev_input, dev_labels, dev_cloud_volume = load_data_from_zarr(dev_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffba27b-d62f-4bcd-8132-e668c3479e3b",
   "metadata": {},
   "source": [
    "## Define the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14361eb6-2ec1-4256-ab8e-3b57e0441b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define RNN\n",
    "class CloudBaseLSTM(pl.LightningModule):\n",
    "    def __init__(self, inputSize, lstmLayers, lstmHiddenSize, output_size, height_dimension, embed_size, BILSTM=True, batch_first=False, lr=2e-3, log_boolean=False, do_linear_fit=False):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.LSTM = torch.nn.LSTM(inputSize+embed_size, lstmHiddenSize, lstmLayers, batch_first=batch_first, bidirectional=BILSTM, proj_size=output_size)\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.batch_first = batch_first\n",
    "        self.proj_size = output_size\n",
    "        \n",
    "        self.relu = torch.nn.ReLU()\n",
    "        \n",
    "        self.height_embedding = torch.nn.Embedding(height_dimension, embed_size)\n",
    "        self.BILSTM = BILSTM\n",
    "        self.lr = lr\n",
    "        \n",
    "        self.loss_fn_vol = torch.nn.MSELoss()\n",
    "        self.do_linear_fit = do_linear_fit\n",
    "        if do_linear_fit:\n",
    "            self.loss_fn_base = torch.nn.CrossEntropyLoss()\n",
    "            self.linearCap = torch.nn.Linear(height_dimension, height_dimension)\n",
    "        \n",
    "        self.log_bool = log_boolean\n",
    "        \n",
    "    def forward(self, x, height):\n",
    "        \n",
    "        #produce height embeds\n",
    "        height_embeds = self.height_embedding(height)\n",
    "        height_embeds = torch.flatten(height_embeds, start_dim=2)\n",
    "        # print(height_embeds.size())\n",
    "        \n",
    "        #concat with feature vector\n",
    "        x_and_height = torch.cat((x, height_embeds), 2)\n",
    "        \n",
    "        #send through LSTM\n",
    "        lstm_out, _ = self.LSTM(x_and_height)\n",
    "        # combine backward and forward LSTM outputs for each cell\n",
    "        if(self.BILSTM):\n",
    "            lstm_out = lstm_out[:,:,:self.proj_size] + lstm_out[:,:,self.proj_size:]\n",
    "        # combinedLSTMOut = combinedLSTMOut / 2\n",
    "        \n",
    "        # # softmax but check for batch first\n",
    "        # softmax_dim = 0\n",
    "        # if self.batch_first:\n",
    "        #     softmax_dim = 1\n",
    "            \n",
    "            \n",
    "        # flatten seq out\n",
    "        lstm_out = torch.flatten(lstm_out, start_dim=1)\n",
    "        \n",
    "        # #normalization\n",
    "        # out = torch.nn.functional.log_softmax(nn_out, dim=softmax_dim)\n",
    "        \n",
    "        # apply ReLU\n",
    "        relu_out = self.relu(lstm_out)\n",
    "        \n",
    "        nn_out = None # initialize for clarity\n",
    "        \n",
    "        if self.do_linear_fit:\n",
    "            # apply linear layer for base prediction\n",
    "            nn_out = self.linearCap(relu_out)\n",
    "            \n",
    "        return nn_out, relu_out\n",
    "        \n",
    "        \n",
    "        # return both the nn_out and the lstm out for loss calculations\n",
    "        \n",
    "    \n",
    "    def generic_model_step(self, batch, batch_idx, str_of_step_name):\n",
    "        # print(\"Start step\")\n",
    "        \n",
    "         #### #### #### WARNING MAY CAUSE SOME WEIRD OBJECT ORIENTED RELATED BEHAVIOUR I AM UNAWARE ABOUT AND NOT WORK #### #### ####\n",
    "            \n",
    "        # print(\"CHECKING\")\n",
    "        # print(batch)\n",
    "            \n",
    "        base_pred, vol_pred = self(batch['x'], batch['height_vector'])\n",
    "        loss = self.loss_fn_vol(vol_pred, batch['cloud_volume_target'])\n",
    "        \n",
    "        if self.do_linear_fit:\n",
    "            loss_2 = self.loss_fn_base(base_pred, batch['cloud_base_target'])\n",
    "            loss = (loss*40) + loss_2 # 40 adjusts for differences in numerical values produced by loss function\n",
    "        \n",
    "        #log to tensorboard\n",
    "        if self.log_bool:\n",
    "            self.log((str_of_step_name + 'loss'), loss)\n",
    "            self.log(str_of_step_name, 'volume loss component', loss_1)\n",
    "            self.log(str_of_step_name, 'base height loss component', loss_2)\n",
    "        \n",
    "        return loss\n",
    "        \n",
    "    \n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \n",
    "        return self.generic_model_step(batch, batch_idx, 'training')\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        \n",
    "        return self.generic_model_step(batch, batch_idx, 'validation')\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        \n",
    "        return self.generic_model_step(batch, batch_idx, 'test')\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optim = torch.optim.Adam(self.parameters(), self.lr)\n",
    "        \n",
    "        return optim\n",
    "\n",
    "# define torch dataloader\n",
    "class CBH_Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_x, data_y, cloud_base_label):\n",
    "        \n",
    "        # print('begin init')\n",
    "        \n",
    "        self.temp_humidity_pressure = data_x\n",
    "        self.cloudbase_target = data_y\n",
    "        self.cbh_label = cloud_base_label\n",
    "        \n",
    "        self.height_layer_number = data_x.shape[1] # take the shape at index 1 as data_x of format sample, height, feature\n",
    "        \n",
    "        assert self.height_layer_number == 70\n",
    "        \n",
    "        # print('end init')\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.temp_humidity_pressure)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        # since dask is being used, first compute the values on the index given to the get function, convert the array to tensor for pytorch\n",
    "        \n",
    "        # torch.from_numpy(x.compute())\n",
    "        \n",
    "        input_features = self.temp_humidity_pressure[idx]\n",
    "        output_target = self.cloudbase_target[idx]\n",
    "        # print(output_target.dtype)\n",
    "        # output_target = output_target.type(torch.FloatTensor)\n",
    "        cbh_lab = self.cbh_label[idx]\n",
    "        \n",
    "        # print('CALL ON GETITEM')\n",
    "        \n",
    "        height_vec = torch.from_numpy(np.arange(self.height_layer_number)) # should have produced this vector here, as it is the same every time, but will leave it since sunken cost and maybe it improves performance??? \n",
    "        \n",
    "        item_in_dataset = {'x':input_features, 'cloud_volume_target':output_target, 'cloud_base_target':cbh_lab, 'height_vector':height_vec}\n",
    "        return item_in_dataset\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7b42189-6eff-4824-8ffd-29e4caf4ce4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # define dask specific collate function for dataloader, collate is the step where the dataloader combines all the samples into a singular batch to be enumerated on, \n",
    "# # after getting all items \n",
    "# from torch._six import string_classes\n",
    "# import collections\n",
    "# def temp_and_real_collate_default(batch):\n",
    "#     elem = batch[0]\n",
    "#     elem_type = type(elem)\n",
    "#     print('0')\n",
    "#     if isinstance(elem, torch.Tensor):\n",
    "#         print('1')\n",
    "#         out = None\n",
    "#         if torch.utils.data.get_worker_info() is not None:\n",
    "#             print('2')\n",
    "#             # If we're in a background process, concatenate directly into a\n",
    "#             # shared memory tensor to avoid an extra copy\n",
    "#             numel = sum(x.numel() for x in batch)\n",
    "#             storage = elem.storage()._new_shared(numel, device=elem.device)\n",
    "#             out = elem.new(storage).resize_(len(batch), *list(elem.size()))\n",
    "#         return torch.stack(batch, 0, out=out)\n",
    "#     elif elem_type.__module__ == 'numpy' and elem_type.__name__ != 'str_' \\\n",
    "#             and elem_type.__name__ != 'string_':\n",
    "#         print('3')\n",
    "#         if elem_type.__name__ == 'ndarray' or elem_type.__name__ == 'memmap':\n",
    "#             print('4')\n",
    "#             # array of string classes and object\n",
    "#             if np_str_obj_array_pattern.search(elem.dtype.str) is not None:\n",
    "#                 print('5')\n",
    "#                 raise TypeError(default_collate_err_msg_format.format(elem.dtype))\n",
    "\n",
    "#             return default_collate([torch.as_tensor(b) for b in batch])\n",
    "#         elif elem.shape == ():  # scalars\n",
    "#             print('6')\n",
    "#             return torch.as_tensor(batch)\n",
    "#     elif isinstance(elem, float):\n",
    "#         print('7')\n",
    "#         return torch.tensor(batch, dtype=torch.float64)\n",
    "#     elif isinstance(elem, int):\n",
    "#         print('8')\n",
    "#         return torch.tensor(batch)\n",
    "#     elif isinstance(elem, string_classes):\n",
    "#         print('9')\n",
    "#         return batch\n",
    "#     elif isinstance(elem, collections.abc.Mapping):\n",
    "#         print('10')\n",
    "#         try:\n",
    "#             print('11')\n",
    "#             return elem_type({key: default_collate([d[key] for d in batch]) for key in elem})\n",
    "#         except TypeError:\n",
    "#             print('012')\n",
    "#             # The mapping type may not support `__init__(iterable)`.\n",
    "#             return {key: default_collate([d[key] for d in batch]) for key in elem}\n",
    "#     elif isinstance(elem, tuple) and hasattr(elem, '_fields'):\n",
    "#         print('013')# namedtuple\n",
    "#         return elem_type(*(default_collate(samples) for samples in zip(*batch)))\n",
    "#     elif isinstance(elem, collections.abc.Sequence):\n",
    "#         print('014')\n",
    "#         # check to make sure that the elements in batch have consistent size\n",
    "#         it = iter(batch)\n",
    "#         elem_size = len(next(it))\n",
    "#         if not all(len(elem) == elem_size for elem in it):\n",
    "#             print('015')\n",
    "#             raise RuntimeError('each element in list of batch should be of equal size')\n",
    "#         transposed = list(zip(*batch))  # It may be accessed twice, so we use a list.\n",
    "\n",
    "#         if isinstance(elem, tuple):\n",
    "#             print('016')\n",
    "#             return [default_collate(samples) for samples in transposed]  # Backwards compatibility.\n",
    "#         else:\n",
    "#             print('017')\n",
    "#             try:\n",
    "#                 print('018')\n",
    "#                 return elem_type([default_collate(samples) for samples in transposed])\n",
    "#             except TypeError:\n",
    "#                 print('019')\n",
    "#                 # The sequence type may not support `__init__(iterable)` (e.g., `range`).\n",
    "#                 return [default_collate(samples) for samples in transposed]\n",
    "\n",
    "#     raise TypeError(default_collate_err_msg_format.format(elem_type))\n",
    "\n",
    "\n",
    "def dataloader_collate_with_dask(batch):\n",
    "    # print(\"call OG collate\")\n",
    "    elem = batch[0]\n",
    "    elem_type = type(elem)\n",
    "    \n",
    "    \n",
    "    # assert torch.utils.data.get_worker_info() is None # if this assertion fails, there are issues in code and this case needs to be handled see pytorch source of default collate fn\n",
    "\n",
    "    try:\n",
    "        return elem_type({key: collate_helper_send_dict_elements_to_tensor([d[key] for d in batch]) for key in elem})\n",
    "        \n",
    "    except TypeError:\n",
    "        # print('Should not have reached here')\n",
    "        # raise TypeError()\n",
    "        return {key: collate_helper_send_dict_elements_to_tensor([d[key] for d in batch]) for key in elem}\n",
    "    \n",
    "    raise TypeError(default_collate_err_msg_format.format(elem_type))\n",
    "\n",
    "    \n",
    "def collate_helper_send_dict_elements_to_tensor(batch):\n",
    "    # print(\"call sub collate\")\n",
    "    # assert torch.utils.data.get_worker_info() is None\n",
    "    \n",
    "    elem = batch[0]\n",
    "    \n",
    "    # print(type(elem))\n",
    "    # print(batch)\n",
    "    \n",
    "    if type(elem) is dask.array.core.Array:\n",
    "        new_batch = np.stack(batch, 0) # emulate torch stack\n",
    "        # print(\"Start compute\", len(batch))\n",
    "        new_batch = new_batch.compute()\n",
    "        # print(\"End compute\")\n",
    "        to_return = torch.from_numpy(new_batch)\n",
    "        \n",
    "    # elif isinstance(elem, torch.Tensor):\n",
    "    #     out = None\n",
    "    #     if torch.utils.data.get_worker_info() is not None:\n",
    "    #         # If we're in a background process, concatenate directly into a\n",
    "    #         # shared memory tensor to avoid an extra copy\n",
    "    #         numel = sum(x.numel() for x in batch)\n",
    "    #         storage = elem.storage()._new_shared(numel)\n",
    "    #         out = elem.new(storage).resize_(len(batch), *list(elem.size()))\n",
    "    #     return torch.stack(batch, 0, out=out)\n",
    "    \n",
    "    \n",
    "    else:\n",
    "        to_return = torch.stack(batch, 0)\n",
    "    # print('okay')\n",
    "    # print(to_return)\n",
    "    return to_return\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b83e7351-b657-4e9b-8997-2d4022f8b5e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# enforce reproducibility\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "\n",
    "seed_everything(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0ab5c4-12e5-48cb-a947-f4f70a0e520e",
   "metadata": {},
   "source": [
    "## Perform the network initialization and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ce919a8-22f0-46c1-a895-6b7c07ccdba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# load into torcg dataset \n",
    "\n",
    "collate_fn = dataloader_collate_with_dask\n",
    "\n",
    "train_cbh_data = CBH_Dataset(train_input, train_cloud_volume, train_labels)\n",
    "dev_cbh_data = CBH_Dataset(dev_input, dev_cloud_volume, dev_labels)\n",
    "\n",
    "height_dim = train_input.shape[1]\n",
    "\n",
    "# define model and hyperparameters\n",
    "layers = 3\n",
    "input_size = train_input.shape[2] # input size is the cell input (feat dim)\n",
    "output_size = 1 # for each height layer, predict one value for cloud base prob\n",
    "hidden_size = 32\n",
    "embed_size = 5\n",
    "BILSTM = False\n",
    "batch_first = True\n",
    "\n",
    "learn_rate = 0.002\n",
    "\n",
    "log_with_pl = False # do not log, as track with mlFlow\n",
    "\n",
    "model = CloudBaseLSTM(input_size, layers, hidden_size, output_size, height_dim, embed_size, BILSTM, batch_first, lr=learn_rate, log_boolean=log_with_pl)\n",
    "\n",
    "# define training related hyperparameters\n",
    "\n",
    "epochs = 10\n",
    "max_time =\"00:12:00:00\" #dd:hh:mm:ss\n",
    "\n",
    "batch_size = 1000\n",
    "\n",
    "# after training parameters defined, load datasets into dataloaders\n",
    "import multiprocessing as mp\n",
    "workers_on_system = np.min((8, mp.cpu_count()))\n",
    "train_loader = torch.utils.data.DataLoader(train_cbh_data, batch_size=batch_size, shuffle=True, collate_fn=collate_fn, num_workers = workers_on_system)\n",
    "val_loader = torch.utils.data.DataLoader(dev_cbh_data, batch_size=batch_size, shuffle=False, collate_fn=collate_fn, num_workers = workers_on_system) # don't shuffle in val\n",
    "\n",
    "# define trainer\n",
    "trainer = pl.Trainer(max_epochs = epochs, deterministic=True, check_val_every_n_epoch=1, devices=\"auto\", accelerator=\"auto\", max_time=max_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39551462-62c9-4181-a41b-640463f4196c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup mlflow logging\n",
    "\n",
    "mlflow.pytorch.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c2dade6-a531-43b9-a88c-dcfb92937ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Missing logger folder: /net/home/h02/hsouth/github_committing/data_science_cop/challenges/2021_CyrilMorcrette_cloudBaseHeight/lightning_logs\n",
      "\n",
      "  | Name             | Type      | Params\n",
      "-----------------------------------------------\n",
      "0 | LSTM             | LSTM      | 2.5 K \n",
      "1 | relu             | ReLU      | 0     \n",
      "2 | height_embedding | Embedding | 350   \n",
      "3 | loss_fn_vol      | MSELoss   | 0     \n",
      "-----------------------------------------------\n",
      "2.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.9 K     Total params\n",
      "0.012     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c60960b6f89c460ba3dc5ff170e187fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/h02/hsouth/.conda/envs/pl/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:726: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "# run the training function \n",
    "with mlflow.start_run() as run:\n",
    "    trainer.fit(model=model, train_dataloaders=train_loader, val_dataloaders=val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba52d2c-1212-4894-ad05-3a9f7761ccf2",
   "metadata": {},
   "source": [
    "## Display and evaluate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "888b7d7e-5158-42a9-b3f2-046dca3a218c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_auto_logged_info(r):\n",
    "\n",
    "    tags = {k: v for k, v in r.data.tags.items() if not k.startswith(\"mlflow.\")}\n",
    "    artifacts = [f.path for f in MlflowClient().list_artifacts(r.info.run_id, \"model\")]\n",
    "    print(\"run_id: {}\".format(r.info.run_id))\n",
    "    print(\"artifacts: {}\".format(artifacts))\n",
    "    print(\"params: {}\".format(r.data.params))\n",
    "    print(\"metrics: {}\".format(r.data.metrics))\n",
    "    print(\"tags: {}\".format(tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c108cb0a-4886-40ac-8ab8-af913c5d3b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_id: 5ebfb65f4e5441de92e1d59798e36e14\n",
      "artifacts: []\n",
      "params: {}\n",
      "metrics: {}\n",
      "tags: {}\n"
     ]
    }
   ],
   "source": [
    "# display mlflow output\n",
    "print_auto_logged_info(mlflow.get_run(run_id=run.info.run_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638a375e-8479-496b-87e1-821431729d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample some predictions for understanding\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
